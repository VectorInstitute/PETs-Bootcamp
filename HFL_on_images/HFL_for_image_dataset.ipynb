{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nE0tDBgUdU0"
   },
   "source": [
    "# Outline:\n",
    "\n",
    "\n",
    "This notebook discusses applying Horizontal Federated Learning (HFL) using TensorFlow Federated on image datasets which include the following steps: \n",
    "\n",
    "*   Tensorflow Federated dataset\n",
    "*   Tensorflow Federated model\n",
    "*   Tensorflow Federated computations for initialization train and validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23kgcnC82Ya9"
   },
   "source": [
    "## Usage:\n",
    "\n",
    "To use this notebook, you need to create your dataset as a dictionary where the keys are client IDs and values are the associated image/ label datasets. More precisely, each key is a client ID, and each value is a tuple of NumPy arrays for images and their associated one-hot encoded labels. Note that we assume the images in NumPy arrays are already preprocessed.\n",
    "\n",
    "After having your data ready in the mentioned format, all you need is to specify the \"**path**\" variable to be the path to the dictionary file (images/labels from different clients).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJnPZ4eR_GNl"
   },
   "source": [
    "### Installation of packages (for running on colab)\n",
    "If you use colab, uncomment and run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UzCd7INb1JeI",
    "outputId": "db10eb8f-61f7-47b8-a61c-a72edf533ff0"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-federated==0.18\n",
    "# !pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxQ0kI1k_cS2"
   },
   "source": [
    "### Importing Required Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c5RzkuLS9mWe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-01 09:22:41.258295: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-01 09:22:41.258328: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import collections\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0HdJosL87Ol"
   },
   "outputs": [],
   "source": [
    "# Base path to the data dictionary\n",
    "path = \"\"\n",
    "\n",
    "data = np.load(\n",
    "    path, allow_pickle=\"TRUE\"\n",
    ").item()  # data[0] return the image-lable tuple for hospital number 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJNZpgarAmNX"
   },
   "source": [
    "## Creating Federated Data:\n",
    "The function `tff.simulation.ClientData.from_clients_and_fn`, requires that we write a function that accepts a `client_id` as input and returns a `tf.data.Dataset`. Let's do that in the helper function below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnfZB3Sr-iaA"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "SHUFFLE_BUFFER = 128\n",
    "\n",
    "def create_tf_dataset_for_client_fn(client_id):\n",
    "    client_data = data[client_id]\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (client_data[0], client_data[1])\n",
    "    ).prefetch(\n",
    "        buffer_size=128\n",
    "    )  # client_data[0] is images,   client_data[1] is labels\n",
    "    dataset = dataset.shuffle(2000, reshuffle_each_iteration=True).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nN5tCuoIFH8u"
   },
   "source": [
    "Now, let's create the training and testing federated data. To this end, we specify the `train_client_ids` and `test_client_ids` which contain the IDs of train and test clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4FymhW7t-uKi"
   },
   "outputs": [],
   "source": [
    "# IDs for train and test clients. For example:\n",
    "# train_client_ids=[0,2,3]\n",
    "# test_client_ids=[1]\n",
    "\n",
    "# specify the train and test clients based on their IDs:\n",
    "train_client_ids = []\n",
    "test_client_ids = []\n",
    "\n",
    "train_data = tff.simulation.ClientData.from_clients_and_fn(\n",
    "    client_ids=train_client_ids,\n",
    "    create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn,\n",
    ")\n",
    "test_data = tff.simulation.ClientData.from_clients_and_fn(\n",
    "    client_ids=test_client_ids,\n",
    "    create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTbwCJ7uHF92"
   },
   "source": [
    "Let's see number of the clients for training federated data and also the sructure of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GQ1Qf20rQGg2",
    "outputId": "4177f0b4-57bb-45eb-b21b-b471998430d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.client_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_Oi4uxgQMJ_",
    "outputId": "0a2fadd3-7ed0-48a5-cb62-9a522efedb65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float16, name=None),\n",
       " TensorSpec(shape=(None, 3), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.element_type_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1nbpGYuGsKX"
   },
   "source": [
    "To see exactly how one batch od data look like we create the following example dataset from one the client ids of train federated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zgW8MDejGRQ3",
    "outputId": "ebf3de5d-a626-4a68-f6dc-51f1a30186fa"
   },
   "outputs": [],
   "source": [
    "example_dataset = train_data.create_tf_dataset_for_client(train_data.client_ids[0])\n",
    "# print(example_dataset)\n",
    "example_element = iter(example_dataset).next()\n",
    "print(example_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0RetA4YfIQL"
   },
   "source": [
    "We now have almost all the building blocks in place to construct federated datasets.\n",
    "\n",
    "One of the ways to feed federated data to TFF in a simulation is simply as a Python list, with each element of the list holding the data of an individual user, as a `tf.data.Dataset`. Since we already have an interface for that, let's use it.\n",
    "\n",
    "The helper function `make_federated_data` below will construct a list of datasets from the\n",
    "given set of users as an input to a round of training or evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uq8HOnoyQ-ss"
   },
   "outputs": [],
   "source": [
    "def make_federated_data(client_data, client_ids):\n",
    "    return [client_data.create_tf_dataset_for_client(x) for x in client_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JrUw1guMj52E",
    "outputId": "13aa3dc2-549c-49ef-a4e6-76596698ad56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of client datasets: 3\n",
      "First dataset: <BatchDataset shapes: ((None, 224, 224, 3), (None, 3)), types: (tf.float16, tf.float64)>\n"
     ]
    }
   ],
   "source": [
    "federated_train_data = make_federated_data(train_data, train_client_ids)\n",
    "print(\"Number of client datasets: {l}\".format(l=len(federated_train_data)))\n",
    "print(\"First dataset: {d}\".format(d=federated_train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExQL-K9kfgxF"
   },
   "source": [
    "## Tensorflow Federated model\n",
    "First we create a simple CNN model with Keras:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFCPMExUfSlW"
   },
   "outputs": [],
   "source": [
    "num_classes = data[0][1].shape[1]\n",
    "img_height = data[0][0].shape[1]\n",
    "img_width = data[0][0].shape[2]\n",
    "\n",
    "def create_keras_model():\n",
    "    model = Sequential(\n",
    "        [\n",
    "            layers.Conv2D(\n",
    "                16,\n",
    "                3,\n",
    "                padding=\"same\",\n",
    "                activation=\"relu\",\n",
    "                input_shape=(img_height, img_width, 3),\n",
    "            ),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation=\"relu\"),\n",
    "            layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYLnYUoqgNlV"
   },
   "source": [
    "Note that we do not compile the model yet. The loss, metrics, and optimizers are introduced later.\n",
    "\n",
    "If you have a Keras model like the one we've just defined above, you can have TFF wrap it for you by invoking\n",
    "`tff.learning.from_keras_model`, passing the model and a sample data batch as\n",
    "arguments (`input_spec=example_dataset.element_spec`), as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PUqDNN5f0ap"
   },
   "outputs": [],
   "source": [
    "# We _must_ create a new model here, and _not_ capture it from an external\n",
    "# scope. TFF will call this within different graph contexts.\n",
    "def model_fn():\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "        keras_model,\n",
    "        input_spec=example_dataset.element_spec,\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.CategoricalAccuracy(),\n",
    "            tf.keras.metrics.AUC(name=\"AUC\"),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDelj8XulaUF"
   },
   "source": [
    "The model_fn is a no-arg function that returns a `tff.learning.Model`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBAe9eMvhIcf"
   },
   "source": [
    "### Training the model on federated data \n",
    "\n",
    "Now that we have a model wrapped as `tff.learning.Model` for use with TFF, we\n",
    "can let TFF construct a **Federated Averaging** algorithm by invoking the helper\n",
    "function `tff.learning.build_federated_averaging_process`, as follows.\n",
    "\n",
    "One critical note on the Federated Averaging algorithm below, there are **2**\n",
    "optimizers: a _client_optimizer_ and a _server_optimizer_. The\n",
    "_client_optimizer_ is only used to compute local model updates on each client.\n",
    "The _server_optimizer_ applies the averaged update to the global model at the\n",
    "server. In particular, this means that the choice of optimizer and learning rate\n",
    "used may need to be different than the ones you have used to train the model on\n",
    "a standard i.i.d. dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjB_sD5egibj"
   },
   "outputs": [],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.05),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-YmVZuGhnI4"
   },
   "source": [
    "In this case, the two computations generated and packed into iterative_process implement Federated Averaging.\n",
    "\n",
    "Let's start with the `initialize` computation. As is the case for all federated\n",
    "computations, you can think of it as a function. The computation takes no\n",
    "arguments, and returns one result - the representation of the state of the\n",
    "Federated Averaging process on the server. While we don't want to dive into the\n",
    "details of TFF, it may be instructive to see what this state looks like. You can\n",
    "visualize it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "Eb5OLh1ohRkm",
    "outputId": "49b5b578-bf4b-459d-cd21-8ec37ba6822b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'( -> <model=<trainable=<float32[3,3,3,16],float32[16],float32[3,3,16,32],float32[32],float32[3,3,32,64],float32[64],float32[50176,128],float32[128],float32[128,3],float32[3]>,non_trainable=<>>,optimizer_state=<int64>,delta_aggregate_state=<value_sum_process=<>,weight_sum_process=<>>,model_broadcast_state=<>>@SERVER)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(iterative_process.initialize.type_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xo_D135PhzCm"
   },
   "source": [
    "While the above type signature may at first seem a bit cryptic, you can recognize that the server state consists of a model (the initial model parameters that will be distributed to all devices), and optimizer_state (additional information maintained by the server, such as the number of rounds to use for hyperparameter schedules, etc.).\n",
    "\n",
    "Let's invoke the initialize computation to construct the server state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7vNqokkhsYi"
   },
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6B8IOPfih2e0",
    "outputId": "dfc2a430-fde3-4416-db00-85ceef651de5"
   },
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLrk-NDxiDBO"
   },
   "source": [
    "The second of the pair of federated computations, `next`, represents a single\n",
    "round of Federated Averaging, which consists of pushing the server state\n",
    "(including the model parameters) to the clients, on-device training on their\n",
    "local data, collecting and averaging model updates, and producing a new updated\n",
    "model at the server.\n",
    "\n",
    "Conceptually, you can think of `next` as having a functional type signature that\n",
    "looks as follows.\n",
    "\n",
    "```\n",
    "SERVER_STATE, FEDERATED_DATA -> SERVER_STATE, TRAINING_METRICS\n",
    "```\n",
    "\n",
    "In particular, one should think about `next()` not as being a function that runs on a server, but rather being a declarative functional representation of the entire decentralized computation - some of the inputs are provided by the server (`SERVER_STATE`), but each participating device contributes its own local dataset.\n",
    "\n",
    "To run a single round of training and visualizing the results We can use the following line of code and federated data we've already generated above:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7HoXm0fWjpnv",
    "outputId": "33e1aba5-9fa4-46ed-e497-9bdc73060e23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/asyncio/tasks.py:840: RuntimeWarning: coroutine 'wrap_coroutine_in_current_trace_context.<locals>._wrapped' was never awaited\n",
      "  futures._chain_future(ensure_future(coro, loop=loop), future)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib/python3.7/asyncio/tasks.py:840: RuntimeWarning: coroutine '_invoke' was never awaited\n",
      "  futures._chain_future(ensure_future(coro, loop=loop), future)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('categorical_accuracy', 0.67475504), ('AUC', 0.82607585), ('loss', 0.7946014)])), ('stat', OrderedDict([('num_examples', 6429)]))])\n"
     ]
    }
   ],
   "source": [
    "state, metrics = iterative_process.next(state, federated_train_data)\n",
    "print(\"round  1, metrics={}\".format(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puoZpi5CltTJ"
   },
   "source": [
    "## Evaluation\n",
    "To perform evaluation on federated data, you can construct another *federated\n",
    "computation* designed for just this purpose, using the\n",
    "`tff.learning.build_federated_evaluation` function, and passing in your model\n",
    "constructor as an argument. Note that as the evaluation doesn't perform gradient descent, and there's no need to construct\n",
    "optimizers.\n",
    "\n",
    "For experimentation and research, when a centralized test dataset is available,\n",
    "[Federated Learning for Text Generation](federated_learning_for_text_generation.ipynb)\n",
    "demonstrates another evaluation option: taking the trained weights from\n",
    "federated learning, applying them to a standard Keras model, and then simply\n",
    "calling `tf.keras.models.Model.evaluate()` on a centralized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnHToV-sl193",
    "outputId": "5df7d3c5-2058-4f48-e236-6bba59415405"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('categorical_accuracy', 0.70076585),\n",
       "             ('AUC', 0.7917838),\n",
       "             ('loss', 1.0567521)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = tff.learning.build_federated_evaluation(\n",
    "    model_fn\n",
    ")  \n",
    "\n",
    "federated_test_data = make_federated_data(test_data, test_client_ids)\n",
    "\n",
    "val_metrics = evaluation(state.model, federated_test_data)\n",
    "\n",
    "val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MRMGwyLmSwJ",
    "outputId": "0f223e85-9baf-4310-d65a-f519ae769072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "a = iter(federated_test_data[0]).next()\n",
    "print(a[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mh_ceyGdjC3G"
   },
   "source": [
    "## Training and evaluation multiple rounds:\n",
    "\n",
    "Here we run the federated learning algorithm multiple rounds on training clients and evaluate the performance on test client.\n",
    "\n",
    "First we initialize the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FIdaipQXh88D",
    "outputId": "4ab43c1a-0ed4-4d85-d70d-050d3bffb67d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:60: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:60: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    }
   ],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsfxH0uckV6O"
   },
   "source": [
    "Now let's train and evaluate for multiple rounds. Note that number of rounds is soecified using the variable `NUM_ROUNDS` in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qe5p5EwokI6O"
   },
   "outputs": [],
   "source": [
    "NUM_ROUNDS = 5\n",
    "\n",
    "loss = list()\n",
    "accuracy = list()\n",
    "AUC = list()\n",
    "\n",
    "val_loss = list()\n",
    "val_accuracy = list()\n",
    "val_AUC = list()\n",
    "\n",
    "evaluation = tff.learning.build_federated_evaluation(model_fn)\n",
    "federated_test_data = make_federated_data(test_data, test_client_ids)\n",
    "\n",
    "for round_num in range(1, NUM_ROUNDS + 1):\n",
    "    state, metrics = iterative_process.next(state, federated_train_data)\n",
    "    val_metrics = evaluation(state.model, federated_test_data)\n",
    "\n",
    "    my_loss = metrics[\"train\"][\"loss\"]\n",
    "    loss.append(metrics[\"train\"][\"loss\"])\n",
    "\n",
    "    my_acc = metrics[\"train\"][\"categorical_accuracy\"]\n",
    "    accuracy.append(metrics[\"train\"][\"categorical_accuracy\"])\n",
    "\n",
    "    my_AUC = metrics[\"train\"][\"AUC\"]\n",
    "    AUC.append(my_AUC)\n",
    "\n",
    "    my_val_loss = val_metrics[\"loss\"]\n",
    "    val_loss.append(val_metrics[\"loss\"])\n",
    "\n",
    "    my_val_accuracy = val_metrics[\"categorical_accuracy\"]\n",
    "    val_accuracy.append(val_metrics[\"categorical_accuracy\"])\n",
    "\n",
    "    my_val_AUC = val_metrics[\"AUC\"]\n",
    "    val_AUC.append(my_val_AUC)\n",
    "\n",
    "    print(\n",
    "        f\"round: {round_num:2d}, training_loss: {my_loss}, training_accuracy: {my_acc}, train_auc: {my_AUC}, test_loss: {my_val_loss}, test_accuracy: {my_val_accuracy},  test_auc: {my_val_AUC}\"\n",
    "    )\n",
    "\n",
    "\n",
    "history_fed = {\n",
    "    \"loss\": loss,\n",
    "    \"categorical_accuracy\": accuracy,\n",
    "    \"AUC\": AUC,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_categorical_accuracy\": val_accuracy,\n",
    "    \"val_AUC\": val_AUC,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OzpUcy1cLVU7"
   },
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(30, 8))\n",
    "fig1.subplots_adjust(top=0.99, bottom=0.01, hspace=0.3, wspace=0.3)\n",
    "ax1 = fig1.add_subplot(1, 3, 1)\n",
    "ax1.plot(\n",
    "    history_fed[\"AUC\"],\n",
    "    label=\"Train AUC on Hispital 1 with Federated Model trained on Hospitals 0-2-3\",\n",
    ")\n",
    "ax1.plot(\n",
    "    history_fed[\"val_AUC\"],\n",
    "    label=\"Test AUC on Hispital 1 with Federated Model trained on Hospitals 0-2-3\",\n",
    ")\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.set_ylabel(\"Auc\")\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.set_title(\"Auc for test and train clients\")\n",
    "ax1.set_xlabel(\"Epoch/Round\")\n",
    "\n",
    "\n",
    "ax2 = fig1.add_subplot(1, 3, 2)\n",
    "ax2.plot(\n",
    "    history_fed[\"categorical_accuracy\"],\n",
    "    label=\"Train Accuracy on Hispital 1 with Federated Model trained on Hospitals 0-2-3\",\n",
    ")\n",
    "ax2.plot(\n",
    "    history_fed[\"val_categorical_accuracy\"],\n",
    "    linewidth=3,\n",
    "    label=\"Test Accuracy on Hispital 1 with Federated Model trained on Hospitals 0-2-3\",\n",
    ")\n",
    "ax2.legend(loc=\"lower right\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "ax2.set_ylim([0, 1])\n",
    "ax2.set_title(\"Accuracy for test and train clients\")\n",
    "ax2.set_xlabel(\"Epoch/Round\")\n",
    "\n",
    "ax3 = fig1.add_subplot(1, 3, 3)\n",
    "ax3.plot(\n",
    "    history_fed[\"loss\"],\n",
    "    label=\"Train Loss on Hispital 1 with Federated Model trained on Hospitals 0-2-3\",\n",
    ")\n",
    "ax3.plot(\n",
    "    history_fed[\"val_loss\"],\n",
    "    label=\"Test Loss on Hispital 1 with Federated Model trained on Hospitals 0-2-3\",\n",
    ")\n",
    "ax3.legend(loc=\"lower right\")\n",
    "ax3.set_ylabel(\"Cross Entropy\")\n",
    "ax3.set_ylim([0, max(ax2.get_ylim()) + 0.5])\n",
    "ax3.set_title(\"Loss for test and train clients\")\n",
    "ax3.set_xlabel(\"Epoch/Round\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HFL_for_image_dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
