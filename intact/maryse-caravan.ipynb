{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "reported-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Restrict minor warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# to display all outputs of one cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer as CTT\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import syft as sy\n",
    "from uuid import UUID\n",
    "from uuid import uuid4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "quality-phrase",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28780/2045112964.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mServer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mid_collate_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.psi.util import Client, Server\n",
    "from src.utils import add_ids\n",
    "from src.utils.data_utils import id_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "designed-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_weights(class1_size, class2_size):\n",
    "    if class1_size < class2_size:\n",
    "        return [class2_size / class1_size, 1]\n",
    "        factor2 = 1\n",
    "    else:\n",
    "        return [1, class1_size / class2_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "collectible-venture",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerticalDataset(Dataset):\n",
    "    \"\"\"Dataset for Vertical Federated Learning\"\"\"\n",
    "\n",
    "    def __init__(self, ids, data, labels=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ids (Numpy Array) : Numpy Array with UUIDS\n",
    "            data (Numpy Array) : Numpy Array with Features\n",
    "            targets (Numpy Array) : Numpy Array with Labels. None if not available. \n",
    "        \"\"\"\n",
    "        self.ids = ids\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Return record single record\"\"\"\n",
    "        feature = self.data[index].astype(np.float32)\n",
    "\n",
    "        if self.labels is None:\n",
    "            label  = None\n",
    "        else:\n",
    "            label = int(self.labels[index]) if self.labels is not None else None\n",
    "\n",
    "        id = self.ids[index]\n",
    "\n",
    "        # Return a tuple of non-None elements\n",
    "        return (*filter(lambda x: x is not None, (feature, label, id)),)\n",
    "    \n",
    "    def get_ids(self):\n",
    "        \"\"\"Return a list of the ids of this dataset.\"\"\"\n",
    "        return [str(id_) for id_ in self.ids]\n",
    "    \n",
    "    def sort_by_ids(self):\n",
    "        \"\"\"\n",
    "        Sort the dataset by IDs in ascending order\n",
    "        \"\"\"\n",
    "        ids = self.get_ids()\n",
    "        sorted_idxs = np.argsort(ids)\n",
    "\n",
    "\n",
    "        self.data = self.data[sorted_idxs]\n",
    "\n",
    "        if self.labels is not None:\n",
    "            self.labels = self.labels[sorted_idxs]\n",
    "\n",
    "        self.ids = self.ids[sorted_idxs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "valuable-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinglePartitionDataLoader(DataLoader):\n",
    "    \"\"\"DataLoader for a single vertically-partitioned dataset\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.collate_fn = id_collate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "appreciated-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerticalDataLoader:\n",
    "    \"\"\"Dataloader which batches data from a complete\n",
    "    set of vertically-partitioned datasets\n",
    "    i.e. the images dataset AND the labels dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data1, data2, *args, **kwargs):\n",
    "\n",
    "        self.dataloader1 = SinglePartitionDataLoader(\n",
    "            data1, *args, **kwargs\n",
    "        )\n",
    "        self.dataloader2 = SinglePartitionDataLoader(\n",
    "            data2, *args, **kwargs\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Zip Dataloaders \n",
    "        \"\"\"\n",
    "        return zip(self.dataloader1, self.dataloader2)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return length of dataset\n",
    "        \"\"\"\n",
    "        return (len(self.dataloader1) + len(self.dataloader2)) // 2\n",
    "\n",
    "    def drop_non_intersecting(self, intersection):\n",
    "        \"\"\"Remove elements and ids in the datasets that are not in the intersection.\"\"\"\n",
    "        self.dataloader1.dataset.data = self.dataloader1.dataset.data[intersection]\n",
    "        self.dataloader1.dataset.ids = self.dataloader1.dataset.ids[intersection]\n",
    "\n",
    "        self.dataloader1.dataset.labels = self.dataloader1.dataset.labels[intersection]\n",
    "        self.dataloader2.dataset.ids = self.dataloader2.dataset.ids[intersection]\n",
    "\n",
    "    def sort_by_ids(self) -> None:\n",
    "        \"\"\"\n",
    "        Sort each dataset by ids\n",
    "        \"\"\"\n",
    "        self.dataloader1.dataset.sort_by_ids()\n",
    "        self.dataloader2.dataset.sort_by_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-ribbon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-soviet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-scotland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-burton",
   "metadata": {},
   "source": [
    "## Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fifth-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"/ssd003/projects/pets/datasets/caravan-insurance-challenge.csv\"\n",
    "df = pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "charitable-tourism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 87)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "religious-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['ORIGIN']=='train']\n",
    "val = df[df['ORIGIN']=='test']\n",
    "\n",
    "_ = train.pop('ORIGIN')\n",
    "_ = val.pop('ORIGIN')\n",
    "\n",
    "X_train = train\n",
    "X_val = val\n",
    "y_train = train.pop('CARAVAN')\n",
    "y_val = val.pop('CARAVAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "needed-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numerical columns\n",
    "cat_cols = ['MOSTYPE','MOSHOOFD']\n",
    "num_cols = list(X_train.columns.values[43:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "latest-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe to numpy arrays\n",
    "# create 2 datasets: one categorial, one numerical\n",
    "X_train_num = np.array(X_train[num_cols])\n",
    "X_train_cat = np.array(X_train[cat_cols])\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_val_num = np.array(X_val[cat_cols])\n",
    "X_val_cat = np.array(X_val[cat_cols])\n",
    "y_val = np.array(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "hired-beijing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5822, 42), (5822, 2), (5822,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num.shape, X_train_cat.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "local-advertising",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 2), (4000, 2), (4000,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_num.shape, X_val_cat.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "sound-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get UID Column\n",
    "uuids = np.array([uuid4() for _ in range(len(X_train))])\n",
    "uuids_val = np.array([uuid4() for _ in range(len(X_val))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "strong-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create VerticalDatasets\n",
    "num_dataset = VerticalDataset(ids=uuids, data=X_train_num, labels=y_train)\n",
    "cat_dataset = VerticalDataset(ids=uuids, data=X_train_cat, labels=y_train)\n",
    "\n",
    "num_dataset_val = VerticalDataset(ids=uuids_val, data=X_val_num, labels=y_val)\n",
    "cat_dataset_val = VerticalDataset(ids=uuids_val, data=X_val_cat, labels=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fancy-manual",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'id_collate_fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28780/2604309076.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Initialize Train Dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVerticalDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Compute private set intersection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclient_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_28780/1600622780.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data1, data2, *args, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         self.dataloader1 = SinglePartitionDataLoader(\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         )\n",
      "\u001b[0;32m/tmp/ipykernel_28780/1760888303.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid_collate_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'id_collate_fn' is not defined"
     ]
    }
   ],
   "source": [
    "## Initialize Train Dataloader \n",
    "dataloader = VerticalDataLoader(num_dataset, cat_dataset, batch_size=512)\n",
    "\n",
    "# Compute private set intersection\n",
    "client_items = dataloader.dataloader1.dataset.get_ids()\n",
    "server_items = dataloader.dataloader2.dataset.get_ids()\n",
    " \n",
    "client = Client(client_items)\n",
    "server = Server(server_items)\n",
    "\n",
    "setup, response = server.process_request(client.request, len(client_items))\n",
    "intersection = client.compute_intersection(setup, response)\n",
    "\n",
    "# Order data\n",
    "dataloader.drop_non_intersecting(intersection)\n",
    "dataloader.sort_by_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize Validation Dataloader \n",
    "val_dataloader = VerticalDataLoader(num_dataset_val, cat_dataset_val, batch_size=512)\n",
    "\n",
    "# Compute private set intersection\n",
    "val_client_items = val_dataloader.dataloader1.dataset.get_ids()\n",
    "val_server_items = val_dataloader.dataloader2.dataset.get_ids()\n",
    "\n",
    "val_client = Client(val_client_items)\n",
    "val_server = Server(val_server_items)\n",
    "\n",
    "val_setup, val_response = val_server.process_request(val_client.request, len(val_client_items))\n",
    "val_intersection = val_client.compute_intersection(val_setup, val_response)\n",
    "\n",
    "# Order data\n",
    "val_dataloader.drop_non_intersecting(val_intersection)\n",
    "val_dataloader.sort_by_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-sussex",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "soviet-found",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# device to train on\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "specialized-assets",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586 9236\n",
      "[15.761092150170649, 1]\n"
     ]
    }
   ],
   "source": [
    "# check relative weights of classes\n",
    "class1_size = df[df['CARAVAN'] == 1].shape[0]\n",
    "class0_size = df[df['CARAVAN'] == 0].shape[0]\n",
    "print(class1_size, class0_size)\n",
    "weights = get_classes_weights(class1_size, class0_size)\n",
    "print(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-export",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-extent",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pets_ALL",
   "language": "python",
   "name": "pets_all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
