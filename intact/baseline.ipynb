{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reported-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Restrict minor warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# to display all outputs of one cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer as CTT\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import syft as sy\n",
    "from uuid import UUID\n",
    "from uuid import uuid4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "quality-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.psi.util import Client, Server\n",
    "from src.utils import add_ids\n",
    "from src.utils.data_utils import id_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "designed-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_weights(class1_size, class2_size):\n",
    "    if class1_size < class2_size:\n",
    "        return [class2_size / class1_size, 1]\n",
    "        factor2 = 1\n",
    "    else:\n",
    "        return [1, class1_size / class2_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-burton",
   "metadata": {},
   "source": [
    "## Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fifth-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"/ssd003/projects/pets/datasets/caravan-insurance-challenge.csv\"\n",
    "df1 = pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "charitable-tourism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9822, 87)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "challenging-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['MOSTYPE','MOSHOOFD']\n",
    "df = pd.get_dummies(df1, columns = categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "religious-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['ORIGIN']=='train']\n",
    "val = df[df['ORIGIN']=='test']\n",
    "\n",
    "_ = train.pop('ORIGIN')\n",
    "_ = val.pop('ORIGIN')\n",
    "\n",
    "X_train = train\n",
    "X_val = val\n",
    "y_train = train.pop('CARAVAN')\n",
    "y_val = val.pop('CARAVAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "hired-beijing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5822, 133), (5822,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "local-advertising",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 133), (4000,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "meaningful-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # change?\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "collect-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.length = self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "suspended-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset(X_train, y_train)\n",
    "dataset_val = dataset(X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "revolutionary-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "generous-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "# tuning batch_size\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=512, shuffle=True)\n",
    "dataload_val = DataLoader(dataset_val, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-sussex",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bronze-knitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586 9236\n",
      "[15.761092150170649, 1]\n"
     ]
    }
   ],
   "source": [
    "# check relative weights of classes\n",
    "class1_size = df[df['CARAVAN'] == 1].shape[0]\n",
    "class0_size = df[df['CARAVAN'] == 0].shape[0]\n",
    "print(class1_size, class0_size)\n",
    "weights = get_classes_weights(class1_size, class0_size)\n",
    "print(weights)\n",
    "weights = torch.tensor(weights).to(device)\n",
    "#criterion = nn.?(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "streaming-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model , Optimizer, Loss\n",
    "model = torch.nn.Sequential(\n",
    "            nn.Linear(X_train.shape[1], 40),\n",
    "            nn.ReLU(), #\n",
    "            nn.Linear(40, 40),\n",
    "            nn.ReLU(), #\n",
    "            nn.Linear(40, 40),\n",
    "            nn.Linear(40, 40),\n",
    "            nn.Linear(40, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "#loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "soviet-found",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# device to train on\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "gothic-mississippi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=133, out_features=40, bias=True)\n",
       "  (1): Linear(in_features=40, out_features=40, bias=True)\n",
       "  (2): Linear(in_features=40, out_features=40, bias=True)\n",
       "  (3): Linear(in_features=40, out_features=40, bias=True)\n",
       "  (4): Linear(in_features=40, out_features=1, bias=True)\n",
       "  (5): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "varying-export",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28221/3377696957.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "#forward loop\n",
    "learning_rate = 0.01\n",
    "epochs = 500\n",
    "\n",
    "losses = []\n",
    "accur = []\n",
    "for i in range(epochs):\n",
    "    for j,(x_train, y_train) in enumerate(dataloader_train):\n",
    "        # calculate output\n",
    "        output = model(x_train)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = loss_fn(output, y_train.reshape(-1, 1))\n",
    "\n",
    "        # accuracy\n",
    "        predicted = model(torch.tensor(output, dtype=torch.float32))\n",
    "        acc = (predicted.reshape(-1).detach().numpy().round() == y).mean()\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%50 == 0:\n",
    "        losses.append(loss)\n",
    "        accur.append(acc)\n",
    "        print(\"epoch {}\\tloss : {}\\t accuracy : {}\".format(i,loss,acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-tenant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 instead of auc on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-liquid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-february",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pets_ALL",
   "language": "python",
   "name": "pets_all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
