{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2pse36zS0Rc"
   },
   "source": [
    "## Summary\n",
    "* In this tutorial, we will use apply a differentially private (DP) logistic regression model using the Tensorflow Privayc libray on the heart disease dataset.\n",
    "* We will calculate the privacy guarantees provided by the DP model.\n",
    "* We will complete a grid search to find hyperparameters that offer good privacy while maintaining an accceptable level of utility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0ibRc7LTgrW"
   },
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgqUmIiDpjij"
   },
   "source": [
    "References \n",
    "\n",
    "\n",
    "\n",
    "*   EDA: https://www.kaggle.com/cdabakoglu/heart-disease-classifications-machine-learning\n",
    "*   TFP Code: https://github.com/tensorflow/privacy/tree/master/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FRAk-azGj6be",
    "outputId": "4f8afcfc-af98-4b30-b16f-5407eed10fb8"
   },
   "outputs": [],
   "source": [
    "# pip install tensorflow_privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "audCpFNgvj7p"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from tensorflow_privacy.privacy.analysis.rdp_accountant import compute_rdp\n",
    "from tensorflow_privacy.privacy.analysis.rdp_accountant import get_privacy_spent\n",
    "from tensorflow_privacy.privacy.optimizers import dp_optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99X_sSb5Y8Uz"
   },
   "source": [
    "## EDA and Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjdJEHtYUhGz"
   },
   "source": [
    "The heart disese prediction dataset can be downloaded from [Kaggle](https://www.kaggle.com/ronitf/heart-disease-uci)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "CbhwbyK5MV5F",
    "outputId": "2927af44-a78e-4b32-e281-262539bc1dca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"/ssd003/projects/pets/datasets\"\n",
    "df = pd.read_csv(f\"{data_dir}/heart.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGRy-PGpMZug"
   },
   "source": [
    "Data contains: <br>\n",
    "\n",
    "* age - age in years <br>\n",
    "* sex - (1 = male; 0 = female) <br>\n",
    "* cp - chest pain type <br>\n",
    "* trestbps - resting blood pressure (in mm Hg on admission to the hospital) <br>\n",
    "* chol - serum cholestoral in mg/dl <br>\n",
    "* fbs - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) <br>\n",
    "* restecg - resting electrocardiographic results <br>\n",
    "* thalach - maximum heart rate achieved <br>\n",
    "* exang - exercise induced angina (1 = yes; 0 = no) <br>\n",
    "* oldpeak - ST depression induced by exercise relative to rest <br>\n",
    "* slope - the slope of the peak exercise ST segment <br>\n",
    "* ca - number of major vessels (0-3) colored by flourosopy <br>\n",
    "* thal - 3 = normal; 6 = fixed defect; 7 = reversable defect <br>\n",
    "* target - have disease or not (1=yes, 0=no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "AQhh-d1xMYBU",
    "outputId": "800fab42-d542-4d4c-bc89-7afadb43c5d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Patients With No Heart Disease: 45.54%\n",
      "Percentage of Patients With Heart Disease: 54.46%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Target\n",
    "df.target.value_counts()\n",
    "countNoDisease = len(df[df.target == 0])\n",
    "countHaveDisease = len(df[df.target == 1])\n",
    "print(\"Percentage of Patients With No Heart Disease: {:.2f}%\".format((countNoDisease / (len(df.target))*100)))\n",
    "print(\"Percentage of Patients With Heart Disease: {:.2f}%\".format((countHaveDisease / (len(df.target))*100)))\n",
    "sns.countplot(x=\"target\", data=df, palette=\"bwr\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "QI6U3YxQMkoe",
    "outputId": "11c9d046-1d8d-4fa5-95ea-783a3a3bdd6a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Female Patients: 31.68%\n",
      "Percentage of Male Patients: 68.32%\n"
     ]
    }
   ],
   "source": [
    "sns.countplot(x='sex', data=df, palette=\"mako_r\")\n",
    "plt.xlabel(\"Sex (0 = female, 1= male)\")\n",
    "plt.show()\n",
    "countFemale = len(df[df.sex == 0])\n",
    "countMale = len(df[df.sex == 1])\n",
    "print(\"Percentage of Female Patients: {:.2f}%\".format((countFemale / (len(df.sex))*100)))\n",
    "print(\"Percentage of Male Patients: {:.2f}%\".format((countMale / (len(df.sex))*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "660g7r6xMotF",
    "outputId": "67f172bb-2590-4974-97e7-80f61e8e3b74"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.crosstab(df.age,df.target).plot(kind=\"bar\",figsize=(20,6))\n",
    "plt.title('Heart Disease Frequency for Ages')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "#plt.savefig('heartDiseaseAndAges.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "aphLpFfGMoxH",
    "outputId": "bfca26c7-1f36-4140-95bb-93b2654eaf9b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.crosstab(df.sex,df.target).plot(kind=\"bar\",figsize=(15,6),color=['#1CA53B','#AA1111' ])\n",
    "plt.title('Heart Disease Frequency for Sex')\n",
    "plt.xlabel('Sex (0 = Female, 1 = Male)')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend([\"No Disease\", \"Has Disease\"])\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sqAbfOQxOEB4"
   },
   "outputs": [],
   "source": [
    "#one hot encode the categorical features\n",
    "a = pd.get_dummies(df['cp'], prefix = \"cp\")\n",
    "b = pd.get_dummies(df['thal'], prefix = \"thal\")\n",
    "c = pd.get_dummies(df['slope'], prefix = \"slope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "IpO9e6ZCVdie",
    "outputId": "df072ce8-d8e6-4737-8dca-f462dddfac40"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>...</th>\n",
       "      <th>cp_1</th>\n",
       "      <th>cp_2</th>\n",
       "      <th>cp_3</th>\n",
       "      <th>thal_0</th>\n",
       "      <th>thal_1</th>\n",
       "      <th>thal_2</th>\n",
       "      <th>thal_3</th>\n",
       "      <th>slope_0</th>\n",
       "      <th>slope_1</th>\n",
       "      <th>slope_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  ...  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3  ...   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5  ...   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4  ...   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8  ...   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6  ...   \n",
       "\n",
       "   cp_1  cp_2  cp_3  thal_0  thal_1  thal_2  thal_3  slope_0  slope_1  slope_2  \n",
       "0     0     0     1       0       1       0       0        1        0        0  \n",
       "1     0     1     0       0       0       1       0        1        0        0  \n",
       "2     1     0     0       0       0       1       0        0        0        1  \n",
       "3     1     0     0       0       0       1       0        0        0        1  \n",
       "4     0     0     0       0       0       1       0        0        0        1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df, a, b, c]\n",
    "df = pd.concat(frames, axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "hOfy6ivPYzgY",
    "outputId": "fa884608-699c-435d-b0b2-3651e287454b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>...</th>\n",
       "      <th>cp_1</th>\n",
       "      <th>cp_2</th>\n",
       "      <th>cp_3</th>\n",
       "      <th>thal_0</th>\n",
       "      <th>thal_1</th>\n",
       "      <th>thal_2</th>\n",
       "      <th>thal_3</th>\n",
       "      <th>slope_0</th>\n",
       "      <th>slope_1</th>\n",
       "      <th>slope_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  ca  ...  \\\n",
       "0   63    1       145   233    1        0      150      0      2.3   0  ...   \n",
       "1   37    1       130   250    0        1      187      0      3.5   0  ...   \n",
       "2   41    0       130   204    0        0      172      0      1.4   0  ...   \n",
       "3   56    1       120   236    0        1      178      0      0.8   0  ...   \n",
       "4   57    0       120   354    0        1      163      1      0.6   0  ...   \n",
       "\n",
       "   cp_1  cp_2  cp_3  thal_0  thal_1  thal_2  thal_3  slope_0  slope_1  slope_2  \n",
       "0     0     0     1       0       1       0       0        1        0        0  \n",
       "1     0     1     0       0       0       1       0        1        0        0  \n",
       "2     1     0     0       0       0       1       0        0        0        1  \n",
       "3     1     0     0       0       0       1       0        0        0        1  \n",
       "4     0     0     0       0       0       1       0        0        0        1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns = ['cp', 'thal', 'slope'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0pm5r873aRdm",
    "outputId": "59a1390f-c718-4872-f1dd-ab188d6a6d6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Sum of Null Values \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "ca          0\n",
       "target      0\n",
       "cp_0        0\n",
       "cp_1        0\n",
       "cp_2        0\n",
       "cp_3        0\n",
       "thal_0      0\n",
       "thal_1      0\n",
       "thal_2      0\n",
       "thal_3      0\n",
       "slope_0     0\n",
       "slope_1     0\n",
       "slope_2     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Data Sum of Null Values \\n')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uNX8C-E5ZBMD"
   },
   "outputs": [],
   "source": [
    "y = df.target.values\n",
    "x_data = df.drop(['target'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XhSbE1rNZB0a"
   },
   "outputs": [],
   "source": [
    "# min-max normalization\n",
    "x = (x_data - np.min(x_data)) / (np.max(x_data) - np.min(x_data)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wXI10uEYZiHY"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YcowiHlJGi4q",
    "outputId": "5c224f55-8ca9-4f75-9434-ac869916b1c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dY67QVWazcUT",
    "outputId": "2bbedca1-7977-454f-f28f-6bbcefcfad03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "etwxelfQbi8I",
    "outputId": "0c87d76f-d7af-49af-d0b5-66b2be260bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size = x_train.shape[0]\n",
    "training_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9fIWyLXqrle"
   },
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "D2_K6gFDrFVU"
   },
   "outputs": [],
   "source": [
    "def lr_model_fn(features, labels, mode, nclasses, dim, regularizer, dpsgd, data_l2_norm, noise_multiplier, learning_rate):\n",
    "  \"\"\"Model function for logistic regression.\"\"\"\n",
    "  input_layer = tf.reshape(features['x'], tuple([-1]) + dim)\n",
    "  logits = tf.keras.layers.Dense(\n",
    "      units=nclasses,\n",
    "      kernel_regularizer=tf.keras.regularizers.L2(l2=regularizer),\n",
    "      bias_regularizer=tf.keras.regularizers.L2(l2=regularizer)).apply(\n",
    "          input_layer)\n",
    "\n",
    "  # Calculate loss as a vector (to support microbatches in DP-SGD).\n",
    "  vector_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "      labels=labels, logits=logits) + tf.losses.get_regularization_loss()\n",
    "\n",
    "  # Define mean of loss across minibatch (for reporting through tf.Estimator).\n",
    "  scalar_loss = tf.reduce_mean(vector_loss)\n",
    "\n",
    "  # Configure the training op (for TRAIN mode).\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      \n",
    "    if dpsgd:\n",
    "      # The loss function is L-Lipschitz with L = sqrt(2*(||x||^2 + 1)) where\n",
    "      # ||x|| is the norm of the data.\n",
    "      # We don't use microbatches (thus speeding up computation), since no\n",
    "      # clipping is necessary due to data normalization.\n",
    "      optimizer = dp_optimizer.DPGradientDescentGaussianOptimizer(\n",
    "          l2_norm_clip=math.sqrt(2 * (data_l2_norm**2 + 1)),\n",
    "          noise_multiplier=noise_multiplier,\n",
    "          num_microbatches=1,\n",
    "          learning_rate=learning_rate)\n",
    "      opt_loss = vector_loss\n",
    "    else:\n",
    "      optimizer = GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "      opt_loss = scalar_loss\n",
    "    global_step = tf.train.get_global_step()\n",
    "    train_op = optimizer.minimize(loss=opt_loss, global_step=global_step)\n",
    "   \n",
    "    # In the following, we pass the mean of the loss (scalar_loss) rather than\n",
    "    # the vector_loss because tf.estimator requires a scalar loss. This is only\n",
    "    # used for evaluation and debugging by tf.estimator. The actual loss being\n",
    "    # minimized is opt_loss defined above and passed to optimizer.minimize().\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=scalar_loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode).\n",
    "  elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "    eval_metric_ops = {\n",
    "        'accuracy':\n",
    "            tf.metrics.accuracy(\n",
    "                labels=labels, predictions=tf.argmax(input=logits, axis=1))\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=scalar_loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Qqj4FDhSrZtD"
   },
   "outputs": [],
   "source": [
    "def normalize_data(data, data_l2_norm):\n",
    "  \"\"\"Normalizes data such that each samples has bounded L2 norm.\n",
    "\n",
    "  Args:\n",
    "    data: the dataset. Each row represents one samples.\n",
    "    data_l2_norm: the target upper bound on the L2 norm.\n",
    "  \"\"\"\n",
    "  for i in range(data.shape[0]):\n",
    "    norm = np.linalg.norm(data[i])\n",
    "    if norm > data_l2_norm:\n",
    "      data[i] = data[i] / norm * data_l2_norm\n",
    "\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "JbrRYt1wrAkN"
   },
   "outputs": [],
   "source": [
    "def print_privacy_guarantees(epochs, batch_size, samples, noise_multiplier):\n",
    "  \"\"\"Tabulating position-dependent privacy guarantees.\"\"\"\n",
    "  if noise_multiplier == 0:\n",
    "    print('No differential privacy (additive noise is 0).')\n",
    "    return\n",
    "\n",
    "  print('In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) '\n",
    "        'the training procedure results in the following privacy guarantees.')\n",
    "\n",
    "  print('Out of the total of {} samples:'.format(samples))\n",
    "\n",
    "  steps_per_epoch = samples // batch_size\n",
    "  orders = np.concatenate(\n",
    "      [np.linspace(2, 20, num=181),\n",
    "       np.linspace(20, 100, num=81)])\n",
    "  delta = 1 / (samples*1.1)\n",
    "  for p in (.5, .9, .99, 1.0):\n",
    "    steps = math.ceil(steps_per_epoch * p)  # Steps in the last epoch.\n",
    "    coef = 2 * (noise_multiplier * batch_size)**-2 * (\n",
    "        # Accounting for privacy loss\n",
    "        (epochs - 1) / steps_per_epoch +  # ... from all-but-last epochs\n",
    "        1 / (steps_per_epoch - steps + 1))  # ... due to the last epoch\n",
    "    # Using RDP accountant to compute eps. Doing computation analytically is\n",
    "    # an option.\n",
    "    rdp = [order * coef for order in orders]\n",
    "    eps, _, _ = get_privacy_spent(orders, rdp, target_delta=delta)\n",
    "    print('\\t{:g}% enjoy at least ({:.2f}, {})-DP'.format(\n",
    "        p * 100, eps, delta))\n",
    "\n",
    "  # Compute privacy guarantees for the Sampled Gaussian Mechanism.\n",
    "  rdp_sgm = compute_rdp(batch_size / samples, noise_multiplier,\n",
    "                        epochs * steps_per_epoch, orders)\n",
    "  eps_sgm, _, _ = get_privacy_spent(orders, rdp_sgm, target_delta=delta)\n",
    "  print('By comparison, DP-SGD analysis for training done with the same '\n",
    "        'parameters and random shuffling in each epoch guarantees '\n",
    "        '({:.2f}, {})-DP for all samples.'.format(eps_sgm, delta))\n",
    "  \n",
    "  return eps, delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "dxnnXmZOqqwU"
   },
   "outputs": [],
   "source": [
    "def train(noise_multiplier, \n",
    "            batch_size,\n",
    "            regularizer = 0,\n",
    "            data_l2_norm = 8,\n",
    "            dpsgd=True, learning_rate=0.01, epochs=120,  model_dir=None,\n",
    "            print_outputs = False):\n",
    "\n",
    "    if data_l2_norm <= 0:\n",
    "        raise ValueError('data_l2_norm must be positive.')\n",
    "    if dpsgd and learning_rate > 8 / data_l2_norm**2:\n",
    "        raise ValueError('The amplification-by-iteration analysis requires'\n",
    "                        'learning_rate <= 2 / beta, where beta is the smoothness'\n",
    "                        'of the loss function and is upper bounded by ||x||^2 / 4'\n",
    "                        'with ||x|| being the largest L2 norm of the samples.')\n",
    "\n",
    "    # Load training and test data.\n",
    "    # Smoothness = ||x||^2 / 4 where ||x|| is the largest L2 norm of the samples.\n",
    "    # To get bounded smoothness, we normalize the data such that each sample has a bounded L2 norm.\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(x, y, test_size = 0.2, random_state=0)\n",
    "    \n",
    "    train_data = train_data.to_numpy()\n",
    "    test_data = test_data.to_numpy()\n",
    "    train_data = normalize_data(train_data, data_l2_norm=data_l2_norm)\n",
    "    test_data = normalize_data(test_data, data_l2_norm=data_l2_norm)\n",
    "\n",
    "    # Instantiate tf.Estimator.\n",
    "    # pylint: disable=g-long-lambda\n",
    "    model_fn = lambda features, labels, mode: lr_model_fn(\n",
    "        features, labels, mode, nclasses=2, dim=train_data.shape[1:], \n",
    "        regularizer=regularizer, dpsgd=dpsgd, data_l2_norm=data_l2_norm, \n",
    "        noise_multiplier=noise_multiplier, learning_rate=learning_rate)\n",
    "    mnist_classifier = tf.estimator.Estimator(\n",
    "        model_fn=model_fn, model_dir=model_dir)\n",
    "\n",
    "    # Create tf.Estimator input functions for the training and test data.\n",
    "    # To analyze the per-user privacy loss, we keep the same orders of samples in\n",
    "    # each epoch by setting shuffle=False.\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={'x': train_data},\n",
    "        y=train_labels,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=epochs,\n",
    "        shuffle=False)\n",
    "    valid_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={'x': test_data}, y=test_labels, num_epochs=1, shuffle=False)\n",
    "\n",
    "    # Train the model.\n",
    "    num_samples = train_data.shape[0]\n",
    "    steps_per_epoch = num_samples // batch_size\n",
    "\n",
    "    mnist_classifier.train(\n",
    "        input_fn=train_input_fn, steps=steps_per_epoch * epochs)\n",
    "\n",
    "    # Evaluate the model and print results.\n",
    "    train_results = mnist_classifier.evaluate(input_fn=train_input_fn)\n",
    "    print('Train accuracy after {} epochs is: {:.2f}'.format(\n",
    "        epochs, train_results['accuracy']))\n",
    "    valid_results = mnist_classifier.evaluate(input_fn=valid_input_fn)\n",
    "    print('Test accuracy after {} epochs is: {:.2f}'.format(\n",
    "        epochs, valid_results['accuracy']))\n",
    "    if dpsgd:\n",
    "        eps_99, delta = print_privacy_guarantees(\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            samples=num_samples,\n",
    "            noise_multiplier=noise_multiplier,\n",
    "        )\n",
    "    \n",
    "    return eps_99, delta, train_results['accuracy'], valid_results['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "H7BdmdWnARYp"
   },
   "outputs": [],
   "source": [
    "def train_grid_search(noise_multipliers, \n",
    "                    batch_sizes,\n",
    "                    data_l2_norms,\n",
    "                    regularizer = 0,\n",
    "                    dpsgd=True, learning_rate=0.01, epochs=120,  model_dir=None,\n",
    "                    print_outputs = False):\n",
    "    \n",
    "    table_outputs = []\n",
    "    for batch_size in batch_sizes:\n",
    "        for data_l2_norm in data_l2_norms:\n",
    "            for noise_multiplier in noise_multipliers:\n",
    "                eps, delta, train_accuracy, valid_accuracy = train(noise_multiplier, \n",
    "                    batch_size,\n",
    "                    regularizer = regularizer,\n",
    "                    data_l2_norm = data_l2_norm,\n",
    "                    dpsgd=dpsgd, learning_rate=learning_rate, epochs=epochs,  model_dir=model_dir,\n",
    "                    print_outputs = print_outputs)\n",
    "                \n",
    "                table_outputs.append([noise_multiplier,  batch_size, regularizer, data_l2_norm, learning_rate, epochs,\n",
    "                                        train_accuracy, valid_accuracy, eps, delta])\n",
    "                 \n",
    "    df = pd.DataFrame(table_outputs, columns=['noise multiplier', 'Batch size', 'Regularizer', 'Data L2 Norm',\n",
    "                                               'learning rate', 'Epochs', \n",
    "                                                'Training accuracy','Validation accuracy', \n",
    "                                                'Epsilon', 'Delta'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OTx_3GIGseua",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "21b88db4-d81e-4429-dcd2-a272bab762aa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpfnw1k943\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpfnw1k943', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /ssd003/projects/aieng/public/pets_env/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /ssd003/projects/aieng/public/pets_env/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:65: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /ssd003/projects/aieng/public/pets_env/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-17-ee36b2d89c73>:8: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /ssd003/projects/aieng/public/pets_env/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:906: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpfnw1k943/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6853335, step = 0\n",
      "INFO:tensorflow:global_step/sec: 495.171\n",
      "INFO:tensorflow:loss = 0.5445023, step = 100 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 677.381\n",
      "INFO:tensorflow:loss = 0.6536411, step = 200 (0.147 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 240 vs previous value: 240. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 687.803\n",
      "INFO:tensorflow:loss = 0.5698772, step = 300 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.653\n",
      "INFO:tensorflow:loss = 0.67395973, step = 400 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 703.756\n",
      "INFO:tensorflow:loss = 0.50602746, step = 500 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.369\n",
      "INFO:tensorflow:loss = 0.5428991, step = 600 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 682.14\n",
      "INFO:tensorflow:loss = 0.5305296, step = 700 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 712.211\n",
      "INFO:tensorflow:loss = 0.5620422, step = 800 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 713.228\n",
      "INFO:tensorflow:loss = 0.579179, step = 900 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 682.468\n",
      "INFO:tensorflow:loss = 0.50180376, step = 1000 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.972\n",
      "INFO:tensorflow:loss = 0.65930766, step = 1100 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 717.322\n",
      "INFO:tensorflow:loss = 0.5731097, step = 1200 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.74\n",
      "INFO:tensorflow:loss = 0.5294707, step = 1300 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.605\n",
      "INFO:tensorflow:loss = 0.40167686, step = 1400 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 691.143\n",
      "INFO:tensorflow:loss = 0.5408922, step = 1500 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.308\n",
      "INFO:tensorflow:loss = 0.38457325, step = 1600 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.135\n",
      "INFO:tensorflow:loss = 0.51642156, step = 1700 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.546\n",
      "INFO:tensorflow:loss = 0.60513157, step = 1800 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.229\n",
      "INFO:tensorflow:loss = 0.4240306, step = 1900 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 706.084\n",
      "INFO:tensorflow:loss = 0.42476472, step = 2000 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 700.241\n",
      "INFO:tensorflow:loss = 0.44291773, step = 2100 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.334\n",
      "INFO:tensorflow:loss = 0.65453696, step = 2200 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.273\n",
      "INFO:tensorflow:loss = 0.59236103, step = 2300 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.983\n",
      "INFO:tensorflow:loss = 0.61754555, step = 2400 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 687.183\n",
      "INFO:tensorflow:loss = 0.36023843, step = 2500 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.659\n",
      "INFO:tensorflow:loss = 0.48036492, step = 2600 (0.143 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2640...\n",
      "INFO:tensorflow:Saving checkpoints for 2640 into /tmp/tmpfnw1k943/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2640...\n",
      "INFO:tensorflow:Loss for final step: 0.44694665.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:00Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpfnw1k943/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 2.32361s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.7933884, global_step = 2640, loss = 0.47530967\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmpfnw1k943/model.ckpt-2640\n",
      "Train accuracy after 120 epochs is: 0.79\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:03Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpfnw1k943/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.29152s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:03\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.78688526, global_step = 2640, loss = 0.45458195\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmpfnw1k943/model.ckpt-2640\n",
      "Test accuracy after 120 epochs is: 0.79\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (1.09, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (1.12, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (1.19, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (1.19, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (13.55, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpb6yr3tic\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpb6yr3tic', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpb6yr3tic/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.73094404, step = 0\n",
      "INFO:tensorflow:global_step/sec: 485.006\n",
      "INFO:tensorflow:loss = 1.1049322, step = 100 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 698.753\n",
      "INFO:tensorflow:loss = 0.5955889, step = 200 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 702.749\n",
      "INFO:tensorflow:loss = 0.5538899, step = 300 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 703.325\n",
      "INFO:tensorflow:loss = 0.7237475, step = 400 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 706.162\n",
      "INFO:tensorflow:loss = 0.74909455, step = 500 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 717.37\n",
      "INFO:tensorflow:loss = 0.53784794, step = 600 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.808\n",
      "INFO:tensorflow:loss = 0.607441, step = 700 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 693.343\n",
      "INFO:tensorflow:loss = 0.49631035, step = 800 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.719\n",
      "INFO:tensorflow:loss = 0.40592393, step = 900 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 696.179\n",
      "INFO:tensorflow:loss = 0.46843585, step = 1000 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 712.283\n",
      "INFO:tensorflow:loss = 0.6870412, step = 1100 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 696.922\n",
      "INFO:tensorflow:loss = 0.6577391, step = 1200 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 706.264\n",
      "INFO:tensorflow:loss = 0.43362963, step = 1300 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.509\n",
      "INFO:tensorflow:loss = 0.5575562, step = 1400 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.118\n",
      "INFO:tensorflow:loss = 0.80256087, step = 1500 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 698.524\n",
      "INFO:tensorflow:loss = 0.449833, step = 1600 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 694.548\n",
      "INFO:tensorflow:loss = 0.73858315, step = 1700 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.132\n",
      "INFO:tensorflow:loss = 0.50846076, step = 1800 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.96\n",
      "INFO:tensorflow:loss = 0.43605396, step = 1900 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 696.108\n",
      "INFO:tensorflow:loss = 0.4036442, step = 2000 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.704\n",
      "INFO:tensorflow:loss = 0.44812724, step = 2100 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 691.627\n",
      "INFO:tensorflow:loss = 0.8029123, step = 2200 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.637\n",
      "INFO:tensorflow:loss = 0.5252039, step = 2300 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 712.241\n",
      "INFO:tensorflow:loss = 0.2685134, step = 2400 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 686.683\n",
      "INFO:tensorflow:loss = 0.4530923, step = 2500 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 732.503\n",
      "INFO:tensorflow:loss = 0.84409946, step = 2600 (0.136 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2640...\n",
      "INFO:tensorflow:Saving checkpoints for 2640 into /tmp/tmpb6yr3tic/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2640...\n",
      "INFO:tensorflow:Loss for final step: 0.9667043.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:08Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpb6yr3tic/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 2.28716s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:10\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.677686, global_step = 2640, loss = 0.72632\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmpb6yr3tic/model.ckpt-2640\n",
      "Train accuracy after 120 epochs is: 0.68\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpb6yr3tic/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.13625s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:10\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.704918, global_step = 2640, loss = 0.6189814\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmpb6yr3tic/model.ckpt-2640\n",
      "Test accuracy after 120 epochs is: 0.70\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.47, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.48, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.51, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.51, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (4.15, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp3kpotsht\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp3kpotsht', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp3kpotsht/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6962488, step = 0\n",
      "INFO:tensorflow:global_step/sec: 494.143\n",
      "INFO:tensorflow:loss = 0.6379157, step = 100 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.098\n",
      "INFO:tensorflow:loss = 0.74001527, step = 200 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.343\n",
      "INFO:tensorflow:loss = 0.53398514, step = 300 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.56\n",
      "INFO:tensorflow:loss = 0.78381115, step = 400 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 713.518\n",
      "INFO:tensorflow:loss = 0.62701946, step = 500 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 682.761\n",
      "INFO:tensorflow:loss = 0.6450212, step = 600 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.75\n",
      "INFO:tensorflow:loss = 0.4123101, step = 700 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 711.252\n",
      "INFO:tensorflow:loss = 0.4111126, step = 800 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.845\n",
      "INFO:tensorflow:loss = 0.56898123, step = 900 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 688.112\n",
      "INFO:tensorflow:loss = 0.48602626, step = 1000 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 706.801\n",
      "INFO:tensorflow:loss = 0.75195956, step = 1100 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 691.862\n",
      "INFO:tensorflow:loss = 0.7909897, step = 1200 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.047\n",
      "INFO:tensorflow:loss = 0.3053188, step = 1300 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.203\n",
      "INFO:tensorflow:loss = 0.3665241, step = 1400 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 694.091\n",
      "INFO:tensorflow:loss = 1.289291, step = 1500 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 700.365\n",
      "INFO:tensorflow:loss = 0.15706615, step = 1600 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.834\n",
      "INFO:tensorflow:loss = 0.69329584, step = 1700 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 693.299\n",
      "INFO:tensorflow:loss = 0.5070896, step = 1800 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.308\n",
      "INFO:tensorflow:loss = 0.32575682, step = 1900 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.397\n",
      "INFO:tensorflow:loss = 0.51166344, step = 2000 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 692.757\n",
      "INFO:tensorflow:loss = 0.4108117, step = 2100 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.737\n",
      "INFO:tensorflow:loss = 1.0012231, step = 2200 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.952\n",
      "INFO:tensorflow:loss = 0.55533624, step = 2300 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.574\n",
      "INFO:tensorflow:loss = 0.76809275, step = 2400 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.236\n",
      "INFO:tensorflow:loss = 0.29878208, step = 2500 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 731.022\n",
      "INFO:tensorflow:loss = 1.0736684, step = 2600 (0.137 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2640...\n",
      "INFO:tensorflow:Saving checkpoints for 2640 into /tmp/tmp3kpotsht/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2640...\n",
      "INFO:tensorflow:Loss for final step: 0.33106205.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:15Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp3kpotsht/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 2.27603s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:17\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.76859504, global_step = 2640, loss = 0.547789\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmp3kpotsht/model.ckpt-2640\n",
      "Train accuracy after 120 epochs is: 0.77\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp3kpotsht/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.13598s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:17\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.72131145, global_step = 2640, loss = 0.6649104\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmp3kpotsht/model.ckpt-2640\n",
      "Test accuracy after 120 epochs is: 0.72\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.28, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.29, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.31, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.31, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (2.38, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp2witc5il\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp2witc5il', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp2witc5il/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.77335906, step = 0\n",
      "INFO:tensorflow:global_step/sec: 494.295\n",
      "INFO:tensorflow:loss = 0.96143174, step = 100 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.134\n",
      "INFO:tensorflow:loss = 1.8684238, step = 200 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 682.196\n",
      "INFO:tensorflow:loss = 0.93919444, step = 300 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.009\n",
      "INFO:tensorflow:loss = 0.95993686, step = 400 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 695.678\n",
      "INFO:tensorflow:loss = 0.77512795, step = 500 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.826\n",
      "INFO:tensorflow:loss = 1.1618716, step = 600 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 688.209\n",
      "INFO:tensorflow:loss = 1.1357383, step = 700 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.234\n",
      "INFO:tensorflow:loss = 0.6751342, step = 800 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.581\n",
      "INFO:tensorflow:loss = 1.1521062, step = 900 (0.144 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 994 vs previous value: 994. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 690.023\n",
      "INFO:tensorflow:loss = 0.9012432, step = 1000 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 687.637\n",
      "INFO:tensorflow:loss = 0.5351868, step = 1100 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.603\n",
      "INFO:tensorflow:loss = 1.2357628, step = 1200 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 700.144\n",
      "INFO:tensorflow:loss = 1.4935372, step = 1300 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.062\n",
      "INFO:tensorflow:loss = 1.6676732, step = 1400 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.839\n",
      "INFO:tensorflow:loss = 0.96260834, step = 1500 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 698.907\n",
      "INFO:tensorflow:loss = 1.951542, step = 1600 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.534\n",
      "INFO:tensorflow:loss = 1.5089988, step = 1700 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 703.577\n",
      "INFO:tensorflow:loss = 1.8071961, step = 1800 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 693.144\n",
      "INFO:tensorflow:loss = 0.9208982, step = 1900 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 696.858\n",
      "INFO:tensorflow:loss = 0.46472836, step = 2000 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.692\n",
      "INFO:tensorflow:loss = 1.2489247, step = 2100 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.889\n",
      "INFO:tensorflow:loss = 0.73508835, step = 2200 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.91\n",
      "INFO:tensorflow:loss = 1.5251247, step = 2300 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 686.131\n",
      "INFO:tensorflow:loss = 3.0996625, step = 2400 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 702.356\n",
      "INFO:tensorflow:loss = 1.9719138, step = 2500 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 726.325\n",
      "INFO:tensorflow:loss = 0.88563675, step = 2600 (0.139 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2640...\n",
      "INFO:tensorflow:Saving checkpoints for 2640 into /tmp/tmp2witc5il/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2640...\n",
      "INFO:tensorflow:Loss for final step: 1.7069618.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp2witc5il/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 2.28523s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:24\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.5082645, global_step = 2640, loss = 1.2011675\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmp2witc5il/model.ckpt-2640\n",
      "Train accuracy after 120 epochs is: 0.51\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp2witc5il/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.14269s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:24\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.37704918, global_step = 2640, loss = 1.2897637\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmp2witc5il/model.ckpt-2640\n",
      "Test accuracy after 120 epochs is: 0.38\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.15, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.15, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (1.24, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmprdv1xs8z\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmprdv1xs8z', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmprdv1xs8z/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.64397603, step = 0\n",
      "INFO:tensorflow:global_step/sec: 489.589\n",
      "INFO:tensorflow:loss = 0.7864673, step = 100 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 711.28\n",
      "INFO:tensorflow:loss = 0.88839775, step = 200 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.299\n",
      "INFO:tensorflow:loss = 0.6435593, step = 300 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 715.572\n",
      "INFO:tensorflow:loss = 0.63046604, step = 400 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 711.381\n",
      "INFO:tensorflow:loss = 0.45886308, step = 500 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 707.761\n",
      "INFO:tensorflow:loss = 0.519118, step = 600 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.223\n",
      "INFO:tensorflow:loss = 0.45448437, step = 700 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 702.105\n",
      "INFO:tensorflow:loss = 0.6598245, step = 800 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 691.768\n",
      "INFO:tensorflow:loss = 0.5731095, step = 900 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 707.088\n",
      "INFO:tensorflow:loss = 0.69245744, step = 1000 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.09\n",
      "INFO:tensorflow:loss = 0.5972404, step = 1100 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 696.961\n",
      "INFO:tensorflow:loss = 0.6545294, step = 1200 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 700.964\n",
      "INFO:tensorflow:loss = 0.7497009, step = 1300 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.956\n",
      "INFO:tensorflow:loss = 0.5846326, step = 1400 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 702.802\n",
      "INFO:tensorflow:loss = 0.7534849, step = 1500 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 716.572\n",
      "INFO:tensorflow:loss = 0.35355413, step = 1600 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 698.906\n",
      "INFO:tensorflow:loss = 0.6313818, step = 1700 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 706.519\n",
      "INFO:tensorflow:loss = 0.44821614, step = 1800 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 717.779\n",
      "INFO:tensorflow:loss = 0.47223586, step = 1900 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.913\n",
      "INFO:tensorflow:loss = 0.39949754, step = 2000 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.499\n",
      "INFO:tensorflow:loss = 0.7493706, step = 2100 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 713.455\n",
      "INFO:tensorflow:loss = 0.6302464, step = 2200 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.36\n",
      "INFO:tensorflow:loss = 0.7106236, step = 2300 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.372\n",
      "INFO:tensorflow:loss = 0.7856188, step = 2400 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 702.605\n",
      "INFO:tensorflow:loss = 0.35037395, step = 2500 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 721.617\n",
      "INFO:tensorflow:loss = 0.9473362, step = 2600 (0.139 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2640...\n",
      "INFO:tensorflow:Saving checkpoints for 2640 into /tmp/tmprdv1xs8z/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2640...\n",
      "INFO:tensorflow:Loss for final step: 0.47529462.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:29Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmprdv1xs8z/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 2.28016s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:31\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.7231405, global_step = 2640, loss = 0.58745444\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmprdv1xs8z/model.ckpt-2640\n",
      "Train accuracy after 120 epochs is: 0.72\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:31Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmprdv1xs8z/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.14953s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:31\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.72131145, global_step = 2640, loss = 0.6406707\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmprdv1xs8z/model.ckpt-2640\n",
      "Test accuracy after 120 epochs is: 0.72\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (1.09, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (1.12, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (1.19, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (1.19, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (13.55, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpamphma2v\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpamphma2v', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpamphma2v/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.5717535, step = 0\n",
      "INFO:tensorflow:global_step/sec: 493.153\n",
      "INFO:tensorflow:loss = 0.5113072, step = 100 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 725.16\n",
      "INFO:tensorflow:loss = 0.4570653, step = 200 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.827\n",
      "INFO:tensorflow:loss = 0.37372875, step = 300 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 709.149\n",
      "INFO:tensorflow:loss = 0.7192414, step = 400 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 700.854\n",
      "INFO:tensorflow:loss = 0.37814102, step = 500 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 718.8\n",
      "INFO:tensorflow:loss = 0.4713237, step = 600 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 709.25\n",
      "INFO:tensorflow:loss = 0.40251368, step = 700 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.012\n",
      "INFO:tensorflow:loss = 0.5025211, step = 800 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.469\n",
      "INFO:tensorflow:loss = 0.34828722, step = 900 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.383\n",
      "INFO:tensorflow:loss = 0.651068, step = 1000 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.705\n",
      "INFO:tensorflow:loss = 0.69960004, step = 1100 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.593\n",
      "INFO:tensorflow:loss = 0.6285667, step = 1200 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 663.598\n",
      "INFO:tensorflow:loss = 0.7627781, step = 1300 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 715.714\n",
      "INFO:tensorflow:loss = 0.41998804, step = 1400 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 715.451\n",
      "INFO:tensorflow:loss = 0.72351974, step = 1500 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 706.105\n",
      "INFO:tensorflow:loss = 0.47384855, step = 1600 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 721.552\n",
      "INFO:tensorflow:loss = 1.0422882, step = 1700 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 692.868\n",
      "INFO:tensorflow:loss = 0.47145593, step = 1800 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 696.137\n",
      "INFO:tensorflow:loss = 0.38299084, step = 1900 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.147\n",
      "INFO:tensorflow:loss = 0.6053558, step = 2000 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.981\n",
      "INFO:tensorflow:loss = 0.5820141, step = 2100 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.475\n",
      "INFO:tensorflow:loss = 0.6962936, step = 2200 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.346\n",
      "INFO:tensorflow:loss = 0.84493446, step = 2300 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.797\n",
      "INFO:tensorflow:loss = 0.718632, step = 2400 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 709.551\n",
      "INFO:tensorflow:loss = 0.457108, step = 2500 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 722.583\n",
      "INFO:tensorflow:loss = 0.7979674, step = 2600 (0.138 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2640...\n",
      "INFO:tensorflow:Saving checkpoints for 2640 into /tmp/tmpamphma2v/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2640...\n",
      "INFO:tensorflow:Loss for final step: 0.3695836.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:36Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpamphma2v/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 2.29242s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:38\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.7644628, global_step = 2640, loss = 0.52188677\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmpamphma2v/model.ckpt-2640\n",
      "Train accuracy after 120 epochs is: 0.76\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:38Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpamphma2v/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.13397s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:38\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.72131145, global_step = 2640, loss = 0.52546173\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmpamphma2v/model.ckpt-2640\n",
      "Test accuracy after 120 epochs is: 0.72\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.47, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.48, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.51, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.51, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (4.15, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpu7pfxxny\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpu7pfxxny', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpu7pfxxny/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.7207922, step = 0\n",
      "INFO:tensorflow:global_step/sec: 493.358\n",
      "INFO:tensorflow:loss = 0.81017494, step = 100 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.625\n",
      "INFO:tensorflow:loss = 1.2046924, step = 200 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.244\n",
      "INFO:tensorflow:loss = 1.3655323, step = 300 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.672\n",
      "INFO:tensorflow:loss = 0.70951134, step = 400 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.35\n",
      "INFO:tensorflow:loss = 0.5185122, step = 500 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.155\n",
      "INFO:tensorflow:loss = 0.44083786, step = 600 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.975\n",
      "INFO:tensorflow:loss = 0.6072329, step = 700 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.357\n",
      "INFO:tensorflow:loss = 1.2680664, step = 800 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 706.566\n",
      "INFO:tensorflow:loss = 0.88640004, step = 900 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.476\n",
      "INFO:tensorflow:loss = 1.630489, step = 1000 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.447\n",
      "INFO:tensorflow:loss = 0.86935806, step = 1100 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 709.845\n",
      "INFO:tensorflow:loss = 0.5912005, step = 1200 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.92\n",
      "INFO:tensorflow:loss = 0.88276654, step = 1300 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.651\n",
      "INFO:tensorflow:loss = 1.1291283, step = 1400 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 712.391\n",
      "INFO:tensorflow:loss = 1.1117253, step = 1500 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.208\n",
      "INFO:tensorflow:loss = 0.5053169, step = 1600 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 703.384\n",
      "INFO:tensorflow:loss = 1.336563, step = 1700 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.182\n",
      "INFO:tensorflow:loss = 0.7835357, step = 1800 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.607\n",
      "INFO:tensorflow:loss = 0.7727423, step = 1900 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 687.898\n",
      "INFO:tensorflow:loss = 0.8357319, step = 2000 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 686.131\n",
      "INFO:tensorflow:loss = 0.8657738, step = 2100 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.494\n",
      "INFO:tensorflow:loss = 0.7211338, step = 2200 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.793\n",
      "INFO:tensorflow:loss = 1.0392665, step = 2300 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.785\n",
      "INFO:tensorflow:loss = 1.2404238, step = 2400 (0.142 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2483 vs previous value: 2483. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 688.564\n",
      "INFO:tensorflow:loss = 0.8613077, step = 2500 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 718.128\n",
      "INFO:tensorflow:loss = 0.9839369, step = 2600 (0.138 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2640...\n",
      "INFO:tensorflow:Saving checkpoints for 2640 into /tmp/tmpu7pfxxny/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2640...\n",
      "INFO:tensorflow:Loss for final step: 0.2801769.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpu7pfxxny/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 2.29129s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:45\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.6818182, global_step = 2640, loss = 0.6262891\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmpu7pfxxny/model.ckpt-2640\n",
      "Train accuracy after 120 epochs is: 0.68\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:45Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpu7pfxxny/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.14318s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:45\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.59016395, global_step = 2640, loss = 0.8267628\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmpu7pfxxny/model.ckpt-2640\n",
      "Test accuracy after 120 epochs is: 0.59\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.28, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.29, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.31, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.31, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (2.38, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_k5c7amn\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_k5c7amn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp_k5c7amn/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6262126, step = 0\n",
      "INFO:tensorflow:global_step/sec: 468.407\n",
      "INFO:tensorflow:loss = 1.283696, step = 100 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.634\n",
      "INFO:tensorflow:loss = 0.97435707, step = 200 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.75\n",
      "INFO:tensorflow:loss = 1.446644, step = 300 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 709.648\n",
      "INFO:tensorflow:loss = 0.977286, step = 400 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.213\n",
      "INFO:tensorflow:loss = 0.6944612, step = 500 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 693.11\n",
      "INFO:tensorflow:loss = 0.49372196, step = 600 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.74\n",
      "INFO:tensorflow:loss = 0.842956, step = 700 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 693.791\n",
      "INFO:tensorflow:loss = 0.27815276, step = 800 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 696.154\n",
      "INFO:tensorflow:loss = 0.5141123, step = 900 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 686.455\n",
      "INFO:tensorflow:loss = 1.092078, step = 1000 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 688.842\n",
      "INFO:tensorflow:loss = 1.9175099, step = 1100 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 688.788\n",
      "INFO:tensorflow:loss = 3.1784403, step = 1200 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.442\n",
      "INFO:tensorflow:loss = 0.894319, step = 1300 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 693.379\n",
      "INFO:tensorflow:loss = 0.45325276, step = 1400 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 695.804\n",
      "INFO:tensorflow:loss = 1.8288391, step = 1500 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.602\n",
      "INFO:tensorflow:loss = 0.6953922, step = 1600 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 698.186\n",
      "INFO:tensorflow:loss = 0.7749405, step = 1700 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.13\n",
      "INFO:tensorflow:loss = 0.8177238, step = 1800 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.173\n",
      "INFO:tensorflow:loss = 1.6759071, step = 1900 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 703.075\n",
      "INFO:tensorflow:loss = 1.5810478, step = 2000 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 700.658\n",
      "INFO:tensorflow:loss = 1.6312279, step = 2100 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.32\n",
      "INFO:tensorflow:loss = 1.658904, step = 2200 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.852\n",
      "INFO:tensorflow:loss = 1.475731, step = 2300 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 702.658\n",
      "INFO:tensorflow:loss = 0.96731544, step = 2400 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 720.917\n",
      "INFO:tensorflow:loss = 0.88071936, step = 2500 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 721.351\n",
      "INFO:tensorflow:loss = 1.7540104, step = 2600 (0.139 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2640...\n",
      "INFO:tensorflow:Saving checkpoints for 2640 into /tmp/tmp_k5c7amn/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2640...\n",
      "INFO:tensorflow:Loss for final step: 1.6192268.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp_k5c7amn/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 2.28741s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:52\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.5, global_step = 2640, loss = 1.469002\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmp_k5c7amn/model.ckpt-2640\n",
      "Train accuracy after 120 epochs is: 0.50\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:52Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp_k5c7amn/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.13905s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:52\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.40983605, global_step = 2640, loss = 1.9098368\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmp_k5c7amn/model.ckpt-2640\n",
      "Test accuracy after 120 epochs is: 0.41\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.15, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.15, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (1.24, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp92a5po83\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp92a5po83', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp92a5po83/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.72372174, step = 0\n",
      "INFO:tensorflow:global_step/sec: 472.158\n",
      "INFO:tensorflow:loss = 0.7037232, step = 100 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.678\n",
      "INFO:tensorflow:loss = 0.5700333, step = 200 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.743\n",
      "INFO:tensorflow:loss = 0.67431694, step = 300 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 700.408\n",
      "INFO:tensorflow:loss = 0.6862142, step = 400 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 686.121\n",
      "INFO:tensorflow:loss = 0.42363393, step = 500 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 700.098\n",
      "INFO:tensorflow:loss = 0.58812386, step = 600 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 717.822\n",
      "INFO:tensorflow:loss = 0.45754477, step = 700 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 706.925\n",
      "INFO:tensorflow:loss = 0.47876826, step = 800 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.835\n",
      "INFO:tensorflow:loss = 0.49028704, step = 900 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 706.628\n",
      "INFO:tensorflow:loss = 0.59870106, step = 1000 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.156\n",
      "INFO:tensorflow:loss = 0.6436843, step = 1100 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 698.543\n",
      "INFO:tensorflow:loss = 0.43374053, step = 1200 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.042\n",
      "INFO:tensorflow:loss = 0.48118323, step = 1300 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.716\n",
      "INFO:tensorflow:loss = 0.5483866, step = 1400 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 709.03\n",
      "INFO:tensorflow:loss = 0.7497864, step = 1500 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.828\n",
      "INFO:tensorflow:loss = 0.46886796, step = 1600 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 712.474\n",
      "INFO:tensorflow:loss = 0.7696197, step = 1700 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.38\n",
      "INFO:tensorflow:loss = 0.5487419, step = 1800 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.577\n",
      "INFO:tensorflow:loss = 0.20803833, step = 1900 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 716.703\n",
      "INFO:tensorflow:loss = 0.5566814, step = 2000 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 703.113\n",
      "INFO:tensorflow:loss = 0.6845534, step = 2100 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.105\n",
      "INFO:tensorflow:loss = 0.9357733, step = 2200 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 715.534\n",
      "INFO:tensorflow:loss = 0.36339027, step = 2300 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.254\n",
      "INFO:tensorflow:loss = 0.4725336, step = 2400 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 711.95\n",
      "INFO:tensorflow:loss = 0.24760814, step = 2500 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 721.912\n",
      "INFO:tensorflow:loss = 0.8890917, step = 2600 (0.139 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2640...\n",
      "INFO:tensorflow:Saving checkpoints for 2640 into /tmp/tmp92a5po83/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2640...\n",
      "INFO:tensorflow:Loss for final step: 0.58205295.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:57Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp92a5po83/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 2.30340s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:59\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.73966944, global_step = 2640, loss = 0.52182883\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmp92a5po83/model.ckpt-2640\n",
      "Train accuracy after 120 epochs is: 0.74\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:20:59Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp92a5po83/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.14774s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:20:59\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.78688526, global_step = 2640, loss = 0.40443096\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmp92a5po83/model.ckpt-2640\n",
      "Test accuracy after 120 epochs is: 0.79\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (1.09, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (1.12, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (1.19, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (1.19, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (13.55, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmphur5qpv0\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmphur5qpv0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmphur5qpv0/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6327013, step = 0\n",
      "INFO:tensorflow:global_step/sec: 489.691\n",
      "INFO:tensorflow:loss = 0.6302971, step = 100 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.482\n",
      "INFO:tensorflow:loss = 0.552417, step = 200 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.522\n",
      "INFO:tensorflow:loss = 0.47631627, step = 300 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.481\n",
      "INFO:tensorflow:loss = 0.8418375, step = 400 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 711.712\n",
      "INFO:tensorflow:loss = 0.42885703, step = 500 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 717.399\n",
      "INFO:tensorflow:loss = 0.5640999, step = 600 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.077\n",
      "INFO:tensorflow:loss = 0.68268144, step = 700 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.849\n",
      "INFO:tensorflow:loss = 0.74748385, step = 800 (0.141 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 862 vs previous value: 862. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 695.003\n",
      "INFO:tensorflow:loss = 0.6179736, step = 900 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.903\n",
      "INFO:tensorflow:loss = 0.5204399, step = 1000 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.3\n",
      "INFO:tensorflow:loss = 0.6705028, step = 1100 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.109\n",
      "INFO:tensorflow:loss = 1.0551392, step = 1200 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.196\n",
      "INFO:tensorflow:loss = 0.7908442, step = 1300 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 698.515\n",
      "INFO:tensorflow:loss = 0.7574915, step = 1400 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.363\n",
      "INFO:tensorflow:loss = 1.2224438, step = 1500 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 692.965\n",
      "INFO:tensorflow:loss = 0.92311376, step = 1600 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.336\n",
      "INFO:tensorflow:loss = 0.5559246, step = 1700 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 695.884\n",
      "INFO:tensorflow:loss = 0.6951297, step = 1800 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.646\n",
      "INFO:tensorflow:loss = 0.31883305, step = 1900 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.291\n",
      "INFO:tensorflow:loss = 0.16478254, step = 2000 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.995\n",
      "INFO:tensorflow:loss = 0.65037286, step = 2100 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 694.8\n",
      "INFO:tensorflow:loss = 0.8889061, step = 2200 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.288\n",
      "INFO:tensorflow:loss = 0.59120595, step = 2300 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 721.698\n",
      "INFO:tensorflow:loss = 0.60234314, step = 2400 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.64\n",
      "INFO:tensorflow:loss = 0.412978, step = 2500 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 721.668\n",
      "INFO:tensorflow:loss = 1.4708557, step = 2600 (0.137 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2640...\n",
      "INFO:tensorflow:Saving checkpoints for 2640 into /tmp/tmphur5qpv0/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2640...\n",
      "INFO:tensorflow:Loss for final step: 0.4310052.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmphur5qpv0/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 2.29445s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:06\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.79752064, global_step = 2640, loss = 0.56843233\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmphur5qpv0/model.ckpt-2640\n",
      "Train accuracy after 120 epochs is: 0.80\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:06Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmphur5qpv0/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.15344s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:07\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.8032787, global_step = 2640, loss = 0.5414001\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmphur5qpv0/model.ckpt-2640\n",
      "Test accuracy after 120 epochs is: 0.80\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.47, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.48, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.51, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.51, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (4.15, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpnk86yrd0\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpnk86yrd0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpnk86yrd0/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.8196425, step = 0\n",
      "INFO:tensorflow:global_step/sec: 456.819\n",
      "INFO:tensorflow:loss = 0.6825531, step = 100 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.126\n",
      "INFO:tensorflow:loss = 0.8934881, step = 200 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.379\n",
      "INFO:tensorflow:loss = 1.2918302, step = 300 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.057\n",
      "INFO:tensorflow:loss = 1.5574183, step = 400 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.26\n",
      "INFO:tensorflow:loss = 0.93533516, step = 500 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 674.734\n",
      "INFO:tensorflow:loss = 0.8285685, step = 600 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 693.191\n",
      "INFO:tensorflow:loss = 1.0610842, step = 700 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.867\n",
      "INFO:tensorflow:loss = 1.4793597, step = 800 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 694.242\n",
      "INFO:tensorflow:loss = 1.6769669, step = 900 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.854\n",
      "INFO:tensorflow:loss = 0.7774311, step = 1000 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.217\n",
      "INFO:tensorflow:loss = 1.1945591, step = 1100 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 674.416\n",
      "INFO:tensorflow:loss = 1.1802306, step = 1200 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.431\n",
      "INFO:tensorflow:loss = 1.6597272, step = 1300 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.182\n",
      "INFO:tensorflow:loss = 0.70228857, step = 1400 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.196\n",
      "INFO:tensorflow:loss = 2.038186, step = 1500 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.009\n",
      "INFO:tensorflow:loss = 0.18721694, step = 1600 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.454\n",
      "INFO:tensorflow:loss = 1.1616848, step = 1700 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.32\n",
      "INFO:tensorflow:loss = 1.1309186, step = 1800 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.82\n",
      "INFO:tensorflow:loss = 1.1207078, step = 1900 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.904\n",
      "INFO:tensorflow:loss = 1.1290996, step = 2000 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 657.679\n",
      "INFO:tensorflow:loss = 1.4096329, step = 2100 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.567\n",
      "INFO:tensorflow:loss = 1.5763736, step = 2200 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.828\n",
      "INFO:tensorflow:loss = 0.98238176, step = 2300 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.358\n",
      "INFO:tensorflow:loss = 2.1621728, step = 2400 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 633.245\n",
      "INFO:tensorflow:loss = 0.30850878, step = 2500 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.785\n",
      "INFO:tensorflow:loss = 1.434244, step = 2600 (0.154 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2640...\n",
      "INFO:tensorflow:Saving checkpoints for 2640 into /tmp/tmpnk86yrd0/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2640...\n",
      "INFO:tensorflow:Loss for final step: 1.7809358.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:11Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpnk86yrd0/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 2.39068s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:14\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.6983471, global_step = 2640, loss = 1.1532714\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmpnk86yrd0/model.ckpt-2640\n",
      "Train accuracy after 120 epochs is: 0.70\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:14Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpnk86yrd0/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.16113s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:14\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.73770493, global_step = 2640, loss = 0.897467\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmpnk86yrd0/model.ckpt-2640\n",
      "Test accuracy after 120 epochs is: 0.74\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.28, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.29, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.31, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.31, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (2.38, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpt_npd8tl\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpt_npd8tl', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpt_npd8tl/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6513462, step = 0\n",
      "INFO:tensorflow:global_step/sec: 464.06\n",
      "INFO:tensorflow:loss = 1.3185124, step = 100 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 674.351\n",
      "INFO:tensorflow:loss = 1.2212464, step = 200 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.154\n",
      "INFO:tensorflow:loss = 0.29473552, step = 300 (0.148 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 395 vs previous value: 395. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 654.044\n",
      "INFO:tensorflow:loss = 1.1814052, step = 400 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.61\n",
      "INFO:tensorflow:loss = 2.116695, step = 500 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.111\n",
      "INFO:tensorflow:loss = 2.4768233, step = 600 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.143\n",
      "INFO:tensorflow:loss = 0.81170374, step = 700 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.166\n",
      "INFO:tensorflow:loss = 0.7032657, step = 800 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.559\n",
      "INFO:tensorflow:loss = 0.42274973, step = 900 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.122\n",
      "INFO:tensorflow:loss = 1.3627926, step = 1000 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.845\n",
      "INFO:tensorflow:loss = 1.2720864, step = 1100 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.576\n",
      "INFO:tensorflow:loss = 1.2344053, step = 1200 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.823\n",
      "INFO:tensorflow:loss = 1.0857759, step = 1300 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.163\n",
      "INFO:tensorflow:loss = 0.5843765, step = 1400 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 674.176\n",
      "INFO:tensorflow:loss = 1.3969876, step = 1500 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.416\n",
      "INFO:tensorflow:loss = 0.9882017, step = 1600 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.569\n",
      "INFO:tensorflow:loss = 0.87183017, step = 1700 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.392\n",
      "INFO:tensorflow:loss = 0.7609901, step = 1800 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.896\n",
      "INFO:tensorflow:loss = 0.49485648, step = 1900 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.545\n",
      "INFO:tensorflow:loss = 0.79608893, step = 2000 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.586\n",
      "INFO:tensorflow:loss = 1.5628083, step = 2100 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 657.449\n",
      "INFO:tensorflow:loss = 1.2510871, step = 2200 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 674.591\n",
      "INFO:tensorflow:loss = 1.879519, step = 2300 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 677.733\n",
      "INFO:tensorflow:loss = 3.500129, step = 2400 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.58\n",
      "INFO:tensorflow:loss = 1.0193911, step = 2500 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 682.012\n",
      "INFO:tensorflow:loss = 2.1188138, step = 2600 (0.148 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2640...\n",
      "INFO:tensorflow:Saving checkpoints for 2640 into /tmp/tmpt_npd8tl/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2640...\n",
      "INFO:tensorflow:Loss for final step: 0.11752016.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:19Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpt_npd8tl/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 2.37788s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:21\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.6983471, global_step = 2640, loss = 1.0690134\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmpt_npd8tl/model.ckpt-2640\n",
      "Train accuracy after 120 epochs is: 0.70\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpt_npd8tl/model.ckpt-2640\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.17226s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:22\n",
      "INFO:tensorflow:Saving dict for global step 2640: accuracy = 0.6229508, global_step = 2640, loss = 1.26842\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2640: /tmp/tmpt_npd8tl/model.ckpt-2640\n",
      "Test accuracy after 120 epochs is: 0.62\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.15, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.15, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (1.24, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpflie1am0\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpflie1am0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpflie1am0/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.66797787, step = 0\n",
      "INFO:tensorflow:global_step/sec: 468.332\n",
      "INFO:tensorflow:loss = 0.61915374, step = 100 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.214\n",
      "INFO:tensorflow:loss = 0.6322937, step = 200 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.823\n",
      "INFO:tensorflow:loss = 0.61238766, step = 300 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 679.109\n",
      "INFO:tensorflow:loss = 0.53869504, step = 400 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.272\n",
      "INFO:tensorflow:loss = 0.6210742, step = 500 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.944\n",
      "INFO:tensorflow:loss = 0.6177828, step = 600 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.056\n",
      "INFO:tensorflow:loss = 0.60831827, step = 700 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.014\n",
      "INFO:tensorflow:loss = 0.5961901, step = 800 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.869\n",
      "INFO:tensorflow:loss = 0.61431885, step = 900 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.36\n",
      "INFO:tensorflow:loss = 0.5796732, step = 1000 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.588\n",
      "INFO:tensorflow:loss = 0.6342646, step = 1100 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.339\n",
      "INFO:tensorflow:loss = 0.62277085, step = 1200 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.278\n",
      "INFO:tensorflow:loss = 0.63469625, step = 1300 (0.157 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1320...\n",
      "INFO:tensorflow:Saving checkpoints for 1320 into /tmp/tmpflie1am0/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1320...\n",
      "INFO:tensorflow:Loss for final step: 0.6578494.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpflie1am0/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.29936s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:26\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.7066116, global_step = 1320, loss = 0.6032687\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmpflie1am0/model.ckpt-1320\n",
      "Train accuracy after 120 epochs is: 0.71\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:26Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpflie1am0/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.15742s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:26\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.7704918, global_step = 1320, loss = 0.5824914\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmpflie1am0/model.ckpt-1320\n",
      "Test accuracy after 120 epochs is: 0.77\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.71, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.73, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.74, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.74, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (22.81, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmptcbqokll\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmptcbqokll', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmptcbqokll/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.70232904, step = 0\n",
      "INFO:tensorflow:global_step/sec: 483.339\n",
      "INFO:tensorflow:loss = 0.74339867, step = 100 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.073\n",
      "INFO:tensorflow:loss = 0.62305003, step = 200 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 668.793\n",
      "INFO:tensorflow:loss = 0.5831195, step = 300 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.157\n",
      "INFO:tensorflow:loss = 0.75597787, step = 400 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 668.918\n",
      "INFO:tensorflow:loss = 0.50982195, step = 500 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.788\n",
      "INFO:tensorflow:loss = 0.5410365, step = 600 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.24\n",
      "INFO:tensorflow:loss = 0.48728517, step = 700 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.963\n",
      "INFO:tensorflow:loss = 0.4335475, step = 800 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.349\n",
      "INFO:tensorflow:loss = 0.70535284, step = 900 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.078\n",
      "INFO:tensorflow:loss = 0.5820862, step = 1000 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.875\n",
      "INFO:tensorflow:loss = 0.7375235, step = 1100 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 634.921\n",
      "INFO:tensorflow:loss = 0.7989626, step = 1200 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 604.164\n",
      "INFO:tensorflow:loss = 0.81623286, step = 1300 (0.167 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1320...\n",
      "INFO:tensorflow:Saving checkpoints for 1320 into /tmp/tmptcbqokll/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1320...\n",
      "INFO:tensorflow:Loss for final step: 0.67645055.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:29Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptcbqokll/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.30960s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:30\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.62396693, global_step = 1320, loss = 0.66966754\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmptcbqokll/model.ckpt-1320\n",
      "Train accuracy after 120 epochs is: 0.62\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptcbqokll/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.15680s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:30\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.6393443, global_step = 1320, loss = 0.5842579\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmptcbqokll/model.ckpt-1320\n",
      "Test accuracy after 120 epochs is: 0.64\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.30, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.31, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.32, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.32, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (6.49, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmprkj4b1i2\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmprkj4b1i2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmprkj4b1i2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6915938, step = 0\n",
      "INFO:tensorflow:global_step/sec: 468.248\n",
      "INFO:tensorflow:loss = 0.55019754, step = 100 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.92\n",
      "INFO:tensorflow:loss = 0.6737988, step = 200 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.755\n",
      "INFO:tensorflow:loss = 1.2681088, step = 300 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.671\n",
      "INFO:tensorflow:loss = 0.8480371, step = 400 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.424\n",
      "INFO:tensorflow:loss = 0.6191372, step = 500 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.717\n",
      "INFO:tensorflow:loss = 0.82365763, step = 600 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.14\n",
      "INFO:tensorflow:loss = 0.7962153, step = 700 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.985\n",
      "INFO:tensorflow:loss = 0.85635984, step = 800 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 585.31\n",
      "INFO:tensorflow:loss = 0.6532227, step = 900 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.96\n",
      "INFO:tensorflow:loss = 0.4638487, step = 1000 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 613.861\n",
      "INFO:tensorflow:loss = 0.6488478, step = 1100 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.325\n",
      "INFO:tensorflow:loss = 0.643038, step = 1200 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.148\n",
      "INFO:tensorflow:loss = 0.6137371, step = 1300 (0.151 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1320...\n",
      "INFO:tensorflow:Saving checkpoints for 1320 into /tmp/tmprkj4b1i2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1320...\n",
      "INFO:tensorflow:Loss for final step: 0.5148453.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:33Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmprkj4b1i2/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.32644s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:35\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.71487606, global_step = 1320, loss = 0.6294146\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmprkj4b1i2/model.ckpt-1320\n",
      "Train accuracy after 120 epochs is: 0.71\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmprkj4b1i2/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.14681s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:35\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.72131145, global_step = 1320, loss = 0.72508395\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmprkj4b1i2/model.ckpt-1320\n",
      "Test accuracy after 120 epochs is: 0.72\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.18, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.19, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.19, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.19, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (3.67, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpsx61sj9v\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpsx61sj9v', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpsx61sj9v/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.72006077, step = 0\n",
      "INFO:tensorflow:global_step/sec: 478.271\n",
      "INFO:tensorflow:loss = 1.0013852, step = 100 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.594\n",
      "INFO:tensorflow:loss = 0.7838697, step = 200 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.12\n",
      "INFO:tensorflow:loss = 0.992947, step = 300 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.569\n",
      "INFO:tensorflow:loss = 0.8362385, step = 400 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.344\n",
      "INFO:tensorflow:loss = 0.96452254, step = 500 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.674\n",
      "INFO:tensorflow:loss = 1.3278728, step = 600 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.48\n",
      "INFO:tensorflow:loss = 1.3622108, step = 700 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.285\n",
      "INFO:tensorflow:loss = 1.0121715, step = 800 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.645\n",
      "INFO:tensorflow:loss = 0.7854095, step = 900 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.32\n",
      "INFO:tensorflow:loss = 1.159137, step = 1000 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.005\n",
      "INFO:tensorflow:loss = 1.2442743, step = 1100 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.186\n",
      "INFO:tensorflow:loss = 1.4461888, step = 1200 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.769\n",
      "INFO:tensorflow:loss = 2.1344552, step = 1300 (0.151 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1320...\n",
      "INFO:tensorflow:Saving checkpoints for 1320 into /tmp/tmpsx61sj9v/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1320...\n",
      "INFO:tensorflow:Loss for final step: 1.9577864.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:38Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpsx61sj9v/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.30298s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:39\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.37190083, global_step = 1320, loss = 2.4206092\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmpsx61sj9v/model.ckpt-1320\n",
      "Train accuracy after 120 epochs is: 0.37\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:39Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpsx61sj9v/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.16091s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:39\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.3114754, global_step = 1320, loss = 2.7565794\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmpsx61sj9v/model.ckpt-1320\n",
      "Test accuracy after 120 epochs is: 0.31\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.09, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.10, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.10, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.10, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (1.89, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpt6xmy5ka\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpt6xmy5ka', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpt6xmy5ka/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.654341, step = 0\n",
      "INFO:tensorflow:global_step/sec: 479.347\n",
      "INFO:tensorflow:loss = 0.5657313, step = 100 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.158\n",
      "INFO:tensorflow:loss = 0.6204274, step = 200 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 657.579\n",
      "INFO:tensorflow:loss = 0.58417666, step = 300 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 668.811\n",
      "INFO:tensorflow:loss = 0.548599, step = 400 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.386\n",
      "INFO:tensorflow:loss = 0.6353865, step = 500 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.927\n",
      "INFO:tensorflow:loss = 0.5677385, step = 600 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.907\n",
      "INFO:tensorflow:loss = 0.579276, step = 700 (0.151 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 665.822\n",
      "INFO:tensorflow:loss = 0.54171425, step = 800 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.357\n",
      "INFO:tensorflow:loss = 0.55897963, step = 900 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.048\n",
      "INFO:tensorflow:loss = 0.5661697, step = 1000 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.363\n",
      "INFO:tensorflow:loss = 0.6782633, step = 1100 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.562\n",
      "INFO:tensorflow:loss = 0.5265281, step = 1200 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.018\n",
      "INFO:tensorflow:loss = 0.65321326, step = 1300 (0.156 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1320...\n",
      "INFO:tensorflow:Saving checkpoints for 1320 into /tmp/tmpt6xmy5ka/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1320...\n",
      "INFO:tensorflow:Loss for final step: 0.53030103.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:42Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpt6xmy5ka/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.29848s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:43\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.73140496, global_step = 1320, loss = 0.5342962\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmpt6xmy5ka/model.ckpt-1320\n",
      "Train accuracy after 120 epochs is: 0.73\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:43Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpt6xmy5ka/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.14922s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:44\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.704918, global_step = 1320, loss = 0.5584184\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmpt6xmy5ka/model.ckpt-1320\n",
      "Test accuracy after 120 epochs is: 0.70\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.71, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.73, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.74, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.74, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (22.81, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp7hzpag5k\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp7hzpag5k', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp7hzpag5k/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6967635, step = 0\n",
      "INFO:tensorflow:global_step/sec: 467.729\n",
      "INFO:tensorflow:loss = 0.6550394, step = 100 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.346\n",
      "INFO:tensorflow:loss = 0.92082995, step = 200 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.459\n",
      "INFO:tensorflow:loss = 0.7036773, step = 300 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 663.996\n",
      "INFO:tensorflow:loss = 0.65858895, step = 400 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.061\n",
      "INFO:tensorflow:loss = 0.61847454, step = 500 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.393\n",
      "INFO:tensorflow:loss = 0.7137723, step = 600 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.187\n",
      "INFO:tensorflow:loss = 0.91417783, step = 700 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.936\n",
      "INFO:tensorflow:loss = 0.628795, step = 800 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.293\n",
      "INFO:tensorflow:loss = 0.9766136, step = 900 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.479\n",
      "INFO:tensorflow:loss = 0.8013878, step = 1000 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.953\n",
      "INFO:tensorflow:loss = 0.84222907, step = 1100 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 668.826\n",
      "INFO:tensorflow:loss = 0.80843407, step = 1200 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.649\n",
      "INFO:tensorflow:loss = 0.6911239, step = 1300 (0.153 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1320...\n",
      "INFO:tensorflow:Saving checkpoints for 1320 into /tmp/tmp7hzpag5k/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1320...\n",
      "INFO:tensorflow:Loss for final step: 0.80281866.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:47Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp7hzpag5k/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.33690s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:48\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.6363636, global_step = 1320, loss = 0.71450573\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmp7hzpag5k/model.ckpt-1320\n",
      "Train accuracy after 120 epochs is: 0.64\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:48Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp7hzpag5k/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.14853s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:48\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.704918, global_step = 1320, loss = 0.59517217\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmp7hzpag5k/model.ckpt-1320\n",
      "Test accuracy after 120 epochs is: 0.70\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.30, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.31, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.32, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.32, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (6.49, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpezlsp5_u\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpezlsp5_u', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpezlsp5_u/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.7160742, step = 0\n",
      "INFO:tensorflow:global_step/sec: 413.893\n",
      "INFO:tensorflow:loss = 0.75608677, step = 100 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.566\n",
      "INFO:tensorflow:loss = 0.79367524, step = 200 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.341\n",
      "INFO:tensorflow:loss = 0.78315485, step = 300 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.221\n",
      "INFO:tensorflow:loss = 1.1348093, step = 400 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.112\n",
      "INFO:tensorflow:loss = 0.75767475, step = 500 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.903\n",
      "INFO:tensorflow:loss = 1.1297609, step = 600 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.459\n",
      "INFO:tensorflow:loss = 1.0372822, step = 700 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 642.355\n",
      "INFO:tensorflow:loss = 0.8190228, step = 800 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.594\n",
      "INFO:tensorflow:loss = 1.3595364, step = 900 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.602\n",
      "INFO:tensorflow:loss = 1.0818394, step = 1000 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 668.722\n",
      "INFO:tensorflow:loss = 0.71423435, step = 1100 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.264\n",
      "INFO:tensorflow:loss = 1.0755793, step = 1200 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.359\n",
      "INFO:tensorflow:loss = 1.42154, step = 1300 (0.161 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1320...\n",
      "INFO:tensorflow:Saving checkpoints for 1320 into /tmp/tmpezlsp5_u/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1320...\n",
      "INFO:tensorflow:Loss for final step: 1.12234.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:51Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpezlsp5_u/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.30620s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:53\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.5082645, global_step = 1320, loss = 1.1323415\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmpezlsp5_u/model.ckpt-1320\n",
      "Train accuracy after 120 epochs is: 0.51\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:53Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpezlsp5_u/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.15661s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:53\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.4262295, global_step = 1320, loss = 1.281278\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmpezlsp5_u/model.ckpt-1320\n",
      "Test accuracy after 120 epochs is: 0.43\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.18, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.19, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.19, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.19, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (3.67, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp3oj7oxcf\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp3oj7oxcf', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp3oj7oxcf/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6364519, step = 0\n",
      "INFO:tensorflow:global_step/sec: 484.908\n",
      "INFO:tensorflow:loss = 0.67503643, step = 100 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.211\n",
      "INFO:tensorflow:loss = 0.72124285, step = 200 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 677.91\n",
      "INFO:tensorflow:loss = 0.47372743, step = 300 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.163\n",
      "INFO:tensorflow:loss = 0.22694941, step = 400 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.737\n",
      "INFO:tensorflow:loss = 0.8794546, step = 500 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.348\n",
      "INFO:tensorflow:loss = 0.7078011, step = 600 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.633\n",
      "INFO:tensorflow:loss = 0.7528277, step = 700 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.536\n",
      "INFO:tensorflow:loss = 2.8547897, step = 800 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.779\n",
      "INFO:tensorflow:loss = 1.6764191, step = 900 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.979\n",
      "INFO:tensorflow:loss = 1.4767503, step = 1000 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.928\n",
      "INFO:tensorflow:loss = 2.2786398, step = 1100 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.496\n",
      "INFO:tensorflow:loss = 1.9106873, step = 1200 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.584\n",
      "INFO:tensorflow:loss = 1.603813, step = 1300 (0.150 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1320...\n",
      "INFO:tensorflow:Saving checkpoints for 1320 into /tmp/tmp3oj7oxcf/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1320...\n",
      "INFO:tensorflow:Loss for final step: 1.6236805.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:56Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp3oj7oxcf/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.29201s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:57\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.5289256, global_step = 1320, loss = 1.9575467\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmp3oj7oxcf/model.ckpt-1320\n",
      "Train accuracy after 120 epochs is: 0.53\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:21:57Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp3oj7oxcf/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.15268s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:21:57\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.6885246, global_step = 1320, loss = 1.6481636\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmp3oj7oxcf/model.ckpt-1320\n",
      "Test accuracy after 120 epochs is: 0.69\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.09, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.10, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.10, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.10, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (1.89, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp5bxem2or\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp5bxem2or', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp5bxem2or/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.79152626, step = 0\n",
      "INFO:tensorflow:global_step/sec: 466.845\n",
      "INFO:tensorflow:loss = 0.9029379, step = 100 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 663.44\n",
      "INFO:tensorflow:loss = 0.7077368, step = 200 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.788\n",
      "INFO:tensorflow:loss = 0.7523841, step = 300 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.656\n",
      "INFO:tensorflow:loss = 0.57328933, step = 400 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.975\n",
      "INFO:tensorflow:loss = 0.57249635, step = 500 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.527\n",
      "INFO:tensorflow:loss = 0.50530946, step = 600 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.312\n",
      "INFO:tensorflow:loss = 0.67734224, step = 700 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.11\n",
      "INFO:tensorflow:loss = 0.62662977, step = 800 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.183\n",
      "INFO:tensorflow:loss = 0.6298188, step = 900 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 663.902\n",
      "INFO:tensorflow:loss = 0.5720307, step = 1000 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.05\n",
      "INFO:tensorflow:loss = 0.63501346, step = 1100 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.417\n",
      "INFO:tensorflow:loss = 0.65456367, step = 1200 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.839\n",
      "INFO:tensorflow:loss = 0.52379054, step = 1300 (0.151 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1320...\n",
      "INFO:tensorflow:Saving checkpoints for 1320 into /tmp/tmp5bxem2or/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1320...\n",
      "INFO:tensorflow:Loss for final step: 0.50954634.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:00Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp5bxem2or/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.30189s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:01\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.78512394, global_step = 1320, loss = 0.4949621\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmp5bxem2or/model.ckpt-1320\n",
      "Train accuracy after 120 epochs is: 0.79\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:01Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp5bxem2or/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.14545s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:02\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.7704918, global_step = 1320, loss = 0.4713057\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmp5bxem2or/model.ckpt-1320\n",
      "Test accuracy after 120 epochs is: 0.77\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.71, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.73, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.74, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.74, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (22.81, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpkdftshsk\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpkdftshsk', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpkdftshsk/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.71899647, step = 0\n",
      "INFO:tensorflow:global_step/sec: 473.186\n",
      "INFO:tensorflow:loss = 0.82909197, step = 100 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.127\n",
      "INFO:tensorflow:loss = 0.61759347, step = 200 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.797\n",
      "INFO:tensorflow:loss = 0.8551355, step = 300 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.632\n",
      "INFO:tensorflow:loss = 0.3478881, step = 400 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.448\n",
      "INFO:tensorflow:loss = 0.8057942, step = 500 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.561\n",
      "INFO:tensorflow:loss = 0.6956362, step = 600 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.372\n",
      "INFO:tensorflow:loss = 0.7191929, step = 700 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.737\n",
      "INFO:tensorflow:loss = 0.61372733, step = 800 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.448\n",
      "INFO:tensorflow:loss = 0.4769142, step = 900 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.617\n",
      "INFO:tensorflow:loss = 0.3645465, step = 1000 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.453\n",
      "INFO:tensorflow:loss = 0.6276996, step = 1100 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.29\n",
      "INFO:tensorflow:loss = 0.4137512, step = 1200 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.664\n",
      "INFO:tensorflow:loss = 0.69695604, step = 1300 (0.163 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1320...\n",
      "INFO:tensorflow:Saving checkpoints for 1320 into /tmp/tmpkdftshsk/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1320...\n",
      "INFO:tensorflow:Loss for final step: 0.48161325.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpkdftshsk/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.31565s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:06\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.7355372, global_step = 1320, loss = 0.67161983\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmpkdftshsk/model.ckpt-1320\n",
      "Train accuracy after 120 epochs is: 0.74\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:06Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpkdftshsk/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.15661s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:06\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.75409836, global_step = 1320, loss = 0.61402434\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmpkdftshsk/model.ckpt-1320\n",
      "Test accuracy after 120 epochs is: 0.75\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.30, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.31, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.32, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.32, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (6.49, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpc2foq2zw\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpc2foq2zw', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpc2foq2zw/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.7181108, step = 0\n",
      "INFO:tensorflow:global_step/sec: 444.451\n",
      "INFO:tensorflow:loss = 0.6936491, step = 100 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 593.972\n",
      "INFO:tensorflow:loss = 1.0525723, step = 200 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.305\n",
      "INFO:tensorflow:loss = 1.1127976, step = 300 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.472\n",
      "INFO:tensorflow:loss = 1.0797533, step = 400 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.92\n",
      "INFO:tensorflow:loss = 1.2809033, step = 500 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.767\n",
      "INFO:tensorflow:loss = 1.7908931, step = 600 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 668.418\n",
      "INFO:tensorflow:loss = 0.9242445, step = 700 (0.150 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 661.439\n",
      "INFO:tensorflow:loss = 1.1340775, step = 800 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.545\n",
      "INFO:tensorflow:loss = 0.85363287, step = 900 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.792\n",
      "INFO:tensorflow:loss = 1.0678964, step = 1000 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.035\n",
      "INFO:tensorflow:loss = 1.1327626, step = 1100 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.544\n",
      "INFO:tensorflow:loss = 1.3954536, step = 1200 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.736\n",
      "INFO:tensorflow:loss = 1.1461837, step = 1300 (0.151 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1320...\n",
      "INFO:tensorflow:Saving checkpoints for 1320 into /tmp/tmpc2foq2zw/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1320...\n",
      "INFO:tensorflow:Loss for final step: 1.1919059.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:09Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpc2foq2zw/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.30611s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:10\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.4752066, global_step = 1320, loss = 1.2427795\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmpc2foq2zw/model.ckpt-1320\n",
      "Train accuracy after 120 epochs is: 0.48\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpc2foq2zw/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.14997s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:10\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.36065573, global_step = 1320, loss = 1.3362709\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmpc2foq2zw/model.ckpt-1320\n",
      "Test accuracy after 120 epochs is: 0.36\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.18, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.19, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.19, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.19, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (3.67, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpdlscesyz\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpdlscesyz', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpdlscesyz/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.7314617, step = 0\n",
      "INFO:tensorflow:global_step/sec: 453.379\n",
      "INFO:tensorflow:loss = 0.8696005, step = 100 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.366\n",
      "INFO:tensorflow:loss = 0.7667806, step = 200 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.071\n",
      "INFO:tensorflow:loss = 1.2887144, step = 300 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.062\n",
      "INFO:tensorflow:loss = 0.95344675, step = 400 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.953\n",
      "INFO:tensorflow:loss = 0.37296525, step = 500 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.08\n",
      "INFO:tensorflow:loss = 1.330861, step = 600 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.253\n",
      "INFO:tensorflow:loss = 1.4329449, step = 700 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.993\n",
      "INFO:tensorflow:loss = 1.2336842, step = 800 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.124\n",
      "INFO:tensorflow:loss = 0.76471335, step = 900 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.07\n",
      "INFO:tensorflow:loss = 0.3515669, step = 1000 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.794\n",
      "INFO:tensorflow:loss = 1.150568, step = 1100 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.068\n",
      "INFO:tensorflow:loss = 0.66503954, step = 1200 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.326\n",
      "INFO:tensorflow:loss = 1.059567, step = 1300 (0.154 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1320...\n",
      "INFO:tensorflow:Saving checkpoints for 1320 into /tmp/tmpdlscesyz/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1320...\n",
      "INFO:tensorflow:Loss for final step: 0.7211626.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpdlscesyz/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.33600s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:15\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.73140496, global_step = 1320, loss = 1.0433793\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmpdlscesyz/model.ckpt-1320\n",
      "Train accuracy after 120 epochs is: 0.73\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:15Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpdlscesyz/model.ckpt-1320\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.14648s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:15\n",
      "INFO:tensorflow:Saving dict for global step 1320: accuracy = 0.7704918, global_step = 1320, loss = 0.94192004\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1320: /tmp/tmpdlscesyz/model.ckpt-1320\n",
      "Test accuracy after 120 epochs is: 0.77\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.09, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.10, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.10, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.10, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (1.89, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp2igh9z0y\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp2igh9z0y', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp2igh9z0y/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.77389514, step = 0\n",
      "INFO:tensorflow:global_step/sec: 375.061\n",
      "INFO:tensorflow:loss = 0.74571466, step = 100 (0.267 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 120...\n",
      "INFO:tensorflow:Saving checkpoints for 120 into /tmp/tmp2igh9z0y/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 120...\n",
      "INFO:tensorflow:Loss for final step: 0.7506914.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:16Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp2igh9z0y/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.30198s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:16\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.43801653, global_step = 120, loss = 0.74784905\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmp2igh9z0y/model.ckpt-120\n",
      "Train accuracy after 120 epochs is: 0.44\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:16Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp2igh9z0y/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.15804s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:16\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.57377046, global_step = 120, loss = 0.6959871\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmp2igh9z0y/model.ckpt-120\n",
      "Test accuracy after 120 epochs is: 0.57\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (124.20, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpqoeetfd0\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpqoeetfd0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpqoeetfd0/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6588965, step = 0\n",
      "INFO:tensorflow:global_step/sec: 350.477\n",
      "INFO:tensorflow:loss = 0.6420143, step = 100 (0.288 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 120...\n",
      "INFO:tensorflow:Saving checkpoints for 120 into /tmp/tmpqoeetfd0/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 120...\n",
      "INFO:tensorflow:Loss for final step: 0.65335023.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpqoeetfd0/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.29609s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:18\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.58264464, global_step = 120, loss = 0.6515304\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmpqoeetfd0/model.ckpt-120\n",
      "Train accuracy after 120 epochs is: 0.58\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:18Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpqoeetfd0/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.14516s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:18\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.59016395, global_step = 120, loss = 0.62141037\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmpqoeetfd0/model.ckpt-120\n",
      "Test accuracy after 120 epochs is: 0.59\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.06, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.06, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.06, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.06, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (34.20, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp00gwfaol\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp00gwfaol', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp00gwfaol/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.66171813, step = 0\n",
      "INFO:tensorflow:global_step/sec: 380.59\n",
      "INFO:tensorflow:loss = 0.7459677, step = 100 (0.265 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 120...\n",
      "INFO:tensorflow:Saving checkpoints for 120 into /tmp/tmp00gwfaol/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 120...\n",
      "INFO:tensorflow:Loss for final step: 0.81826544.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:19Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp00gwfaol/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.29011s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:19\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.3553719, global_step = 120, loss = 0.8207392\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmp00gwfaol/model.ckpt-120\n",
      "Train accuracy after 120 epochs is: 0.36\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:19Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp00gwfaol/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.16036s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:19\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.21311475, global_step = 120, loss = 0.89814687\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmp00gwfaol/model.ckpt-120\n",
      "Test accuracy after 120 epochs is: 0.21\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.04, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.04, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.04, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.04, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (17.53, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_23vt2no\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_23vt2no', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp_23vt2no/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.74299484, step = 0\n",
      "INFO:tensorflow:global_step/sec: 365.239\n",
      "INFO:tensorflow:loss = 1.2346777, step = 100 (0.274 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 120...\n",
      "INFO:tensorflow:Saving checkpoints for 120 into /tmp/tmp_23vt2no/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 120...\n",
      "INFO:tensorflow:Loss for final step: 1.390936.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:20Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp_23vt2no/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.28472s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:21\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.5413223, global_step = 120, loss = 1.3980709\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmp_23vt2no/model.ckpt-120\n",
      "Train accuracy after 120 epochs is: 0.54\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:21Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp_23vt2no/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.15094s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:21\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.55737704, global_step = 120, loss = 1.5110772\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmp_23vt2no/model.ckpt-120\n",
      "Test accuracy after 120 epochs is: 0.56\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.02, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.02, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.02, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.02, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (8.58, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp1u9ebnyq\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp1u9ebnyq', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp1u9ebnyq/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.7441711, step = 0\n",
      "INFO:tensorflow:global_step/sec: 373.96\n",
      "INFO:tensorflow:loss = 0.7667808, step = 100 (0.270 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 120...\n",
      "INFO:tensorflow:Saving checkpoints for 120 into /tmp/tmp1u9ebnyq/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 120...\n",
      "INFO:tensorflow:Loss for final step: 0.77282625.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp1u9ebnyq/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.29003s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:22\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.35123968, global_step = 120, loss = 0.7703095\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmp1u9ebnyq/model.ckpt-120\n",
      "Train accuracy after 120 epochs is: 0.35\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp1u9ebnyq/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.14317s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:22\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.26229507, global_step = 120, loss = 0.7839175\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmp1u9ebnyq/model.ckpt-120\n",
      "Test accuracy after 120 epochs is: 0.26\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (124.20, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_py6wwrc\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_py6wwrc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp_py6wwrc/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.68176883, step = 0\n",
      "INFO:tensorflow:global_step/sec: 372.654\n",
      "INFO:tensorflow:loss = 0.722463, step = 100 (0.269 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 120...\n",
      "INFO:tensorflow:Saving checkpoints for 120 into /tmp/tmp_py6wwrc/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 120...\n",
      "INFO:tensorflow:Loss for final step: 0.7548517.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:23Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp_py6wwrc/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.30003s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:24\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.5, global_step = 120, loss = 0.7498043\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmp_py6wwrc/model.ckpt-120\n",
      "Train accuracy after 120 epochs is: 0.50\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp_py6wwrc/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.15035s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:24\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.45901638, global_step = 120, loss = 0.75402284\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmp_py6wwrc/model.ckpt-120\n",
      "Test accuracy after 120 epochs is: 0.46\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.06, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.06, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.06, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.06, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (34.20, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpm4aqlbib\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpm4aqlbib', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpm4aqlbib/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.66787034, step = 0\n",
      "INFO:tensorflow:global_step/sec: 377.869\n",
      "INFO:tensorflow:loss = 0.85857886, step = 100 (0.266 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 120...\n",
      "INFO:tensorflow:Saving checkpoints for 120 into /tmp/tmpm4aqlbib/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 120...\n",
      "INFO:tensorflow:Loss for final step: 0.83764416.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:25Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpm4aqlbib/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.29877s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:25\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.46694216, global_step = 120, loss = 0.8288955\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmpm4aqlbib/model.ckpt-120\n",
      "Train accuracy after 120 epochs is: 0.47\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:25Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpm4aqlbib/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.16011s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:25\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.4918033, global_step = 120, loss = 0.7809058\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmpm4aqlbib/model.ckpt-120\n",
      "Test accuracy after 120 epochs is: 0.49\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.04, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.04, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.04, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.04, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (17.53, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmps1cyw_m9\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmps1cyw_m9', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmps1cyw_m9/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6797855, step = 0\n",
      "INFO:tensorflow:global_step/sec: 362.909\n",
      "INFO:tensorflow:loss = 0.61840844, step = 100 (0.276 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 120...\n",
      "INFO:tensorflow:Saving checkpoints for 120 into /tmp/tmps1cyw_m9/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 120...\n",
      "INFO:tensorflow:Loss for final step: 0.8001356.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:26Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmps1cyw_m9/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.29834s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:27\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.5661157, global_step = 120, loss = 0.8392009\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmps1cyw_m9/model.ckpt-120\n",
      "Train accuracy after 120 epochs is: 0.57\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmps1cyw_m9/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.14830s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:27\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.59016395, global_step = 120, loss = 0.7812253\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmps1cyw_m9/model.ckpt-120\n",
      "Test accuracy after 120 epochs is: 0.59\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.02, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.02, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.02, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.02, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (8.58, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpnt0zolad\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpnt0zolad', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpnt0zolad/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6337721, step = 0\n",
      "INFO:tensorflow:global_step/sec: 347.797\n",
      "INFO:tensorflow:loss = 0.60666335, step = 100 (0.290 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 120...\n",
      "INFO:tensorflow:Saving checkpoints for 120 into /tmp/tmpnt0zolad/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 120...\n",
      "INFO:tensorflow:Loss for final step: 0.620754.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:28Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpnt0zolad/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.29721s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:28\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.69008267, global_step = 120, loss = 0.6269997\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmpnt0zolad/model.ckpt-120\n",
      "Train accuracy after 120 epochs is: 0.69\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:28Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpnt0zolad/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.15434s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:29\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.704918, global_step = 120, loss = 0.6007405\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmpnt0zolad/model.ckpt-120\n",
      "Test accuracy after 120 epochs is: 0.70\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.16, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (124.20, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpry5jjc4e\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpry5jjc4e', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpry5jjc4e/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.77039474, step = 0\n",
      "INFO:tensorflow:global_step/sec: 355.829\n",
      "INFO:tensorflow:loss = 0.6294369, step = 100 (0.282 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 120...\n",
      "INFO:tensorflow:Saving checkpoints for 120 into /tmp/tmpry5jjc4e/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 120...\n",
      "INFO:tensorflow:Loss for final step: 0.63212174.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpry5jjc4e/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.29886s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:30\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.677686, global_step = 120, loss = 0.62026894\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmpry5jjc4e/model.ckpt-120\n",
      "Train accuracy after 120 epochs is: 0.68\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpry5jjc4e/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.16352s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:30\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.704918, global_step = 120, loss = 0.5988464\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmpry5jjc4e/model.ckpt-120\n",
      "Test accuracy after 120 epochs is: 0.70\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.06, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.06, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.06, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.06, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (34.20, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpzx2nlctu\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpzx2nlctu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpzx2nlctu/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.68574744, step = 0\n",
      "INFO:tensorflow:global_step/sec: 373.69\n",
      "INFO:tensorflow:loss = 0.6906074, step = 100 (0.268 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 120...\n",
      "INFO:tensorflow:Saving checkpoints for 120 into /tmp/tmpzx2nlctu/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 120...\n",
      "INFO:tensorflow:Loss for final step: 0.57195646.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:31Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpzx2nlctu/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.27823s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:32\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.6652893, global_step = 120, loss = 0.60249585\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmpzx2nlctu/model.ckpt-120\n",
      "Train accuracy after 120 epochs is: 0.67\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpzx2nlctu/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.14871s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:32\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.55737704, global_step = 120, loss = 0.64285266\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmpzx2nlctu/model.ckpt-120\n",
      "Test accuracy after 120 epochs is: 0.56\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.04, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.04, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.04, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.04, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (17.53, 0.0037565740045078884)-DP for all samples.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpb_6fpe9i\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpb_6fpe9i', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpb_6fpe9i/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.81751585, step = 0\n",
      "INFO:tensorflow:global_step/sec: 370.201\n",
      "INFO:tensorflow:loss = 0.5294401, step = 100 (0.272 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 120...\n",
      "INFO:tensorflow:Saving checkpoints for 120 into /tmp/tmpb_6fpe9i/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 120...\n",
      "INFO:tensorflow:Loss for final step: 0.476058.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:33Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpb_6fpe9i/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.29666s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:33\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.75619835, global_step = 120, loss = 0.477725\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmpb_6fpe9i/model.ckpt-120\n",
      "Train accuracy after 120 epochs is: 0.76\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-10-28T14:22:33Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpb_6fpe9i/model.ckpt-120\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.15823s\n",
      "INFO:tensorflow:Finished evaluation at 2021-10-28-14:22:33\n",
      "INFO:tensorflow:Saving dict for global step 120: accuracy = 0.8032787, global_step = 120, loss = 0.39603174\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 120: /tmp/tmpb_6fpe9i/model.ckpt-120\n",
      "Test accuracy after 120 epochs is: 0.80\n",
      "In the conditions of Theorem 34 (https://arxiv.org/abs/1808.06651) the training procedure results in the following privacy guarantees.\n",
      "Out of the total of 242 samples:\n",
      "\t50% enjoy at least (0.02, 0.0037565740045078884)-DP\n",
      "\t90% enjoy at least (0.02, 0.0037565740045078884)-DP\n",
      "\t99% enjoy at least (0.02, 0.0037565740045078884)-DP\n",
      "\t100% enjoy at least (0.02, 0.0037565740045078884)-DP\n",
      "By comparison, DP-SGD analysis for training done with the same parameters and random shuffling in each epoch guarantees (8.58, 0.0037565740045078884)-DP for all samples.\n"
     ]
    }
   ],
   "source": [
    "GradientDescentOptimizer = tf.train.GradientDescentOptimizer\n",
    "\n",
    "noise_multipliers = [1, 2, 3, 5]\n",
    "data_l2_norms = [0.8, 1.0, 1.2]\n",
    "batch_sizes = [11, 22, 242]\n",
    "\n",
    "df = train_grid_search(noise_multipliers=noise_multipliers, \n",
    "                    batch_sizes = batch_sizes,\n",
    "                    regularizer = 0,\n",
    "                    data_l2_norms = data_l2_norms,\n",
    "                    dpsgd=True, learning_rate=0.01, epochs=120,  model_dir=None,\n",
    "                    print_outputs = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "79ee-l3ha33f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzhIlW2Svk0A"
   },
   "source": [
    "Note in the table below, the Epsilon value is the epsilon enjoyed by 100% of the input value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "N8Okw9acvhOR",
    "outputId": "37db274e-0688-4461-fc38-2664a53d6dd8"
   },
   "outputs": [],
   "source": [
    "df.sort_values(by=['Validation accuracy', 'Epsilon'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TFP-HeartDisease-LogisticRegression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Pets Test",
   "language": "python",
   "name": "pets_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
