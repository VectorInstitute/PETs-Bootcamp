{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning for tabular data - Breast Cancer Dataset\n",
    "\n",
    "References:\n",
    "- https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification\n",
    "- https://stackoverflow.com/questions/58965488/how-to-create-federated-dataset-from-a-csv-file\n",
    "- https://www.youtube.com/watch?v=JBNas6Yd30A&ab_channel=GoogleTechTalks \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that your environment is correctly setup, run the following. \n",
    "If you don't see a greeting, refer to the [Installation](https://www.tensorflow.org/federated/install) guide for instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip3 install numpy\n",
    "\n",
    "# TODO:\n",
    "# client proportions\n",
    "# number clients\n",
    "# size \n",
    "# different type of clients?\n",
    "\n",
    "# simulate clients\n",
    "# realistic preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /ssd003/projects/aieng/public/pets_unified/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:61: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /ssd003/projects/aieng/public/pets_unified/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:61: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from tensorflow import reshape, nest, config\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(0)\n",
    "\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing the tabular input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Federated learning requires a federated data set, i.e., a collection of data from multiple users. \n",
    "The TFF has a few federated datasets, but in this notebook, we will be converting a tabular dataset to a federated one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_13</th>\n",
       "      <th>FLAG_DOCUMENT_14</th>\n",
       "      <th>FLAG_DOCUMENT_15</th>\n",
       "      <th>FLAG_DOCUMENT_16</th>\n",
       "      <th>FLAG_DOCUMENT_17</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.577538</td>\n",
       "      <td>0.142129</td>\n",
       "      <td>-0.478095</td>\n",
       "      <td>-0.166149</td>\n",
       "      <td>-0.507465</td>\n",
       "      <td>-0.149452</td>\n",
       "      <td>1.506880</td>\n",
       "      <td>-0.456215</td>\n",
       "      <td>0.379837</td>\n",
       "      <td>0.579154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059477</td>\n",
       "      <td>-0.054269</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>-0.100138</td>\n",
       "      <td>-0.016332</td>\n",
       "      <td>-0.090534</td>\n",
       "      <td>-0.024402</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.577538</td>\n",
       "      <td>0.426792</td>\n",
       "      <td>1.725450</td>\n",
       "      <td>0.592677</td>\n",
       "      <td>1.600698</td>\n",
       "      <td>-1.252750</td>\n",
       "      <td>-0.166821</td>\n",
       "      <td>-0.460115</td>\n",
       "      <td>1.078697</td>\n",
       "      <td>1.790855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059477</td>\n",
       "      <td>-0.054269</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>-0.100138</td>\n",
       "      <td>-0.016332</td>\n",
       "      <td>-0.090534</td>\n",
       "      <td>-0.024402</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.577538</td>\n",
       "      <td>-0.427196</td>\n",
       "      <td>-1.152888</td>\n",
       "      <td>-1.404676</td>\n",
       "      <td>-1.092389</td>\n",
       "      <td>-0.783451</td>\n",
       "      <td>-0.689509</td>\n",
       "      <td>-0.453299</td>\n",
       "      <td>0.206116</td>\n",
       "      <td>0.306869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059477</td>\n",
       "      <td>-0.054269</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>-0.100138</td>\n",
       "      <td>-0.016332</td>\n",
       "      <td>-0.090534</td>\n",
       "      <td>-0.024402</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.577538</td>\n",
       "      <td>-0.142533</td>\n",
       "      <td>-0.711430</td>\n",
       "      <td>0.177869</td>\n",
       "      <td>-0.653696</td>\n",
       "      <td>-0.928991</td>\n",
       "      <td>-0.680114</td>\n",
       "      <td>-0.473217</td>\n",
       "      <td>-1.375829</td>\n",
       "      <td>0.369143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059477</td>\n",
       "      <td>-0.054269</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>-0.100138</td>\n",
       "      <td>-0.016332</td>\n",
       "      <td>-0.090534</td>\n",
       "      <td>-0.024402</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.577538</td>\n",
       "      <td>-0.199466</td>\n",
       "      <td>-0.213734</td>\n",
       "      <td>-0.361755</td>\n",
       "      <td>-0.068772</td>\n",
       "      <td>0.563570</td>\n",
       "      <td>-0.892535</td>\n",
       "      <td>-0.473210</td>\n",
       "      <td>0.191639</td>\n",
       "      <td>-0.307263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059477</td>\n",
       "      <td>-0.054269</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>-0.100138</td>\n",
       "      <td>-0.016332</td>\n",
       "      <td>-0.090534</td>\n",
       "      <td>-0.024402</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307506</th>\n",
       "      <td>-0.577538</td>\n",
       "      <td>-0.047646</td>\n",
       "      <td>-0.855489</td>\n",
       "      <td>0.031009</td>\n",
       "      <td>-0.848671</td>\n",
       "      <td>0.845396</td>\n",
       "      <td>1.537586</td>\n",
       "      <td>-0.453377</td>\n",
       "      <td>-0.984955</td>\n",
       "      <td>0.670578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059477</td>\n",
       "      <td>-0.054269</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>-0.100138</td>\n",
       "      <td>-0.016332</td>\n",
       "      <td>-0.090534</td>\n",
       "      <td>-0.024402</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307507</th>\n",
       "      <td>-0.577538</td>\n",
       "      <td>-0.408219</td>\n",
       "      <td>-0.818594</td>\n",
       "      <td>-1.042339</td>\n",
       "      <td>-0.848671</td>\n",
       "      <td>0.310593</td>\n",
       "      <td>-1.085707</td>\n",
       "      <td>2.133617</td>\n",
       "      <td>0.169782</td>\n",
       "      <td>-0.725959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059477</td>\n",
       "      <td>-0.054269</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>-0.100138</td>\n",
       "      <td>-0.016332</td>\n",
       "      <td>-0.090534</td>\n",
       "      <td>-0.024402</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307508</th>\n",
       "      <td>-0.577538</td>\n",
       "      <td>-0.066623</td>\n",
       "      <td>0.195379</td>\n",
       "      <td>0.198050</td>\n",
       "      <td>0.126202</td>\n",
       "      <td>-1.147120</td>\n",
       "      <td>0.245417</td>\n",
       "      <td>-0.507774</td>\n",
       "      <td>-0.497002</td>\n",
       "      <td>-1.428203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059477</td>\n",
       "      <td>-0.054269</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>-0.100138</td>\n",
       "      <td>-0.016332</td>\n",
       "      <td>-0.090534</td>\n",
       "      <td>-0.024402</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307509</th>\n",
       "      <td>-0.577538</td>\n",
       "      <td>0.009287</td>\n",
       "      <td>-0.568757</td>\n",
       "      <td>-0.476324</td>\n",
       "      <td>-0.592767</td>\n",
       "      <td>-1.124635</td>\n",
       "      <td>0.934008</td>\n",
       "      <td>-0.485583</td>\n",
       "      <td>0.688107</td>\n",
       "      <td>1.366859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059477</td>\n",
       "      <td>-0.054269</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>-0.100138</td>\n",
       "      <td>-0.016332</td>\n",
       "      <td>-0.090534</td>\n",
       "      <td>-0.024402</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307510</th>\n",
       "      <td>-0.577538</td>\n",
       "      <td>-0.047646</td>\n",
       "      <td>0.188760</td>\n",
       "      <td>1.518545</td>\n",
       "      <td>0.369920</td>\n",
       "      <td>1.832942</td>\n",
       "      <td>-0.187674</td>\n",
       "      <td>-0.460639</td>\n",
       "      <td>-0.040274</td>\n",
       "      <td>1.712018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059477</td>\n",
       "      <td>-0.054269</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>-0.100138</td>\n",
       "      <td>-0.016332</td>\n",
       "      <td>-0.090534</td>\n",
       "      <td>-0.024402</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307511 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0          -0.577538          0.142129   -0.478095    -0.166149   \n",
       "1          -0.577538          0.426792    1.725450     0.592677   \n",
       "2          -0.577538         -0.427196   -1.152888    -1.404676   \n",
       "3          -0.577538         -0.142533   -0.711430     0.177869   \n",
       "4          -0.577538         -0.199466   -0.213734    -0.361755   \n",
       "...              ...               ...         ...          ...   \n",
       "307506     -0.577538         -0.047646   -0.855489     0.031009   \n",
       "307507     -0.577538         -0.408219   -0.818594    -1.042339   \n",
       "307508     -0.577538         -0.066623    0.195379     0.198050   \n",
       "307509     -0.577538          0.009287   -0.568757    -0.476324   \n",
       "307510     -0.577538         -0.047646    0.188760     1.518545   \n",
       "\n",
       "        AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "0             -0.507465                   -0.149452    1.506880   \n",
       "1              1.600698                   -1.252750   -0.166821   \n",
       "2             -1.092389                   -0.783451   -0.689509   \n",
       "3             -0.653696                   -0.928991   -0.680114   \n",
       "4             -0.068772                    0.563570   -0.892535   \n",
       "...                 ...                         ...         ...   \n",
       "307506        -0.848671                    0.845396    1.537586   \n",
       "307507        -0.848671                    0.310593   -1.085707   \n",
       "307508         0.126202                   -1.147120    0.245417   \n",
       "307509        -0.592767                   -1.124635    0.934008   \n",
       "307510         0.369920                    1.832942   -0.187674   \n",
       "\n",
       "        DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  ...  \\\n",
       "0           -0.456215           0.379837         0.579154  ...   \n",
       "1           -0.460115           1.078697         1.790855  ...   \n",
       "2           -0.453299           0.206116         0.306869  ...   \n",
       "3           -0.473217          -1.375829         0.369143  ...   \n",
       "4           -0.473210           0.191639        -0.307263  ...   \n",
       "...               ...                ...              ...  ...   \n",
       "307506      -0.453377          -0.984955         0.670578  ...   \n",
       "307507       2.133617           0.169782        -0.725959  ...   \n",
       "307508      -0.507774          -0.497002        -1.428203  ...   \n",
       "307509      -0.485583           0.688107         1.366859  ...   \n",
       "307510      -0.460639          -0.040274         1.712018  ...   \n",
       "\n",
       "        FLAG_DOCUMENT_13  FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  \\\n",
       "0              -0.059477         -0.054269         -0.034802   \n",
       "1              -0.059477         -0.054269         -0.034802   \n",
       "2              -0.059477         -0.054269         -0.034802   \n",
       "3              -0.059477         -0.054269         -0.034802   \n",
       "4              -0.059477         -0.054269         -0.034802   \n",
       "...                  ...               ...               ...   \n",
       "307506         -0.059477         -0.054269         -0.034802   \n",
       "307507         -0.059477         -0.054269         -0.034802   \n",
       "307508         -0.059477         -0.054269         -0.034802   \n",
       "307509         -0.059477         -0.054269         -0.034802   \n",
       "307510         -0.059477         -0.054269         -0.034802   \n",
       "\n",
       "        FLAG_DOCUMENT_16  FLAG_DOCUMENT_17  FLAG_DOCUMENT_18  \\\n",
       "0              -0.100138         -0.016332         -0.090534   \n",
       "1              -0.100138         -0.016332         -0.090534   \n",
       "2              -0.100138         -0.016332         -0.090534   \n",
       "3              -0.100138         -0.016332         -0.090534   \n",
       "4              -0.100138         -0.016332         -0.090534   \n",
       "...                  ...               ...               ...   \n",
       "307506         -0.100138         -0.016332         -0.090534   \n",
       "307507         -0.100138         -0.016332         -0.090534   \n",
       "307508         -0.100138         -0.016332         -0.090534   \n",
       "307509         -0.100138         -0.016332         -0.090534   \n",
       "307510         -0.100138         -0.016332         -0.090534   \n",
       "\n",
       "        FLAG_DOCUMENT_19  FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  target  \n",
       "0              -0.024402         -0.022529         -0.018305       1  \n",
       "1              -0.024402         -0.022529         -0.018305       0  \n",
       "2              -0.024402         -0.022529         -0.018305       0  \n",
       "3              -0.024402         -0.022529         -0.018305       0  \n",
       "4              -0.024402         -0.022529         -0.018305       0  \n",
       "...                  ...               ...               ...     ...  \n",
       "307506         -0.024402         -0.022529         -0.018305       0  \n",
       "307507         -0.024402         -0.022529         -0.018305       0  \n",
       "307508         -0.024402         -0.022529         -0.018305       0  \n",
       "307509         -0.024402         -0.022529         -0.018305       1  \n",
       "307510         -0.024402         -0.022529         -0.018305       0  \n",
       "\n",
       "[307511 rows x 99 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = '/ssd003/projects/pets/datasets/home_credit/home_credit_train.csv'\n",
    "data = pd.read_csv(datapath)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_13</th>\n",
       "      <th>FLAG_DOCUMENT_14</th>\n",
       "      <th>FLAG_DOCUMENT_15</th>\n",
       "      <th>FLAG_DOCUMENT_16</th>\n",
       "      <th>FLAG_DOCUMENT_17</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>307511.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.225633e-17</td>\n",
       "      <td>-1.220299e-17</td>\n",
       "      <td>-3.880695e-17</td>\n",
       "      <td>4.621251e-17</td>\n",
       "      <td>6.585514e-16</td>\n",
       "      <td>3.335850e-16</td>\n",
       "      <td>3.350407e-17</td>\n",
       "      <td>4.311627e-17</td>\n",
       "      <td>-6.469751e-18</td>\n",
       "      <td>6.757424e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.944738e-18</td>\n",
       "      <td>2.463127e-17</td>\n",
       "      <td>4.898526e-18</td>\n",
       "      <td>-2.952402e-17</td>\n",
       "      <td>3.512151e-18</td>\n",
       "      <td>-1.899334e-17</td>\n",
       "      <td>-7.625064e-18</td>\n",
       "      <td>-1.940925e-18</td>\n",
       "      <td>6.053839e-18</td>\n",
       "      <td>0.080729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>0.272419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.775378e-01</td>\n",
       "      <td>-6.036870e-01</td>\n",
       "      <td>-1.376496e+00</td>\n",
       "      <td>-1.758940e+00</td>\n",
       "      <td>-1.348293e+00</td>\n",
       "      <td>-1.487798e+00</td>\n",
       "      <td>-2.106335e+00</td>\n",
       "      <td>-5.784940e-01</td>\n",
       "      <td>-5.588007e+00</td>\n",
       "      <td>-2.784328e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.947728e-02</td>\n",
       "      <td>-5.426904e-02</td>\n",
       "      <td>-3.480198e-02</td>\n",
       "      <td>-1.001382e-01</td>\n",
       "      <td>-1.633182e-02</td>\n",
       "      <td>-9.053411e-02</td>\n",
       "      <td>-2.440195e-02</td>\n",
       "      <td>-2.252901e-02</td>\n",
       "      <td>-1.830463e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-5.775378e-01</td>\n",
       "      <td>-2.374210e-01</td>\n",
       "      <td>-8.174760e-01</td>\n",
       "      <td>-7.303015e-01</td>\n",
       "      <td>-8.121132e-01</td>\n",
       "      <td>-7.853308e-01</td>\n",
       "      <td>-8.352476e-01</td>\n",
       "      <td>-4.712426e-01</td>\n",
       "      <td>-7.077673e-01</td>\n",
       "      <td>-8.644204e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.947728e-02</td>\n",
       "      <td>-5.426904e-02</td>\n",
       "      <td>-3.480198e-02</td>\n",
       "      <td>-1.001382e-01</td>\n",
       "      <td>-1.633182e-02</td>\n",
       "      <td>-9.053411e-02</td>\n",
       "      <td>-2.440195e-02</td>\n",
       "      <td>-2.252901e-02</td>\n",
       "      <td>-1.830463e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-5.775378e-01</td>\n",
       "      <td>-9.129414e-02</td>\n",
       "      <td>-2.124151e-01</td>\n",
       "      <td>-1.521775e-01</td>\n",
       "      <td>-2.393752e-01</td>\n",
       "      <td>-1.459095e-01</td>\n",
       "      <td>6.576450e-02</td>\n",
       "      <td>-4.602923e-01</td>\n",
       "      <td>1.368540e-01</td>\n",
       "      <td>-1.721143e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.947728e-02</td>\n",
       "      <td>-5.426904e-02</td>\n",
       "      <td>-3.480198e-02</td>\n",
       "      <td>-1.001382e-01</td>\n",
       "      <td>-1.633182e-02</td>\n",
       "      <td>-9.053411e-02</td>\n",
       "      <td>-2.440195e-02</td>\n",
       "      <td>-2.252901e-02</td>\n",
       "      <td>-1.830463e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.072731e-01</td>\n",
       "      <td>1.421293e-01</td>\n",
       "      <td>5.208178e-01</td>\n",
       "      <td>5.166083e-01</td>\n",
       "      <td>3.821064e-01</td>\n",
       "      <td>5.635704e-01</td>\n",
       "      <td>8.304332e-01</td>\n",
       "      <td>-4.537519e-01</td>\n",
       "      <td>8.447974e-01</td>\n",
       "      <td>8.441512e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.947728e-02</td>\n",
       "      <td>-5.426904e-02</td>\n",
       "      <td>-3.480198e-02</td>\n",
       "      <td>-1.001382e-01</td>\n",
       "      <td>-1.633182e-02</td>\n",
       "      <td>-9.053411e-02</td>\n",
       "      <td>-2.440195e-02</td>\n",
       "      <td>-2.252901e-02</td>\n",
       "      <td>-1.830463e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.573387e+01</td>\n",
       "      <td>4.927034e+02</td>\n",
       "      <td>8.574059e+00</td>\n",
       "      <td>1.593252e+01</td>\n",
       "      <td>9.509356e+00</td>\n",
       "      <td>3.733564e+00</td>\n",
       "      <td>1.958761e+00</td>\n",
       "      <td>2.133617e+00</td>\n",
       "      <td>1.415353e+00</td>\n",
       "      <td>1.983641e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.681314e+01</td>\n",
       "      <td>1.842671e+01</td>\n",
       "      <td>2.873400e+01</td>\n",
       "      <td>9.986201e+00</td>\n",
       "      <td>6.123017e+01</td>\n",
       "      <td>1.104556e+01</td>\n",
       "      <td>4.098034e+01</td>\n",
       "      <td>4.438721e+01</td>\n",
       "      <td>5.463098e+01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CNT_CHILDREN  AMT_INCOME_TOTAL    AMT_CREDIT   AMT_ANNUITY  \\\n",
       "count  3.075110e+05      3.075110e+05  3.075110e+05  3.075110e+05   \n",
       "mean  -3.225633e-17     -1.220299e-17 -3.880695e-17  4.621251e-17   \n",
       "std    1.000002e+00      1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -5.775378e-01     -6.036870e-01 -1.376496e+00 -1.758940e+00   \n",
       "25%   -5.775378e-01     -2.374210e-01 -8.174760e-01 -7.303015e-01   \n",
       "50%   -5.775378e-01     -9.129414e-02 -2.124151e-01 -1.521775e-01   \n",
       "75%    8.072731e-01      1.421293e-01  5.208178e-01  5.166083e-01   \n",
       "max    2.573387e+01      4.927034e+02  8.574059e+00  1.593252e+01   \n",
       "\n",
       "       AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE    DAYS_BIRTH  \\\n",
       "count     3.075110e+05                3.075110e+05  3.075110e+05   \n",
       "mean      6.585514e-16                3.335850e-16  3.350407e-17   \n",
       "std       1.000002e+00                1.000002e+00  1.000002e+00   \n",
       "min      -1.348293e+00               -1.487798e+00 -2.106335e+00   \n",
       "25%      -8.121132e-01               -7.853308e-01 -8.352476e-01   \n",
       "50%      -2.393752e-01               -1.459095e-01  6.576450e-02   \n",
       "75%       3.821064e-01                5.635704e-01  8.304332e-01   \n",
       "max       9.509356e+00                3.733564e+00  1.958761e+00   \n",
       "\n",
       "       DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  ...  \\\n",
       "count   3.075110e+05       3.075110e+05     3.075110e+05  ...   \n",
       "mean    4.311627e-17      -6.469751e-18     6.757424e-17  ...   \n",
       "std     1.000002e+00       1.000002e+00     1.000002e+00  ...   \n",
       "min    -5.784940e-01      -5.588007e+00    -2.784328e+00  ...   \n",
       "25%    -4.712426e-01      -7.077673e-01    -8.644204e-01  ...   \n",
       "50%    -4.602923e-01       1.368540e-01    -1.721143e-01  ...   \n",
       "75%    -4.537519e-01       8.447974e-01     8.441512e-01  ...   \n",
       "max     2.133617e+00       1.415353e+00     1.983641e+00  ...   \n",
       "\n",
       "       FLAG_DOCUMENT_13  FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  FLAG_DOCUMENT_16  \\\n",
       "count      3.075110e+05      3.075110e+05      3.075110e+05      3.075110e+05   \n",
       "mean      -4.944738e-18      2.463127e-17      4.898526e-18     -2.952402e-17   \n",
       "std        1.000002e+00      1.000002e+00      1.000002e+00      1.000002e+00   \n",
       "min       -5.947728e-02     -5.426904e-02     -3.480198e-02     -1.001382e-01   \n",
       "25%       -5.947728e-02     -5.426904e-02     -3.480198e-02     -1.001382e-01   \n",
       "50%       -5.947728e-02     -5.426904e-02     -3.480198e-02     -1.001382e-01   \n",
       "75%       -5.947728e-02     -5.426904e-02     -3.480198e-02     -1.001382e-01   \n",
       "max        1.681314e+01      1.842671e+01      2.873400e+01      9.986201e+00   \n",
       "\n",
       "       FLAG_DOCUMENT_17  FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_20  \\\n",
       "count      3.075110e+05      3.075110e+05      3.075110e+05      3.075110e+05   \n",
       "mean       3.512151e-18     -1.899334e-17     -7.625064e-18     -1.940925e-18   \n",
       "std        1.000002e+00      1.000002e+00      1.000002e+00      1.000002e+00   \n",
       "min       -1.633182e-02     -9.053411e-02     -2.440195e-02     -2.252901e-02   \n",
       "25%       -1.633182e-02     -9.053411e-02     -2.440195e-02     -2.252901e-02   \n",
       "50%       -1.633182e-02     -9.053411e-02     -2.440195e-02     -2.252901e-02   \n",
       "75%       -1.633182e-02     -9.053411e-02     -2.440195e-02     -2.252901e-02   \n",
       "max        6.123017e+01      1.104556e+01      4.098034e+01      4.438721e+01   \n",
       "\n",
       "       FLAG_DOCUMENT_21         target  \n",
       "count      3.075110e+05  307511.000000  \n",
       "mean       6.053839e-18       0.080729  \n",
       "std        1.000002e+00       0.272419  \n",
       "min       -1.830463e-02       0.000000  \n",
       "25%       -1.830463e-02       0.000000  \n",
       "50%       -1.830463e-02       0.000000  \n",
       "75%       -1.830463e-02       0.000000  \n",
       "max        5.463098e+01       1.000000  \n",
       "\n",
       "[8 rows x 99 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del data['Unnamed: 32']\n",
    "# del data['id']\n",
    "# print(data.shape)\n",
    "# data['diagnosis'] = data['diagnosis'].str.replace('M','1')\n",
    "# data['diagnosis'] = data['diagnosis'].str.replace('B','0')\n",
    "# data[\"diagnosis\"] = pd.to_numeric(data[\"diagnosis\"])\n",
    "\n",
    "# new = data.copy()\n",
    "# del new['diagnosis']\n",
    "# x = new.values #returns a numpy array\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# x_scaled = min_max_scaler.fit_transform(x)\n",
    "# df = pd.DataFrame(x_scaled)\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
      "0          -0.577538          0.142129   -0.478095    -0.166149   \n",
      "1          -0.577538          0.426792    1.725450     0.592677   \n",
      "2          -0.577538         -0.427196   -1.152888    -1.404676   \n",
      "3          -0.577538         -0.142533   -0.711430     0.177869   \n",
      "4          -0.577538         -0.199466   -0.213734    -0.361755   \n",
      "...              ...               ...         ...          ...   \n",
      "307506     -0.577538         -0.047646   -0.855489     0.031009   \n",
      "307507     -0.577538         -0.408219   -0.818594    -1.042339   \n",
      "307508     -0.577538         -0.066623    0.195379     0.198050   \n",
      "307509     -0.577538          0.009287   -0.568757    -0.476324   \n",
      "307510     -0.577538         -0.047646    0.188760     1.518545   \n",
      "\n",
      "        AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
      "0             -0.507465                   -0.149452    1.506880   \n",
      "1              1.600698                   -1.252750   -0.166821   \n",
      "2             -1.092389                   -0.783451   -0.689509   \n",
      "3             -0.653696                   -0.928991   -0.680114   \n",
      "4             -0.068772                    0.563570   -0.892535   \n",
      "...                 ...                         ...         ...   \n",
      "307506        -0.848671                    0.845396    1.537586   \n",
      "307507        -0.848671                    0.310593   -1.085707   \n",
      "307508         0.126202                   -1.147120    0.245417   \n",
      "307509        -0.592767                   -1.124635    0.934008   \n",
      "307510         0.369920                    1.832942   -0.187674   \n",
      "\n",
      "        DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  ...  \\\n",
      "0           -0.456215           0.379837         0.579154  ...   \n",
      "1           -0.460115           1.078697         1.790855  ...   \n",
      "2           -0.453299           0.206116         0.306869  ...   \n",
      "3           -0.473217          -1.375829         0.369143  ...   \n",
      "4           -0.473210           0.191639        -0.307263  ...   \n",
      "...               ...                ...              ...  ...   \n",
      "307506      -0.453377          -0.984955         0.670578  ...   \n",
      "307507       2.133617           0.169782        -0.725959  ...   \n",
      "307508      -0.507774          -0.497002        -1.428203  ...   \n",
      "307509      -0.485583           0.688107         1.366859  ...   \n",
      "307510      -0.460639          -0.040274         1.712018  ...   \n",
      "\n",
      "        FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  FLAG_DOCUMENT_16  \\\n",
      "0              -0.054269         -0.034802         -0.100138   \n",
      "1              -0.054269         -0.034802         -0.100138   \n",
      "2              -0.054269         -0.034802         -0.100138   \n",
      "3              -0.054269         -0.034802         -0.100138   \n",
      "4              -0.054269         -0.034802         -0.100138   \n",
      "...                  ...               ...               ...   \n",
      "307506         -0.054269         -0.034802         -0.100138   \n",
      "307507         -0.054269         -0.034802         -0.100138   \n",
      "307508         -0.054269         -0.034802         -0.100138   \n",
      "307509         -0.054269         -0.034802         -0.100138   \n",
      "307510         -0.054269         -0.034802         -0.100138   \n",
      "\n",
      "        FLAG_DOCUMENT_17  FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  \\\n",
      "0              -0.016332         -0.090534         -0.024402   \n",
      "1              -0.016332         -0.090534         -0.024402   \n",
      "2              -0.016332         -0.090534         -0.024402   \n",
      "3              -0.016332         -0.090534         -0.024402   \n",
      "4              -0.016332         -0.090534         -0.024402   \n",
      "...                  ...               ...               ...   \n",
      "307506         -0.016332         -0.090534         -0.024402   \n",
      "307507         -0.016332         -0.090534         -0.024402   \n",
      "307508         -0.016332         -0.090534         -0.024402   \n",
      "307509         -0.016332         -0.090534         -0.024402   \n",
      "307510         -0.016332         -0.090534         -0.024402   \n",
      "\n",
      "        FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  target  \\\n",
      "0              -0.022529         -0.018305       1   \n",
      "1              -0.022529         -0.018305       0   \n",
      "2              -0.022529         -0.018305       0   \n",
      "3              -0.022529         -0.018305       0   \n",
      "4              -0.022529         -0.018305       0   \n",
      "...                  ...               ...     ...   \n",
      "307506         -0.022529         -0.018305       0   \n",
      "307507         -0.022529         -0.018305       0   \n",
      "307508         -0.022529         -0.018305       0   \n",
      "307509         -0.022529         -0.018305       1   \n",
      "307510         -0.022529         -0.018305       0   \n",
      "\n",
      "                                                 features  \n",
      "0       [-0.5775378417542217, 0.142129252374572, -0.47...  \n",
      "1       [-0.5775378417542217, 0.426791930024181, 1.725...  \n",
      "2       [-0.5775378417542217, -0.4271961029246461, -1....  \n",
      "3       [-0.5775378417542217, -0.14253342527503704, -0...  \n",
      "4       [-0.5775378417542217, -0.19946596080495885, -0...  \n",
      "...                                                   ...  \n",
      "307506  [-0.5775378417542217, -0.0476458660585007, -0....  \n",
      "307507  [-0.5775378417542217, -0.4082185910813388, -0....  \n",
      "307508  [-0.5775378417542217, -0.06662337790180796, 0....  \n",
      "307509  [-0.5775378417542217, 0.009286669471421113, -0...  \n",
      "307510  [-0.5775378417542217, -0.0476458660585007, 0.1...  \n",
      "\n",
      "[307511 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "new = df.copy()\n",
    "data['features']= new.values.tolist()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To simulate FL, we'll make a new column for \"hospital_id\" --> id: 1, 2, 3, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22365/3875885449.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['hospital_id'] = np.random.randint(1,5, size=len(data))\n"
     ]
    }
   ],
   "source": [
    "data['hospital_id'] = np.random.randint(1,5, size=len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['target', 'hospital_id', 'features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.5775378417542217, 0.142129252374572, -0.47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.5775378417542217, 0.426791930024181, 1.725...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.5775378417542217, -0.4271961029246461, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.5775378417542217, -0.14253342527503704, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.5775378417542217, -0.19946596080495885, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307506</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.5775378417542217, -0.0476458660585007, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307507</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.5775378417542217, -0.4082185910813388, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307508</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.5775378417542217, -0.06662337790180796, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307509</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.5775378417542217, 0.009286669471421113, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307510</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.5775378417542217, -0.0476458660585007, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307511 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target  hospital_id                                           features\n",
       "0            1            1  [-0.5775378417542217, 0.142129252374572, -0.47...\n",
       "1            0            4  [-0.5775378417542217, 0.426791930024181, 1.725...\n",
       "2            0            3  [-0.5775378417542217, -0.4271961029246461, -1....\n",
       "3            0            3  [-0.5775378417542217, -0.14253342527503704, -0...\n",
       "4            0            2  [-0.5775378417542217, -0.19946596080495885, -0...\n",
       "...        ...          ...                                                ...\n",
       "307506       0            2  [-0.5775378417542217, -0.0476458660585007, -0....\n",
       "307507       0            3  [-0.5775378417542217, -0.4082185910813388, -0....\n",
       "307508       0            1  [-0.5775378417542217, -0.06662337790180796, 0....\n",
       "307509       1            3  [-0.5775378417542217, 0.009286669471421113, -0...\n",
       "307510       0            1  [-0.5775378417542217, -0.0476458660585007, 0.1...\n",
       "\n",
       "[307511 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we have 4 hospitals. We will train on 3 clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id_colname = 'hospital_id' #column that represents client ID \n",
    "number_of_training_clients = 3\n",
    "\n",
    "# split client_id into train and test clients\n",
    "client_ids = data[client_id_colname].unique()\n",
    "train_client_ids = sample(client_ids.tolist(), number_of_training_clients)\n",
    "test_client_ids = [x for x in client_ids if x not in train_client_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 2]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_client_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `tff.simulation.ClientData.from_clients_and_fn`, requires that we write a function that accepts a `client_id` as input and returns a `tf.data.Dataset`. Let's do that in the helper function below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE_BUFFER = 1000\n",
    "NUM_EPOCHS = 10\n",
    "def create_tf_dataset_for_client_fn(client_id):\n",
    "    client_data = data[data[client_id_colname] == client_id]\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(client_data.to_dict('list'))\n",
    "    dataset = dataset.shuffle(SHUFFLE_BUFFER).batch(1).repeat(NUM_EPOCHS)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tff.__version__ < \"0.19.0\":\n",
    "\n",
    "    train_data = tff.simulation.ClientData.from_clients_and_fn(\n",
    "        client_ids=train_client_ids,   \n",
    "        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn)\n",
    "    \n",
    "    test_data = tff.simulation.ClientData.from_clients_and_fn(\n",
    "        client_ids=test_client_ids,\n",
    "        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn)\n",
    "else:\n",
    "    train_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
    "        client_ids=train_client_ids, \n",
    "        serializable_dataset_fn=create_tf_dataset_for_client_fn)\n",
    "    \n",
    "    test_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
    "        client_ids=test_client_ids,\n",
    "        serializable_dataset_fn=create_tf_dataset_for_client_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example dataset \n",
    "\n",
    "Each element of example_dataset is a Python dictionary where the keys are strings representing feature names, and the values are tensors with one batch of those features. Now, you have a federated dataset that can be preprocessed and used for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RepeatDataset element_spec={'target': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'hospital_id': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'features': TensorSpec(shape=(None, 99), dtype=tf.float32, name=None)}>\n",
      "{'target': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>, 'hospital_id': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([4], dtype=int32)>, 'features': <tf.Tensor: shape=(1, 99), dtype=float32, numpy=\n",
      "array([[-5.77537835e-01,  6.16567075e-01,  1.19052362e+00,\n",
      "         5.38342237e-01,  9.79216158e-01, -9.82854366e-01,\n",
      "         1.57194763e-01, -4.65070218e-01,  6.37864470e-01,\n",
      "         1.62445068e-01, -5.82998335e-01,  1.80330989e-03,\n",
      "         4.68696862e-01, -4.99013036e-01,  4.32445444e-02,\n",
      "        -6.25259101e-01, -2.45215252e-01, -1.67639494e-01,\n",
      "        -1.03064351e-01, -6.26985356e-02, -1.94189306e-02,\n",
      "         8.06424141e+00,  4.32401323e+00, -2.05868647e-01,\n",
      "        -2.91207880e-01, -5.47235489e-01, -4.67814147e-01,\n",
      "        -9.19422567e-01,  1.19701350e+00,  1.42642260e+00,\n",
      "        -1.43810916e+00, -1.66568363e+00, -7.16030598e-02,\n",
      "        -1.51403761e+00, -1.05237603e+00, -8.58345628e-01,\n",
      "        -1.14506304e+00, -1.80044043e+00, -1.62387192e+00,\n",
      "        -1.19693136e+00, -1.80643988e+00, -1.27514815e+00,\n",
      "        -3.33794802e-01, -6.09261632e-01, -1.39715171e+00,\n",
      "        -1.61220062e+00, -5.11821099e-02, -1.45665646e+00,\n",
      "        -1.02427042e+00, -8.24147522e-01, -1.07084620e+00,\n",
      "        -1.77316391e+00, -1.58412647e+00, -1.16031694e+00,\n",
      "        -1.78609717e+00, -1.23743868e+00, -3.15670848e-01,\n",
      "        -5.74531734e-01, -1.43113422e+00, -1.66173375e+00,\n",
      "        -7.12033808e-02, -1.51000428e+00, -1.05026340e+00,\n",
      "        -8.49642038e-01, -1.13418269e+00, -1.79140186e+00,\n",
      "        -1.61539900e+00, -1.19665205e+00, -1.80636847e+00,\n",
      "        -1.26860607e+00, -3.30011725e-01, -6.01082206e-01,\n",
      "        -1.24653459e+00,  2.41032809e-01, -3.21603060e-01,\n",
      "         2.50314176e-01, -2.76616484e-01, -6.73847735e-01,\n",
      "        -6.50205323e-03, -1.56478560e+00, -9.01690125e-03,\n",
      "        -1.23882495e-01, -3.10737550e-01, -1.38527928e-02,\n",
      "         3.35985756e+00, -6.25382438e-02, -4.77115624e-03,\n",
      "        -6.26691282e-02, -2.55026948e-03, -5.94772846e-02,\n",
      "        -5.42690381e-02, -3.48019823e-02, -1.00138180e-01,\n",
      "        -1.63318180e-02, -9.05341133e-02, -2.44019479e-02,\n",
      "        -2.25290135e-02, -1.83046330e-02,  0.00000000e+00]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "example_dataset = train_data.create_tf_dataset_for_client(\n",
    "        train_data.client_ids[2]\n",
    "    )\n",
    "print(example_dataset)\n",
    "example_element = iter(example_dataset).next()\n",
    "print(example_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring heterogeneity in federated data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of examples per layer for a sample of clients\n",
    "f = plt.figure(figsize=(12, 7))\n",
    "f.suptitle('Label Counts for a Sample of Clients')\n",
    "for i in [0,1,2]:\n",
    "    client_dataset = train_data.create_tf_dataset_for_client(\n",
    "        train_data.client_ids[i])\n",
    "    plot_data = collections.defaultdict(list)\n",
    "    for example in client_dataset:\n",
    "        label = example['target'].numpy()[0]\n",
    "        plot_data[label].append(label)\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.title('Client {}'.format(i))\n",
    "    for j in range(10):\n",
    "        plt.hist(\n",
    "        plot_data[j],\n",
    "        bins=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above steps, we now have a federated dataset that can be preprocessed and used for modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Preprocessing the input data\n",
    "We will now shuffle the individual examples, organize them into batches, and rename the features\n",
    "from `features` and `diagnosis` to `x` and `y` for use with Keras. We also throw in a\n",
    "`repeat` over the data set to run several epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = len(data['features'][0])\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROUNDS = 5\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 20\n",
    "PREFETCH_BUFFER = 10\n",
    "def preprocess(dataset):\n",
    "    def batch_format_fn(element):\n",
    "                \n",
    "        return collections.OrderedDict(x= tf.reshape(element['features'], [-1,n_features]),\n",
    "                                       y=tf.reshape(element['target'], [-1,1]))\n",
    "\n",
    "    return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
    "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify this worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('x',\n",
       "              array([[ 2.192084  ,  0.42679194,  0.5872293 , ..., -0.02252901,\n",
       "                      -0.01830463,  0.        ],\n",
       "                     [-0.57753783,  0.52167946, -0.01606499, ..., -0.02252901,\n",
       "                      -0.01830463,  0.        ],\n",
       "                     [ 2.192084  ,  0.42679194, -1.0410839 , ..., -0.02252901,\n",
       "                      -0.01830463,  0.        ],\n",
       "                     ...,\n",
       "                     [-0.57753783, -0.33230853, -0.7816987 , ..., -0.02252901,\n",
       "                      -0.01830463,  0.        ],\n",
       "                     [-0.57753783, -0.29435351, -1.1534469 , ..., -0.02252901,\n",
       "                      -0.01830463,  0.        ],\n",
       "                     [-0.57753783, -0.23742099, -0.8018793 , ..., -0.02252901,\n",
       "                      -0.01830463,  0.        ]], dtype=float32)),\n",
       "             ('y',\n",
       "              array([[0],\n",
       "                     [0],\n",
       "                     [0],\n",
       "                     [0],\n",
       "                     [0],\n",
       "                     [0],\n",
       "                     [1],\n",
       "                     [0],\n",
       "                     [0],\n",
       "                     [0],\n",
       "                     [0],\n",
       "                     [0],\n",
       "                     [0],\n",
       "                     [0],\n",
       "                     [1],\n",
       "                     [0],\n",
       "                     [0],\n",
       "                     [0],\n",
       "                     [0],\n",
       "                     [0]], dtype=int32))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_example_dataset = preprocess(example_dataset)\n",
    "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
    "                                     next(iter(preprocessed_example_dataset)))\n",
    "\n",
    "sample_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have almost all the building blocks in place to construct federated datasets.\n",
    "\n",
    "One of the ways to feed federated data to TFF in a simulation is simply as a Python list, with each element of the list holding the data of an individual user, as a `tf.data.Dataset`. Since we already have an interface for that, let's use it.\n",
    "\n",
    "The helper function `make_federated_data` below will construct a list of datasets from the\n",
    "given set of users as an input to a round of training or evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_federated_data(client_data, client_ids):\n",
    "    return [\n",
    "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
    "      for x in client_ids\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, how do we choose the clients? \n",
    "\n",
    "In a typical federated training scenario, we might have only a fraction of the devices available for training at a given point in time. But, since we are in a simulation environment, all the data is locally available. Typically then, when running simulations, we would simply sample a random subset of the clients to be involved in each round of training, generally different in each round.\n",
    "\n",
    "That said, as you can find out by studying the paper on the [Federated Averaging](https://arxiv.org/abs/1602.05629) algorithm, achieving convergence in a system with randomly sampled subsets of clients in each round can take a while, and it would be impractical to have to run hundreds of rounds in this interactive tutorial.\n",
    "\n",
    "For simplicity here, we will sample the set of clients once, and reuse the same set across rounds to speed up convergence (intentionally over-fitting to these few user's data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of client datasets: 3\n",
      "First dataset: <PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 99), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>\n"
     ]
    }
   ],
   "source": [
    "train_client_ids = sample(client_ids.tolist(), number_of_training_clients)\n",
    "federated_train_data = make_federated_data(train_data, train_data.client_ids)\n",
    "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
    "print('First dataset: {d}'.format(d=federated_train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a model with Keras \n",
    "Here's an example of a simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 23 13:23:15 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            On   | 00000000:2F:00.0 Off |                    0 |\r\n",
      "| N/A   44C    P0    28W /  70W |  14266MiB / 15109MiB |      2%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     22365      C   ...c/pets_unified/bin/python    14263MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape=(n_features,)), # n_features\n",
    "      tf.keras.layers.Dense(150, activation = 'swish'),\n",
    "        tf.keras.layers.Dense(50, activation = 'swish'),\n",
    "        tf.keras.layers.Dense(1, activation = 'sigmoid'),\n",
    "      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we do not compile the model yet. The loss, metrics, and optimizers are introduced later.\n",
    "\n",
    "If you have a Keras model like the one we've just defined above, you can have TFF wrap it for you by invoking\n",
    "`tff.learning.from_keras_model`, passing the model and a sample data batch as\n",
    "arguments, as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "def model_fn():\n",
    "  # We _must_ create a new model here, and _not_ capture it from an external\n",
    "  # scope. TFF will call this within different graph contexts.\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=preprocessed_example_dataset.element_spec,\n",
    "      loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Precision(name='Precision'),\n",
    "               tf.keras.metrics.Recall(name='Recall'), tf.keras.metrics.AUC(name='AUC')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training the model on federated data \n",
    "\n",
    "Now that we have a model wrapped as `tff.learning.Model` for use with TFF, we\n",
    "can let TFF construct a **Federated Averaging** algorithm by invoking the helper\n",
    "function `tff.learning.build_federated_averaging_process`, as follows.\n",
    "\n",
    "One critical note on the Federated Averaging algorithm below, there are **2**\n",
    "optimizers: a _client_optimizer_ and a _server_optimizer_. The\n",
    "_client_optimizer_ is only used to compute local model updates on each client.\n",
    "The _server_optimizer_ applies the averaged update to the global model at the\n",
    "server. In particular, this means that the choice of optimizer and learning rate\n",
    "used may need to be different than the ones you have used to train the model on\n",
    "a standard i.i.d. dataset.\n",
    "\n",
    "We will start with regular SGD and a smaller learning rate than usual. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the two computations generated and packed into iterative_process implement Federated Averaging.\n",
    "\n",
    "Let's start with the `initialize` computation. As is the case for all federated\n",
    "computations, you can think of it as a function. The computation takes no\n",
    "arguments, and returns one result - the representation of the state of the\n",
    "Federated Averaging process on the server. While we don't want to dive into the\n",
    "details of TFF, it may be instructive to see what this state looks like. You can\n",
    "visualize it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'( -> <model=<trainable=<float32[99,150],float32[150],float32[150,50],float32[50],float32[50,1],float32[1]>,non_trainable=<>>,optimizer_state=<int64>,delta_aggregate_state=<value_sum_process=<>,weight_sum_process=<>>,model_broadcast_state=<>>@SERVER)'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(iterative_process.initialize.type_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the above type signature may at first seem a bit cryptic, you can recognize that the server state consists of a model (the initial model parameters for MNIST that will be distributed to all devices), and optimizer_state (additional information maintained by the server, such as the number of rounds to use for hyperparameter schedules, etc.).\n",
    "\n",
    "Let's invoke the initialize computation to construct the server state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ServerState(model=ModelWeights(trainable=[array([[ 0.10348243, -0.06885037,  0.07771191, ..., -0.10749009,\n",
       "        -0.1032353 ,  0.08645412],\n",
       "       [ 0.0501992 , -0.02820575,  0.14514181, ..., -0.03871834,\n",
       "        -0.11406054, -0.1034091 ],\n",
       "       [ 0.14803419,  0.09056705,  0.06475905, ...,  0.06517252,\n",
       "        -0.05347275, -0.11413331],\n",
       "       ...,\n",
       "       [-0.14944807, -0.15239197, -0.13543782, ...,  0.13688761,\n",
       "        -0.14491893,  0.14292198],\n",
       "       [ 0.13721761, -0.04483501, -0.06196497, ..., -0.02843122,\n",
       "         0.00641531,  0.13988072],\n",
       "       [-0.09317924,  0.08071399, -0.02243645, ...,  0.100384  ,\n",
       "         0.02957618,  0.0923211 ]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32), array([[ 0.05595344, -0.13133407, -0.09519204, ...,  0.04235713,\n",
       "        -0.09700784,  0.01476571],\n",
       "       [ 0.07448894,  0.02221242, -0.12520085, ...,  0.02643602,\n",
       "         0.06474043,  0.0733723 ],\n",
       "       [ 0.05213375,  0.06323823, -0.04331572, ..., -0.09492739,\n",
       "        -0.00519054,  0.07728806],\n",
       "       ...,\n",
       "       [-0.11881977, -0.0909817 , -0.16351376, ..., -0.12330598,\n",
       "        -0.0346055 , -0.08255622],\n",
       "       [-0.01573624, -0.03768679, -0.15877604, ..., -0.12697163,\n",
       "        -0.07866859, -0.10587456],\n",
       "       [ 0.16209969,  0.16201264, -0.06001575, ...,  0.0327258 ,\n",
       "        -0.05450324,  0.0809311 ]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32), array([[ 0.32981375],\n",
       "       [ 0.23516032],\n",
       "       [ 0.15980151],\n",
       "       [-0.02514231],\n",
       "       [ 0.22037813],\n",
       "       [ 0.00283635],\n",
       "       [-0.18085754],\n",
       "       [ 0.3053744 ],\n",
       "       [ 0.2747943 ],\n",
       "       [ 0.16097859],\n",
       "       [-0.32939202],\n",
       "       [-0.1993926 ],\n",
       "       [-0.24372646],\n",
       "       [ 0.26350096],\n",
       "       [-0.14203444],\n",
       "       [ 0.17708847],\n",
       "       [-0.07507142],\n",
       "       [-0.2650252 ],\n",
       "       [-0.1758635 ],\n",
       "       [ 0.22975037],\n",
       "       [-0.32609782],\n",
       "       [-0.17432152],\n",
       "       [-0.05494475],\n",
       "       [-0.20749219],\n",
       "       [-0.24908891],\n",
       "       [-0.16315407],\n",
       "       [ 0.18641862],\n",
       "       [-0.1132426 ],\n",
       "       [ 0.19715765],\n",
       "       [-0.29322013],\n",
       "       [ 0.30096164],\n",
       "       [-0.15741742],\n",
       "       [-0.0057269 ],\n",
       "       [-0.24329722],\n",
       "       [-0.28168723],\n",
       "       [ 0.17731985],\n",
       "       [ 0.11619613],\n",
       "       [ 0.15638089],\n",
       "       [-0.32174277],\n",
       "       [-0.04754418],\n",
       "       [-0.27556106],\n",
       "       [-0.20497788],\n",
       "       [-0.27501005],\n",
       "       [-0.2537502 ],\n",
       "       [-0.0944237 ],\n",
       "       [ 0.29299697],\n",
       "       [-0.21098301],\n",
       "       [ 0.00706437],\n",
       "       [ 0.01634288],\n",
       "       [-0.19928   ]], dtype=float32), array([0.], dtype=float32)], non_trainable=[]), optimizer_state=[0], delta_aggregate_state=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), model_broadcast_state=())"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second of the pair of federated computations, `next`, represents a single\n",
    "round of Federated Averaging, which consists of pushing the server state\n",
    "(including the model parameters) to the clients, on-device training on their\n",
    "local data, collecting and averaging model updates, and producing a new updated\n",
    "model at the server.\n",
    "\n",
    "Conceptually, you can think of `next` as having a functional type signature that\n",
    "looks as follows.\n",
    "\n",
    "```\n",
    "SERVER_STATE, FEDERATED_DATA -> SERVER_STATE, TRAINING_METRICS\n",
    "```\n",
    "\n",
    "In particular, one should think about `next()` not as being a function that runs on a server, but rather being a declarative functional representation of the entire decentralized computation - some of the inputs are provided by the server (`SERVER_STATE`), but each participating device contributes its own local dataset.\n",
    "\n",
    "Let's run a single round of training and visualize the results. We can use the\n",
    "federated data we've already generated above for a sample of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 99), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>,\n",
       " <PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 99), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>,\n",
       " <PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 99), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federated_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelWeights(trainable=[array([[ 0.10348243, -0.06885037,  0.07771191, ..., -0.10749009,\n",
       "        -0.1032353 ,  0.08645412],\n",
       "       [ 0.0501992 , -0.02820575,  0.14514181, ..., -0.03871834,\n",
       "        -0.11406054, -0.1034091 ],\n",
       "       [ 0.14803419,  0.09056705,  0.06475905, ...,  0.06517252,\n",
       "        -0.05347275, -0.11413331],\n",
       "       ...,\n",
       "       [-0.14944807, -0.15239197, -0.13543782, ...,  0.13688761,\n",
       "        -0.14491893,  0.14292198],\n",
       "       [ 0.13721761, -0.04483501, -0.06196497, ..., -0.02843122,\n",
       "         0.00641531,  0.13988072],\n",
       "       [-0.09317924,  0.08071399, -0.02243645, ...,  0.100384  ,\n",
       "         0.02957618,  0.0923211 ]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32), array([[ 0.05595344, -0.13133407, -0.09519204, ...,  0.04235713,\n",
       "        -0.09700784,  0.01476571],\n",
       "       [ 0.07448894,  0.02221242, -0.12520085, ...,  0.02643602,\n",
       "         0.06474043,  0.0733723 ],\n",
       "       [ 0.05213375,  0.06323823, -0.04331572, ..., -0.09492739,\n",
       "        -0.00519054,  0.07728806],\n",
       "       ...,\n",
       "       [-0.11881977, -0.0909817 , -0.16351376, ..., -0.12330598,\n",
       "        -0.0346055 , -0.08255622],\n",
       "       [-0.01573624, -0.03768679, -0.15877604, ..., -0.12697163,\n",
       "        -0.07866859, -0.10587456],\n",
       "       [ 0.16209969,  0.16201264, -0.06001575, ...,  0.0327258 ,\n",
       "        -0.05450324,  0.0809311 ]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32), array([[ 0.32981375],\n",
       "       [ 0.23516032],\n",
       "       [ 0.15980151],\n",
       "       [-0.02514231],\n",
       "       [ 0.22037813],\n",
       "       [ 0.00283635],\n",
       "       [-0.18085754],\n",
       "       [ 0.3053744 ],\n",
       "       [ 0.2747943 ],\n",
       "       [ 0.16097859],\n",
       "       [-0.32939202],\n",
       "       [-0.1993926 ],\n",
       "       [-0.24372646],\n",
       "       [ 0.26350096],\n",
       "       [-0.14203444],\n",
       "       [ 0.17708847],\n",
       "       [-0.07507142],\n",
       "       [-0.2650252 ],\n",
       "       [-0.1758635 ],\n",
       "       [ 0.22975037],\n",
       "       [-0.32609782],\n",
       "       [-0.17432152],\n",
       "       [-0.05494475],\n",
       "       [-0.20749219],\n",
       "       [-0.24908891],\n",
       "       [-0.16315407],\n",
       "       [ 0.18641862],\n",
       "       [-0.1132426 ],\n",
       "       [ 0.19715765],\n",
       "       [-0.29322013],\n",
       "       [ 0.30096164],\n",
       "       [-0.15741742],\n",
       "       [-0.0057269 ],\n",
       "       [-0.24329722],\n",
       "       [-0.28168723],\n",
       "       [ 0.17731985],\n",
       "       [ 0.11619613],\n",
       "       [ 0.15638089],\n",
       "       [-0.32174277],\n",
       "       [-0.04754418],\n",
       "       [-0.27556106],\n",
       "       [-0.20497788],\n",
       "       [-0.27501005],\n",
       "       [-0.2537502 ],\n",
       "       [-0.0944237 ],\n",
       "       [ 0.29299697],\n",
       "       [-0.21098301],\n",
       "       [ 0.00706437],\n",
       "       [ 0.01634288],\n",
       "       [-0.19928   ]], dtype=float32), array([0.], dtype=float32)], non_trainable=[])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('binary_accuracy', 0.99758273), ('Precision', 0.999075), ('Recall', 0.9709596), ('AUC', 0.99885046), ('loss', 0.009680059)])), ('stat', OrderedDict([('num_examples', 5772700)]))])\n"
     ]
    }
   ],
   "source": [
    "state, metrics = iterative_process.next(state, federated_train_data)\n",
    "print('round  1, metrics={}'.format(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a few more rounds. As noted earlier, typically at this point you would\n",
    "pick a subset of your simulation data from a new randomly selected sample of\n",
    "users for each round in order to simulate a realistic deployment in which users\n",
    "continuously come and go, but in this interactive notebook, for the sake of\n",
    "demonstration we'll just reuse the same users, so that the system converges\n",
    "quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  2, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('binary_accuracy', 0.9977161), ('Precision', 0.9991932), ('Recall', 0.972498), ('AUC', 0.9989885), ('loss', 0.009067172)])), ('stat', OrderedDict([('num_examples', 5772700)]))])\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 3\n",
    "for round_num in range(2, NUM_ROUNDS):\n",
    "    state, metrics = iterative_process.next(state, federated_train_data)\n",
    "    print('round {:2d}, metrics={}'.format(round_num, metrics))\n",
    "    print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loss is decreasing after each round of federated training, indicating\n",
    "the model is converging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's visualize the metrics from these federated computations using Tensorboard.\n",
    "\n",
    "Let's start by creating the directory and the corresponding summary writer to write the metrics to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"/tmp/logs/scalars/training/\"\n",
    "summary_writer = tf.summary.create_file_writer(logdir)\n",
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = tff.learning.build_federated_evaluation(model_fn)\n",
    "federated_test_data = make_federated_data(test_data, test_client_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  1, loss: 0.012665404006838799, test_accuracy: [0.6131092], training_recall : 0.9666298627853394, training_precision = 0.9961702823638916, training_f1 = 0.9811777728744955, val_precision = 0.0638551115989685, val_recall = 0.27774181962013245, val_f1 = 0.1038372056198123\n",
      "round:  2, loss: 0.009648364037275314, test_accuracy: [0.6131092, 0.6472984], training_recall : 0.9683720469474792, training_precision = 0.9985817670822144, training_f1 = 0.9832449737587943, val_precision = 0.07021452486515045, val_recall = 0.27531543374061584, val_f1 = 0.11189270852614036\n",
      "round:  3, loss: 0.010997599922120571, test_accuracy: [0.6131092, 0.6472984, 0.6805086], training_recall : 0.9695757031440735, training_precision = 0.9976620078086853, training_f1 = 0.9834183372028747, val_precision = 0.07813653349876404, val_recall = 0.27402135729789734, val_f1 = 0.12159930877763878\n",
      "round:  4, loss: 0.009223437868058681, test_accuracy: [0.6131092, 0.6472984, 0.6805086, 0.71082073], training_recall : 0.971322238445282, training_precision = 0.9984186887741089, training_f1 = 0.9846841300789233, val_precision = 0.08750904351472855, val_recall = 0.27402135729789734, val_f1 = 0.13265466826291467\n",
      "round:  5, loss: 0.008886171504855156, test_accuracy: [0.6131092, 0.6472984, 0.6805086, 0.71082073, 0.7388483], training_recall : 0.9723027348518372, training_precision = 0.9988229870796204, training_f1 = 0.98538445809589, val_precision = 0.09879839420318604, val_recall = 0.27531543374061584, val_f1 = 0.145414154918711\n",
      "round:  6, loss: 0.009236996993422508, test_accuracy: [0.6131092, 0.6472984, 0.6805086, 0.71082073, 0.7388483, 0.7649048], training_recall : 0.9735578894615173, training_precision = 0.9980379939079285, training_f1 = 0.9856459405361103, val_precision = 0.11205143481492996, val_recall = 0.2762860059738159, val_f1 = 0.1594399100199364\n",
      "round:  7, loss: 0.009495734237134457, test_accuracy: [0.6131092, 0.6472984, 0.6805086, 0.71082073, 0.7388483, 0.7649048, 0.7875932], training_recall : 0.9749289155006409, training_precision = 0.9977273941040039, training_f1 = 0.9861964461827042, val_precision = 0.12751975655555725, val_recall = 0.2793594300746918, val_f1 = 0.17510772673336947\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 10\n",
    "MAX_STD = 0.001\n",
    "loss = list()\n",
    "accuracy = list()\n",
    "val_loss = list()\n",
    "val_accuracy = list()\n",
    "precision = list()\n",
    "recall = list()\n",
    "f1 = list()\n",
    "val_precision = list()\n",
    "val_recall = list()\n",
    "val_f1 = list() \n",
    "train_AUC = list()\n",
    "val_AUC = list() \n",
    "\n",
    "with summary_writer.as_default():\n",
    "    for round_num in range(1, NUM_ROUNDS+1):\n",
    "        state, metrics = iterative_process.next(state, federated_train_data)\n",
    "        val_metrics = evaluation(state.model, federated_test_data)\n",
    "        \n",
    "        my_precision = metrics['train']['Precision']\n",
    "        precision.append(my_precision)\n",
    "        \n",
    "        my_recall = metrics['train']['Recall']\n",
    "        recall.append(my_recall)\n",
    "        \n",
    "        my_f1 = 2 * (my_precision * my_recall) / (my_precision + my_recall)\n",
    "        f1.append(my_f1)\n",
    "        \n",
    "        val_precision.append(val_metrics['eval']['Precision'])\n",
    "        val_recall.append(val_metrics['eval']['Recall'])\n",
    "        my_val_f1 = 2 * (val_metrics['eval']['Precision'] * val_metrics['eval']['Recall']) / (val_metrics['eval']['Precision'] + val_metrics['eval']['Recall'])\n",
    "        val_f1.append(my_val_f1)\n",
    "        \n",
    "        my_loss = metrics['train']['loss']\n",
    "        \n",
    "        train_AUC.append(metrics['train']['AUC'])\n",
    "        val_AUC.append(val_metrics['eval']['AUC'])\n",
    "        \n",
    "        loss.append(metrics['train']['loss'])\n",
    "        accuracy.append(metrics['train']['binary_accuracy'])\n",
    "        my_acc = val_metrics['eval']['binary_accuracy']\n",
    "        val_loss.append(val_metrics['eval']['loss'])\n",
    "        val_accuracy.append(val_metrics['eval']['binary_accuracy'])\n",
    "        print(f\"round: {round_num:2d}, loss: {my_loss}, test_accuracy: {val_accuracy}, training_recall : {my_recall}, training_precision = {my_precision}, training_f1 = {my_f1}, val_precision = {val_metrics['eval']['Precision']}, val_recall = {val_metrics['eval']['Recall']}, val_f1 = {my_val_f1}\")\n",
    "        for name, value in metrics['train'].items():\n",
    "            tf.summary.scalar(name, value, step=round_num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_test_data = make_federated_data(test_data, test_client_ids)\n",
    "print(federated_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls {logdir}\n",
    "%tensorboard --host 0.0.0.0 --logdir {logdir} --port=6004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(8, 8))\n",
    "ax1 = fig1.add_subplot(2, 1, 1)\n",
    "ax1.plot(accuracy, label='Training Accuracy')\n",
    "ax1.plot(val_accuracy, label='Validation Accuracy')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.set_title('Training and Validation AUC')\n",
    "\n",
    "ax2 = fig1.add_subplot(2, 1, 2)\n",
    "ax2.plot(loss, label='Training Loss')\n",
    "ax2.plot(val_loss, label='Validation Loss')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.set_ylabel('Cross Entropy')\n",
    "ax2.set_ylim([0,max(ax2.get_ylim())])\n",
    "ax2.set_title('Training and Validation Loss')\n",
    "ax2.set_xlabel('Round')\n",
    "\n",
    "# plt.savefig('./figures/DELIRIUM_normalized_TFF_accuracy_loss_10_rounds.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Round')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.figure(figsize=(8, 8))\n",
    "ax1 = fig1.add_subplot(2, 1, 1)\n",
    "ax1.plot(precision, label='Training precision')\n",
    "ax1.plot(val_precision, label='Validation precision')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.set_title('Training and Validation precision')\n",
    "\n",
    "ax2 = fig1.add_subplot(2, 1, 2)\n",
    "ax2.plot(recall, label='Training recall')\n",
    "ax2.plot(val_recall, label='Validation recall')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.set_ylabel('Cross Entropy')\n",
    "ax2.set_ylim([0,max(ax2.get_ylim())])\n",
    "ax2.set_title('Training and Validation recall')\n",
    "ax2.set_xlabel('Round')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = evaluation(state.model, federated_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OrderedDict([('eval', OrderedDict([('binary_accuracy', 0.80285037), ('Precision', 0.67264575), ('Recall', 0.9375), ('AUC', 0.93620694), ('loss', 0.6794335)])), ('stat', OrderedDict([('num_examples', 10525)]))])\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(train_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = evaluation(state.model, federated_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OrderedDict([('eval', OrderedDict([('binary_accuracy', 0.7972973), ('Precision', 0.6486486), ('Recall', 0.9230769), ('AUC', 0.9454127), ('loss', 0.6804818)])), ('stat', OrderedDict([('num_examples', 3700)]))])\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(test_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pets",
   "language": "python",
   "name": "pets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
