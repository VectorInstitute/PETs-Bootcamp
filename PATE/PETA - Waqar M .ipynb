{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad338e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from syft.frameworks.torch.dp import pate\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b1a382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f2146f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/ssd003/projects/pets/datasets/home_credit\"\n",
    "data = pd.read_csv(f\"{DATA_PATH}/train.csv\")\n",
    "labels = data.pop(\"target\")\n",
    "data = data.to_numpy(dtype=np.float32)\n",
    "labels = labels.to_numpy(dtype=np.int)\n",
    "dataset = HomeCredit(data=data, labels=labels)\n",
    "\n",
    "# Get train and validation size\n",
    "train_size = int(len(dataset) * TRAIN_PERC)\n",
    "val_size = len(dataset) - train_size\n",
    "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Define dataloaders\n",
    "t_loaders, s_loader = get_loaders(train_data, NUM_TEACHERS, BATCH_SIZE) # Teacher loaders, student loader\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, drop_last=True) # Loader to validate in Train Ensemble and Train Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66a7944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TRAIN_PERC = .9\n",
    "BATCH_SIZE = 1024\n",
    "NUM_TEACHERS = 15\n",
    "TEACHER_EPOCHS = 20\n",
    "STUDENT_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d9b057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HomeCredit(Dataset): \n",
    "    \"\"\"Dataset for Vertical Federated Learning\"\"\"\n",
    "\n",
    "    def __init__(self, data, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (Numpy Array) : Numpy Array with Features\n",
    "            labels (Numpy Array) : Numpy Array with Labels. None if not available. \n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return record single record\"\"\"\n",
    "        features = self.data[idx].astype(np.float32)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return features, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return Length\"\"\"\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1613de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(data, num_teachers, batch_size):\n",
    "    \"\"\" \n",
    "    Function to create data loaders for the Teacher Class.\n",
    "    \n",
    "    :param data: Numpy Array of the data \n",
    "    :param num_teacher: Number of teacher models \n",
    "    :param batch_size: Batch size for the dataloaders\n",
    "\n",
    "    :return: Return teacher loaders and student loader (with actual labels)\n",
    "    \"\"\" \n",
    "    loaders = []\n",
    "    sample_size = len(data) // (num_teachers + 1)\n",
    "\n",
    "    for i in range(num_teachers):\n",
    "        indices = list(range(i*sample_size, (i+1)*sample_size))\n",
    "        subset_data = Subset(data, indices)\n",
    "        loader = DataLoader(subset_data, batch_size=batch_size)\n",
    "        loaders.append(loader)\n",
    "    \n",
    "    return loaders[1:], loaders[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44bf3a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_loader(student_train_loader, labels):\n",
    "    \"\"\" \n",
    "    Function to modify the student loader to include labels from teacher\n",
    "    \n",
    "    :param student_train_loader: The student loader with actual labels \n",
    "    :param labels: Labels from the teacher model\n",
    "\n",
    "    :return: Return iterator  \n",
    "    \"\"\" \n",
    "    # Use teacher to label data (discard actual labels)\n",
    "    for i, (data, _) in enumerate(iter(student_train_loader)):\n",
    "        yield data, torch.from_numpy(labels[i*len(data): (i+1)*len(data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60f14a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 307511\n"
     ]
    }
   ],
   "source": [
    "#EDA\n",
    "# Load Data and Labels\n",
    "print(len(data_df.columns), len(data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb02ff60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.577538</td>\n",
       "      <td>0.142129</td>\n",
       "      <td>-0.478095</td>\n",
       "      <td>-0.166149</td>\n",
       "      <td>-0.507465</td>\n",
       "      <td>-0.149452</td>\n",
       "      <td>1.506880</td>\n",
       "      <td>-0.456215</td>\n",
       "      <td>0.379837</td>\n",
       "      <td>0.579154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090534</td>\n",
       "      <td>-0.024402</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>-8.210023e-02</td>\n",
       "      <td>-0.067957</td>\n",
       "      <td>-1.805048e-01</td>\n",
       "      <td>-0.313873</td>\n",
       "      <td>-3.594746e-01</td>\n",
       "      <td>-5.176655e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.577538</td>\n",
       "      <td>0.426792</td>\n",
       "      <td>1.725450</td>\n",
       "      <td>0.592677</td>\n",
       "      <td>1.600698</td>\n",
       "      <td>-1.252750</td>\n",
       "      <td>-0.166821</td>\n",
       "      <td>-0.460115</td>\n",
       "      <td>1.078697</td>\n",
       "      <td>1.790855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090534</td>\n",
       "      <td>-0.024402</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>-8.210023e-02</td>\n",
       "      <td>-0.067957</td>\n",
       "      <td>-1.805048e-01</td>\n",
       "      <td>-0.313873</td>\n",
       "      <td>-3.594746e-01</td>\n",
       "      <td>-1.092866e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.577538</td>\n",
       "      <td>-0.427196</td>\n",
       "      <td>-1.152888</td>\n",
       "      <td>-1.404676</td>\n",
       "      <td>-1.092389</td>\n",
       "      <td>-0.783451</td>\n",
       "      <td>-0.689509</td>\n",
       "      <td>-0.453299</td>\n",
       "      <td>0.206116</td>\n",
       "      <td>0.306869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090534</td>\n",
       "      <td>-0.024402</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>-8.210023e-02</td>\n",
       "      <td>-0.067957</td>\n",
       "      <td>-1.805048e-01</td>\n",
       "      <td>-0.313873</td>\n",
       "      <td>-3.594746e-01</td>\n",
       "      <td>-1.092866e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.577538</td>\n",
       "      <td>-0.142533</td>\n",
       "      <td>-0.711430</td>\n",
       "      <td>0.177869</td>\n",
       "      <td>-0.653696</td>\n",
       "      <td>-0.928991</td>\n",
       "      <td>-0.680114</td>\n",
       "      <td>-0.473217</td>\n",
       "      <td>-1.375829</td>\n",
       "      <td>0.369143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090534</td>\n",
       "      <td>-0.024402</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>3.336720e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.645032e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.516682e-17</td>\n",
       "      <td>-3.831603e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.577538</td>\n",
       "      <td>-0.199466</td>\n",
       "      <td>-0.213734</td>\n",
       "      <td>-0.361755</td>\n",
       "      <td>-0.068772</td>\n",
       "      <td>0.563570</td>\n",
       "      <td>-0.892535</td>\n",
       "      <td>-0.473210</td>\n",
       "      <td>0.191639</td>\n",
       "      <td>-0.307263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090534</td>\n",
       "      <td>-0.024402</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.018305</td>\n",
       "      <td>-8.210023e-02</td>\n",
       "      <td>-0.067957</td>\n",
       "      <td>-1.805048e-01</td>\n",
       "      <td>-0.313873</td>\n",
       "      <td>-3.594746e-01</td>\n",
       "      <td>-1.092866e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0     -0.577538          0.142129   -0.478095    -0.166149        -0.507465   \n",
       "1     -0.577538          0.426792    1.725450     0.592677         1.600698   \n",
       "2     -0.577538         -0.427196   -1.152888    -1.404676        -1.092389   \n",
       "3     -0.577538         -0.142533   -0.711430     0.177869        -0.653696   \n",
       "4     -0.577538         -0.199466   -0.213734    -0.361755        -0.068772   \n",
       "\n",
       "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  \\\n",
       "0                   -0.149452    1.506880      -0.456215           0.379837   \n",
       "1                   -1.252750   -0.166821      -0.460115           1.078697   \n",
       "2                   -0.783451   -0.689509      -0.453299           0.206116   \n",
       "3                   -0.928991   -0.680114      -0.473217          -1.375829   \n",
       "4                    0.563570   -0.892535      -0.473210           0.191639   \n",
       "\n",
       "   DAYS_ID_PUBLISH  ...  FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_20  \\\n",
       "0         0.579154  ...         -0.090534         -0.024402         -0.022529   \n",
       "1         1.790855  ...         -0.090534         -0.024402         -0.022529   \n",
       "2         0.306869  ...         -0.090534         -0.024402         -0.022529   \n",
       "3         0.369143  ...         -0.090534         -0.024402         -0.022529   \n",
       "4        -0.307263  ...         -0.090534         -0.024402         -0.022529   \n",
       "\n",
       "   FLAG_DOCUMENT_21  AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0         -0.018305               -8.210023e-02                  -0.067957   \n",
       "1         -0.018305               -8.210023e-02                  -0.067957   \n",
       "2         -0.018305               -8.210023e-02                  -0.067957   \n",
       "3         -0.018305                3.336720e-17                   0.000000   \n",
       "4         -0.018305               -8.210023e-02                  -0.067957   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0               -1.805048e-01                  -0.313873   \n",
       "1               -1.805048e-01                  -0.313873   \n",
       "2               -1.805048e-01                  -0.313873   \n",
       "3               -3.645032e-17                   0.000000   \n",
       "4               -1.805048e-01                  -0.313873   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0              -3.594746e-01               -5.176655e-01  \n",
       "1              -3.594746e-01               -1.092866e+00  \n",
       "2              -3.594746e-01               -1.092866e+00  \n",
       "3              -7.516682e-17               -3.831603e-16  \n",
       "4              -3.594746e-01               -1.092866e+00  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d60fbb41",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'value_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10619/2050587664.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# lable balance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabel_bd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_bd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_bd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabel_bd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'value_counts'"
     ]
    }
   ],
   "source": [
    "# lable balance \n",
    "label_bd = labels.value_counts()\n",
    "print(label_bd[1]/sum(label_bd) * 100,\"%\")\n",
    "label_bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3af93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e97d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9d3ea0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10619/2761175310.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# val_labels = np.array(val_data.pop('target'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mval_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Form np arrays of labels and features.\n",
    "# train_labels = np.array(train_data.pop('target'))\n",
    "# val_labels = np.array(val_data.pop('target'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06a4a546",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10619/1503898627.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "val_features = scaler.transform(val_features)\n",
    "\n",
    "train_features = np.clip(train_features, -5, 5)\n",
    "val_features = np.clip(val_features, -5, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fde704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "\n",
    "X_train_oversampled, y_oversampled = oversample.fit_resample(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c21b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af4fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb0da654",
   "metadata": {},
   "source": [
    "## MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c5eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HCModel(torch.nn.Module):\n",
    "    \"\"\" \n",
    "    Model for Credit Bureau\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    feat_dim: \n",
    "        Dimensionality of Data\n",
    "    Methods\n",
    "    -------\n",
    "    forward(x):\n",
    "        Performs a forward pass through the Credit Bureau Model\n",
    "    \"\"\"\n",
    "    def __init__(self, feat_dim): \n",
    "        super(HCModel, self).__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.feat_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, feat):\n",
    "        pred = self.layers(feat)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fdc3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models and otptimizers for teacher ensembles\n",
    "models = [HCModel(feat_dim=data.shape[1]) for i in range(NUM_TEACHERS)]\n",
    "opts = [torch.optim.Adam(model.parameters(), lr=.001,  betas=(0.9, 0.999)) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b41ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(num_teachers, models, opts, train_loaders, val_loader):\n",
    "    \"\"\" \n",
    "    Train the teacher models on the the training data and assess on validation set\n",
    "    \n",
    "    :param num_teacher: Number of teacher models \n",
    "    :param models A list of teacher models \n",
    "    :param opts A list of optimizers\n",
    "    :param train_loaders A list of train data loaders \n",
    "    :param val_loader A validation loader\n",
    "\n",
    "    :return: Return A list of train and validation losses for each epoch\n",
    "    \"\"\" \n",
    "    train_losses = [[] for i in range(num_teachers)]\n",
    "    val_losses = [[] for i in range(num_teachers)]\n",
    "    for epoch in range(TEACHER_EPOCHS):\n",
    "        train_loss = train_step(models, opts, train_loaders)\n",
    "        val_loss = val_step(models, val_loader)\n",
    "        avg_train_loss = sum(train_loss) / len(train_loss)\n",
    "        avg_val_loss = sum(val_loss) / len(val_loss)\n",
    "        print(f\"Epoch: {str(epoch)}\\t AVG Train Loss: {str(avg_train_loss)}\\t AVG Val Loss: {str(avg_val_loss)}\")\n",
    "\n",
    "\n",
    "        for i in range(num_teachers):\n",
    "            train_losses[i].append(train_loss[i])\n",
    "            val_losses[i].append(val_loss[i])\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24073e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(models, opts, train_loaders):\n",
    "    \"\"\" \n",
    "    Train teacher ensembles for a single epoch\n",
    "    \n",
    "    :param models A list of teacher models \n",
    "    :param opts A list of optimizers\n",
    "    :param train_loaders A list of train data loaders \n",
    "\n",
    "    :return: Return A list of train and validation losses for each teacher for each epoch\n",
    "    \"\"\" \n",
    "    train_running_losses = [0 for i in range(len(models))]\n",
    "    for i, (model, opt, loader) in enumerate(zip(models, opts, train_loaders)):\n",
    "            model = model.to(DEVICE)\n",
    "            for feat, lbl in loader:\n",
    "                feat, lbl = feat.to(DEVICE), lbl.to(DEVICE)\n",
    "                model.zero_grad()\n",
    "                out = model(feat)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                loss = criterion(out, lbl)\n",
    "\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                train_running_losses[i] += loss.detach().cpu().item()\n",
    "    \n",
    "    return train_running_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14221673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step(models, loader):\n",
    "    \"\"\" \n",
    "    Validation teacher ensembles for a single epoch\n",
    "    \n",
    "    :param models A list of teacher models \n",
    "    :param loader Validation dataloader\n",
    "\n",
    "    :return: A list of validation losses\n",
    "    \"\"\" \n",
    "    val_loss = []\n",
    "    for i, model in enumerate(models):\n",
    "        outputs, labels, _ = predict(model, loader)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss.append(loss.cpu().item())\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4dabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "    \"\"\" \n",
    "    Get predictions of single model on loader\n",
    "    \n",
    "    :param model A teacher model \n",
    "    :param loader A dataloader\n",
    "\n",
    "    :return: output of the model, labels, index of predicted class\n",
    "    \"\"\" \n",
    "    preds = torch.zeros(0, dtype=torch.long).to(DEVICE)\n",
    "    labels = torch.zeros(0, dtype=torch.long).to(DEVICE)\n",
    "    outputs = []\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    for feat, lbl in loader:\n",
    "        feat, lbl = feat.to(DEVICE), lbl.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            output = model(feat)\n",
    "        outputs.append(output)\n",
    "        ps = torch.argmax(torch.exp(output), dim=1)\n",
    "        preds = torch.cat((preds, ps))\n",
    "        labels = torch.cat((labels, lbl))\n",
    "    outputs = torch.cat(outputs, dim=0)\n",
    "\n",
    "    return outputs, labels, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbe2f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_teacher(models, loader, epsilon):\n",
    "    \"\"\" \n",
    "    Get noisily aggregated prediction of teacher ensemble \n",
    "    \n",
    "    :param models A list of teacher models \n",
    "    :param loader A dataloader\n",
    "    :param epsilon A noise parameter for the laplace \n",
    "\n",
    "    :return: index of predictions, actual labels\n",
    "    \"\"\" \n",
    "    preds = []\n",
    "    for i, model in enumerate(models):\n",
    "        _, _, pred = predict(model, loader)\n",
    "        preds.append(pred.cpu().numpy())\n",
    "    preds = np.stack(preds)\n",
    "\n",
    "    labels = np.array([]).astype(int)\n",
    "    for pred in np.transpose(preds):\n",
    "        label_counts = np.bincount(pred, minlength=2)\n",
    "        beta = 1 / epsilon\n",
    "\n",
    "        for i in range(len(label_counts)):\n",
    "            noise = np.random.laplace(0, beta, 1)\n",
    "            label_counts[i] += noise\n",
    "\n",
    "        new_label = np.argmax(label_counts)\n",
    "        labels = np.append(labels, new_label)\n",
    "\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad42cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_student(model, opt, train_loader, val_loader, epochs):\n",
    "    \"\"\" \n",
    "    Train student on public dataset labelled with teach ensemble\n",
    "    \n",
    "    :param model Student model\n",
    "    :param opt Optimizer for hte student model \n",
    "    :param train_loader Train dataloader\n",
    "    :param val_loader Validation dataloader\n",
    "    :epochs The number of epochs\n",
    "\n",
    "    :return: list of train losses, list of validation losses, list of validation aucs\n",
    "    \"\"\" \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_aucs = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_student_step(model, opt, train_loader)\n",
    "        val_loss, val_auc = val_student_step(model, val_loader)\n",
    "        print(f\"{str(epoch)}\\t AVG Train Loss: {str(train_loss)}\\t AVG Val Loss: {str(val_loss)} \\t AVG AUC: {val_auc}\")\n",
    " \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_aucs.append(val_auc)\n",
    "        \n",
    "    return train_losses, val_losses, val_aucs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2727e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_student_step(model, opt, train_loader):\n",
    "    \"\"\" \n",
    "    Train step on student model\n",
    "    \n",
    "    :param model Student model\n",
    "    :param opt Optimizer for hte student model \n",
    "    :param train_loader Train dataloader\n",
    "\n",
    "\n",
    "    :return: running loss from the step \n",
    "    \"\"\"\n",
    "    running_loss = 0\n",
    "    model.to(DEVICE)\n",
    "    model.train()\n",
    "    for i, (feat, lbl) in enumerate(train_loader):\n",
    "        feat, lbl = feat.to(DEVICE), lbl.to(DEVICE)\n",
    "        model.zero_grad()\n",
    "        out = model(feat)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(out, lbl)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += loss.detach().cpu().item()\n",
    "    \n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78778076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_student_step(model, val_loader):\n",
    "    \"\"\" \n",
    "    Validation step on student model\n",
    "    \n",
    "    :param model Student model\n",
    "    :param val_loader A validation load\n",
    "\n",
    "\n",
    "    :return: Average loss , Average auc\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    aucs = []\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    for i, (feat, lbl) in enumerate(val_loader):\n",
    "        feat, lbl = feat.to(DEVICE), lbl.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            out = model(feat)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(out, lbl)\n",
    "        auc = roc_auc_score(lbl.cpu().numpy(), out.cpu().numpy()[:, 1])\n",
    "\n",
    "        losses.append(loss.cpu().item())\n",
    "        aucs.append(auc)\n",
    "\n",
    "    avg_auc = sum(aucs) / len(aucs)\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "    return avg_loss, avg_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49757123",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses = train_models(NUM_TEACHERS, models, opts, t_loaders, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871ba372",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = HCModel(feat_dim=104)\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=0.003)\n",
    "\n",
    "train_losses, val_losses, val_aucs  = train_student(student_model, optimizer, s_loader, val_loader, STUDENT_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1, 1, figsize=(10, 10))\n",
    "axarr.plot(val_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783c78ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
